From 27adef920887a63fd8c509d25f5e0fbcb6f67a8d Mon Sep 17 00:00:00 2001
From: Peleg Hadar <peleg.hadar.w@gmail.com>
Date: Tue, 6 Jul 2021 14:34:55 +0200
Subject: [PATCH 1/2] Ported kAFL & hAFL2 to QEMU 6

---
 accel/kvm/kvm-all.c       | 129 ++++++
 configure                 |  13 +-
 hmp-commands-pt.hx        |  76 ++++
 hmp-commands.hx           |  11 +
 include/hw/core/cpu.h     |  42 ++
 include/monitor/hmp.h     |  11 +-
 include/qemu/log.h        |   1 +
 linux-headers/linux/kvm.h |  69 +++
 meson.build               |  20 +-
 monitor/hmp-cmds.c        | 183 ++++++++
 monitor/misc.c            |  10 +
 pt.c                      | 476 ++++++++++++++++++++
 pt.h                      |  35 ++
 pt/Makefile.objs          |   2 +
 pt/asm_decoder.c          | 226 ++++++++++
 pt/asm_decoder.h          |  32 ++
 pt/cfg.h                  |  80 ++++
 pt/debug.h                |  36 ++
 pt/decoder.c              | 738 +++++++++++++++++++++++++++++++
 pt/decoder.h              |  98 +++++
 pt/disassembler.c         | 762 ++++++++++++++++++++++++++++++++
 pt/disassembler.h         |  96 ++++
 pt/file_helper.c          | 137 ++++++
 pt/file_helper.h          |  31 ++
 pt/filter.c               | 109 +++++
 pt/filter.h               |  51 +++
 pt/hypercall.c            | 626 ++++++++++++++++++++++++++
 pt/hypercall.h            | 153 +++++++
 pt/interface.c            | 408 +++++++++++++++++
 pt/interface.h            |  70 +++
 pt/khash.h                | 607 +++++++++++++++++++++++++
 pt/logger.c               | 106 +++++
 pt/logger.h               |  57 +++
 pt/memory_access.c        | 289 ++++++++++++
 pt/memory_access.h        |  60 +++
 pt/meson.build            |   0
 pt/patcher.c              | 192 ++++++++
 pt/patcher.h              |  54 +++
 pt/printk.c               | 113 +++++
 pt/printk.h               |  17 +
 pt/redqueen.c             | 905 ++++++++++++++++++++++++++++++++++++++
 pt/redqueen.h             | 122 +++++
 pt/redqueen_patch.c       |  49 +++
 pt/redqueen_patch.h       |  20 +
 pt/synchronization.c      | 110 +++++
 pt/synchronization.h      |  19 +
 pt/tmp.objs               |   2 +
 pt/tnt_cache.c            |  82 ++++
 pt/tnt_cache.h            |  49 +++
 scripts/qemu-version.sh   |   2 +-
 softmmu/hmp-commands-pt.h |  70 +++
 softmmu/runstate.c        |  71 +++
 softmmu/vl.c              |   7 +
 util/log.c                |   2 +
 54 files changed, 7731 insertions(+), 5 deletions(-)
 create mode 100644 hmp-commands-pt.hx
 create mode 100644 pt.c
 create mode 100644 pt.h
 create mode 100644 pt/Makefile.objs
 create mode 100644 pt/asm_decoder.c
 create mode 100644 pt/asm_decoder.h
 create mode 100644 pt/cfg.h
 create mode 100644 pt/debug.h
 create mode 100644 pt/decoder.c
 create mode 100644 pt/decoder.h
 create mode 100644 pt/disassembler.c
 create mode 100644 pt/disassembler.h
 create mode 100644 pt/file_helper.c
 create mode 100644 pt/file_helper.h
 create mode 100644 pt/filter.c
 create mode 100644 pt/filter.h
 create mode 100644 pt/hypercall.c
 create mode 100644 pt/hypercall.h
 create mode 100644 pt/interface.c
 create mode 100644 pt/interface.h
 create mode 100644 pt/khash.h
 create mode 100644 pt/logger.c
 create mode 100644 pt/logger.h
 create mode 100644 pt/memory_access.c
 create mode 100644 pt/memory_access.h
 create mode 100644 pt/meson.build
 create mode 100644 pt/patcher.c
 create mode 100644 pt/patcher.h
 create mode 100644 pt/printk.c
 create mode 100644 pt/printk.h
 create mode 100644 pt/redqueen.c
 create mode 100644 pt/redqueen.h
 create mode 100644 pt/redqueen_patch.c
 create mode 100644 pt/redqueen_patch.h
 create mode 100644 pt/synchronization.c
 create mode 100644 pt/synchronization.h
 create mode 100644 pt/tmp.objs
 create mode 100644 pt/tnt_cache.c
 create mode 100644 pt/tnt_cache.h
 create mode 100644 softmmu/hmp-commands-pt.h

diff --git a/accel/kvm/kvm-all.c b/accel/kvm/kvm-all.c
index b6d9f92f1..6b7b29aec 100644
--- a/accel/kvm/kvm-all.c
+++ b/accel/kvm/kvm-all.c
@@ -49,6 +49,12 @@
 
 #include "hw/boards.h"
 
+#ifdef CONFIG_PROCESSOR_TRACE
+#include "pt.h"
+#include "pt/hypercall.h"
+#include "pt/synchronization.h"
+#endif
+
 /* This check must be after config-host.h is included */
 #ifdef CONFIG_EVENTFD
 #include <sys/eventfd.h>
@@ -438,6 +444,10 @@ int kvm_init_vcpu(CPUState *cpu, Error **errp)
     cpu->kvm_state = s;
     cpu->vcpu_dirty = true;
 
+#ifdef CONFIG_PROCESSOR_TRACE
+    pt_kvm_init(cpu);
+#endif
+
     mmap_size = kvm_ioctl(s, KVM_GET_VCPU_MMAP_SIZE, 0);
     if (mmap_size < 0) {
         ret = mmap_size;
@@ -2425,6 +2435,10 @@ static void kvm_eat_signals(CPUState *cpu)
     } while (sigismember(&chkset, SIG_IPI));
 }
 
+#ifdef CONFIG_PROCESSOR_TRACE
+extern void qemu_system_reload_request(void);
+#endif
+
 int kvm_cpu_exec(CPUState *cpu)
 {
     struct kvm_run *run = cpu->kvm_run;
@@ -2443,6 +2457,8 @@ int kvm_cpu_exec(CPUState *cpu)
     do {
         MemTxAttrs attrs;
 
+        synchronization_check_reload_pending(cpu);
+
         if (cpu->vcpu_dirty) {
             kvm_arch_put_registers(cpu, KVM_PUT_RUNTIME_STATE);
             cpu->vcpu_dirty = false;
@@ -2538,6 +2554,116 @@ int kvm_cpu_exec(CPUState *cpu)
         case KVM_EXIT_INTERNAL_ERROR:
             ret = kvm_handle_internal_error(cpu, run);
             break;
+        #ifdef CONFIG_PROCESSOR_TRACE
+        case KVM_EXIT_KAFL_ACQUIRE:
+            handle_hypercall_kafl_acquire(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_GET_PAYLOAD:
+            handle_hypercall_get_payload(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_GET_PROGRAM:
+            handle_hypercall_get_program(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_RELEASE:
+            handle_hypercall_kafl_release(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_SUBMIT_CR3:
+            handle_hypercall_kafl_cr3(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_SUBMIT_PANIC:
+            handle_hypercall_kafl_submit_panic(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_SUBMIT_KASAN:
+            handle_hypercall_kafl_submit_kasan(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_PANIC:
+            handle_hypercall_kafl_panic(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_KASAN:
+            handle_hypercall_kafl_kasan(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_TIMEOUT:
+            handle_hypercall_kafl_timeout(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_LOCK:
+            handle_hypercall_kafl_lock(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_INFO:
+            handle_hypercall_kafl_info(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_NEXT_PAYLOAD:
+            handle_hypercall_kafl_next_payload(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_PRINTF:
+            handle_hypercall_kafl_printf(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_PRINTK_ADDR:
+            handle_hypercall_kafl_printk_addr(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_PRINTK:
+            handle_hypercall_kafl_printk(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_CRASH_DUMP:
+             handle_hypercall_kafl_crash_dump(run, cpu);
+             ret = 0;
+             break;
+        case KVM_EXIT_KAFL_CRASH_DUMP_SIZE:
+             handle_hypercall_kafl_crash_dump_size(run, cpu);
+             ret = 0;
+             break;
+        /* user space only exit reasons */
+        case KVM_EXIT_KAFL_USER_RANGE_ADVISE:
+            handle_hypercall_kafl_user_range_advise(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_USER_SUBMIT_MODE:
+            handle_hypercall_kafl_user_submit_mode(run, cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_USER_FAST_ACQUIRE:
+            if(handle_hypercall_kafl_next_payload(run, cpu)){
+                handle_hypercall_kafl_cr3(run, cpu);
+                handle_hypercall_kafl_acquire(run, cpu);
+            }
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_TOPA_MAIN_FULL:
+            //synchronization_lock(cpu);
+            pt_handle_overflow(cpu);
+            ret = 0;
+            break;
+        case KVM_EXIT_KAFL_USER_ABORT:
+            handle_hypercall_kafl_user_abort(run, cpu);
+            ret = 0;
+            break;
+#ifdef CONFIG_REDQUEEN
+        case KVM_EXIT_DEBUG:
+            kvm_arch_get_registers(cpu);
+            if(!handle_hypercall_kafl_hook(run, cpu)){
+                ret = kvm_arch_handle_exit(cpu, run);
+            }
+            else {
+                ret = 0;
+            }
+            break;
+#endif
+#endif
         case KVM_EXIT_SYSTEM_EVENT:
             switch (run->system_event.type) {
             case KVM_SYSTEM_EVENT_SHUTDOWN:
@@ -2566,6 +2692,9 @@ int kvm_cpu_exec(CPUState *cpu)
             ret = kvm_arch_handle_exit(cpu, run);
             break;
         }
+#ifdef CONFIG_PROCESSOR_TRACE                                                                                                                                                
+        pt_post_kvm_run(cpu);                                                                                                                                            
+#endif    
     } while (ret == 0);
 
     cpu_exec_end(cpu);
diff --git a/configure b/configure
index 4f374b488..5acea8c89 100755
--- a/configure
+++ b/configure
@@ -862,6 +862,10 @@ for opt do
   case "$opt" in
   --help|-h) show_help=yes
   ;;
+  --enable-pt) pt="yes"
+  ;;
+  --enable-redqueen) redqueen="yes"
+  ;;
   --version|-V) exec cat $source_path/VERSION
   ;;
   --prefix=*) prefix="$optarg"
@@ -1811,6 +1815,7 @@ disabled with --disable-FEATURE, default is enabled if available
   debug-info      debugging information
   lto             Enable Link-Time Optimization.
   sparse          sparse checker
+  pt              enable guest tracing (vmx_pt)
   safe-stack      SafeStack Stack Smash Protection. Depends on
                   clang/llvm >= 3.7 and requires coroutine backend ucontext.
   cfi             Enable Control-Flow Integrity for indirect function calls.
@@ -5299,7 +5304,7 @@ write_c_skeleton
 if test "$gcov" = "yes" ; then
   :
 elif test "$fortify_source" = "yes" ; then
-  QEMU_CFLAGS="-U_FORTIFY_SOURCE -D_FORTIFY_SOURCE=2 $QEMU_CFLAGS"
+  QEMU_CFLAGS="-O3 -frename-registers -funroll-loops -frename-registers -mtune=native -g -U_FORTIFY_SOURCE -D_FORTIFY_SOURCE=2 $QEMU_CFLAGS"
   debug=no
 fi
 
@@ -5596,6 +5601,12 @@ fi
 if test "$splice" = "yes" ; then
   echo "CONFIG_SPLICE=y" >> $config_host_mak
 fi
+if test "$pt" = "yes" ; then
+  echo "CONFIG_PROCESSOR_TRACE=y" >> $config_host_mak
+  if test "$redqueen" = "yes" ; then
+    echo "CONFIG_REDQUEEN=y" >> $config_host_mak
+  fi
+fi
 if test "$eventfd" = "yes" ; then
   echo "CONFIG_EVENTFD=y" >> $config_host_mak
 fi
diff --git a/hmp-commands-pt.hx b/hmp-commands-pt.hx
new file mode 100644
index 000000000..e8f05bb73
--- /dev/null
+++ b/hmp-commands-pt.hx
@@ -0,0 +1,76 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+HXCOMM Use DEFHEADING() to define headings in both help text and texi
+HXCOMM Text between STEXI and ETEXI are copied to texi version and
+HXCOMM discarded from C version
+HXCOMM DEF(command, args, callback, arg_string, help) is used to construct
+HXCOMM monitor info commands
+HXCOMM HXCOMM can be used for comments, discarded from both texi and C
+
+#if defined(CONFIG_PROCESSOR_TRACE)
+
+{
+    .name       = "enable",
+    .args_type  = "id:i",
+    .params     = "id",
+    .help       = "enable processor tracing for specified vcpu",
+    .cmd  = hmp_pt_enable,
+},
+{
+    .name       = "enable_all",
+    .args_type  = "",
+    .params     = "",
+    .help       = "enable processor tracing for all presented vcpus",
+    .cmd  = hmp_pt_enable_all,
+},
+{
+    .name       = "disable",
+    .args_type  = "id:i",
+    .params     = "id",
+    .help       = "disable processor tracing for specified vcpu",
+    .cmd  = hmp_pt_disable,
+},
+{
+    .name       = "disable_all",
+    .args_type  = "",
+    .params     = "",
+    .help       = "disable processor tracing for all presented vcpus",
+    .cmd  = hmp_pt_disable_all,
+},
+{
+    .name       = "status",
+    .args_type  = "id:i",
+    .params     = "id",
+    .help       = "print processor tracing status of specified vcpu",
+    .cmd  = hmp_pt_status,
+},
+{
+    .name       = "status_all",
+    .args_type  = "",
+    .params     = "",
+    .help       = "print processor tracing status of all presented vcpus",
+    .cmd  = hmp_pt_status_all,
+},
+{
+    .name       = "ip_filtering",
+    .args_type  = "id:i,addrn:i,addr_a:l,addr_b:l",
+    .params     = "id addrn (0-4) addr_a addr_b",
+    .help       = "enables ip-filtering for specified vcpu",
+    .cmd  = hmp_pt_ip_filtering,
+},
+{
+    .name       = "set_file",
+    .args_type  = "file:s",
+    .params     = "file",
+    .help       = "set output file for all specified vcpu (postfix: _cpuid)",
+    .cmd  = hmp_pt_set_file,
+},
+        
+#endif
diff --git a/hmp-commands.hx b/hmp-commands.hx
index 435c591a1..eb4fe883e 100644
--- a/hmp-commands.hx
+++ b/hmp-commands.hx
@@ -1725,3 +1725,14 @@ ERST
         .flags      = "p",
     },
 
+#if defined(CONFIG_PROCESSOR_TRACE) && defined(TARGET_X86_64)
+    {
+        .name       = "pt",
+        .args_type  = "item:s?",
+        .params     = "[subcommand]",
+        .help       = "show various option to configure Intel Processor Tracing",
+        .cmd        = hmp_info_help,
+        .sub_table  = hmp_pt_cmds,
+        .flags      = "p",
+    },
+#endif
diff --git a/include/hw/core/cpu.h b/include/hw/core/cpu.h
index c68bc3ba8..6766dbc9d 100644
--- a/include/hw/core/cpu.h
+++ b/include/hw/core/cpu.h
@@ -393,6 +393,48 @@ struct CPUState {
      * we store some rarely used information in the CPU context.
      */
     uintptr_t mem_io_pc;
+#ifdef CONFIG_PROCESSOR_TRACE
+#include "pt/interface.h"
+    volatile int pt_cmd;
+    volatile uint64_t pt_arg;
+    volatile int pt_ret;
+    volatile bool pt_enabled;
+    volatile bool decoder_compile_init;
+    volatile bool ip_enabled;
+    int pt_fd;
+    void* pt_mmap;
+
+    volatile uint32_t overflow_counter;
+    volatile uint64_t trace_size;
+
+    uint64_t pt_features;
+
+    volatile bool pt_ip_filter_enabled[INTEL_PT_MAX_RANGES];
+    uint64_t pt_ip_filter_a[INTEL_PT_MAX_RANGES];
+    uint64_t pt_ip_filter_b[INTEL_PT_MAX_RANGES];
+    void* pt_decoder_state[INTEL_PT_MAX_RANGES];
+    uint64_t pt_c3_filter;
+
+    FILE *pt_target_file;
+    bool reload_pending;
+    bool executing;
+    int disassembler_word_width;
+    bool intel_pt_run_trashed;
+    
+
+#ifdef CONFIG_REDQUEEN
+    void* redqueen_state[INTEL_PT_MAX_RANGES];
+    bool redqueen_enable_pending;
+    bool redqueen_disable_pending;
+
+    int redqueen_instrumentation_mode;
+    bool redqueen_update_blacklist;
+
+    bool patches_enable_pending;
+    bool patches_disable_pending;
+    void* redqueen_patch_state;
+#endif
+#endif
 
     int kvm_fd;
     struct KVMState *kvm_state;
diff --git a/include/monitor/hmp.h b/include/monitor/hmp.h
index 605d57287..e304999a4 100644
--- a/include/monitor/hmp.h
+++ b/include/monitor/hmp.h
@@ -17,7 +17,16 @@
 #include "qemu/readline.h"
 
 void hmp_handle_error(Monitor *mon, Error *err);
-
+#ifdef CONFIG_PROCESSOR_TRACE
+void hmp_pt_enable(Monitor *mon, const QDict *qdict);
+void hmp_pt_disable(Monitor *mon, const QDict *qdict);
+void hmp_pt_enable_all(Monitor *mon, const QDict *qdict);
+void hmp_pt_disable_all(Monitor *mon, const QDict *qdict);
+void hmp_pt_status(Monitor *mon, const QDict *qdict);
+void hmp_pt_status_all(Monitor *mon, const QDict *qdict);
+void hmp_pt_ip_filtering(Monitor *mon, const QDict *qdict);
+void hmp_pt_set_file(Monitor *mon, const QDict *qdict);
+#endif
 void hmp_info_name(Monitor *mon, const QDict *qdict);
 void hmp_info_version(Monitor *mon, const QDict *qdict);
 void hmp_info_kvm(Monitor *mon, const QDict *qdict);
diff --git a/include/qemu/log.h b/include/qemu/log.h
index 9b8066020..c9f087535 100644
--- a/include/qemu/log.h
+++ b/include/qemu/log.h
@@ -64,6 +64,7 @@ static inline bool qemu_log_separate(void)
 #define CPU_LOG_PLUGIN     (1 << 18)
 /* LOG_STRACE is used for user-mode strace logging. */
 #define LOG_STRACE         (1 << 19)
+#define LOG_KAFL           (1 << 20)
 
 /* Lock output for a series of related logs.  Since this is not needed
  * for a single qemu_log / qemu_log_mask / qemu_log_mask_and_addr, we
diff --git a/linux-headers/linux/kvm.h b/linux-headers/linux/kvm.h
index 020b62a61..47758f192 100644
--- a/linux-headers/linux/kvm.h
+++ b/linux-headers/linux/kvm.h
@@ -252,6 +252,40 @@ struct kvm_hyperv_exit {
 #define KVM_EXIT_X86_WRMSR        30
 #define KVM_EXIT_DIRTY_RING_FULL  31
 
+#define HYPERCALL_KAFL_RAX_ID			35
+#define KAFL_EXIT_OFFSET				100
+
+#define KVM_EXIT_KAFL_ACQUIRE			100
+#define KVM_EXIT_KAFL_GET_PAYLOAD		101
+#define KVM_EXIT_KAFL_GET_PROGRAM		102
+#define KVM_EXIT_KAFL_GET_ARGV			103
+#define KVM_EXIT_KAFL_RELEASE			104
+#define KVM_EXIT_KAFL_SUBMIT_CR3		105
+#define KVM_EXIT_KAFL_SUBMIT_PANIC		106
+#define KVM_EXIT_KAFL_SUBMIT_KASAN		107
+#define KVM_EXIT_KAFL_PANIC				108
+#define KVM_EXIT_KAFL_KASAN				109
+#define KVM_EXIT_KAFL_LOCK				110
+#define KVM_EXIT_KAFL_INFO				111
+#define KVM_EXIT_KAFL_NEXT_PAYLOAD		112
+#define KVM_EXIT_KAFL_PRINTF			113
+
+/* Kernel Printf Debugger */
+#define KVM_EXIT_KAFL_PRINTK_ADDR		114
+#define KVM_EXIT_KAFL_PRINTK			115
+
+/* user space only exit reasons */
+#define KVM_EXIT_KAFL_USER_RANGE_ADVISE	116
+#define KVM_EXIT_KAFL_USER_SUBMIT_MODE	117
+#define KVM_EXIT_KAFL_USER_FAST_ACQUIRE	118
+#define KVM_EXIT_KAFL_TOPA_MAIN_FULL	119
+#define KVM_EXIT_KAFL_USER_ABORT		120
+#define KVM_EXIT_KAFL_TIMEOUT			121
+#define KVM_EXIT_KAFL_CRASH_DUMP               122
+#define KVM_EXIT_KAFL_CRASH_DUMP_SIZE          123
+#define KVM_EXIT_KAFL_CRASH_DUMP_OFFSET                124
+
+
 /* For KVM_EXIT_INTERNAL_ERROR */
 /* Emulate instruction failed. */
 #define KVM_INTERNAL_ERROR_EMULATION	1
@@ -1713,6 +1747,41 @@ struct kvm_hyperv_eventfd {
 #define KVM_HYPERV_CONN_ID_MASK		0x00ffffff
 #define KVM_HYPERV_EVENTFD_DEASSIGN	(1 << 0)
 
+/*
+ * ioctls for vmx_pt fds
+ */
+#define KVM_VMX_PT_SETUP_FD                                     _IO(KVMIO,      0xd0)                   /* apply vmx_pt fd (via vcpu fd ioctl)*/
+#define KVM_VMX_PT_CONFIGURE_ADDR0                      _IOW(KVMIO,     0xd1, __u64)    /* configure IP-filtering for addr0_a & addr0_b */
+#define KVM_VMX_PT_CONFIGURE_ADDR1                      _IOW(KVMIO,     0xd2, __u64)    /* configure IP-filtering for addr1_a & addr1_b */
+#define KVM_VMX_PT_CONFIGURE_ADDR2                      _IOW(KVMIO,     0xd3, __u64)    /* configure IP-filtering for addr2_a & addr2_b */
+#define KVM_VMX_PT_CONFIGURE_ADDR3                      _IOW(KVMIO,     0xd4, __u64)    /* configure IP-filtering for addr3_a & addr3_b */
+
+#define KVM_VMX_PT_CONFIGURE_CR3                        _IOW(KVMIO,     0xd5, __u64)    /* setup CR3 filtering value */
+#define KVM_VMX_PT_ENABLE                                       _IO(KVMIO,      0xd6)                   /* enable and lock configuration */ 
+#define KVM_VMX_PT_GET_TOPA_SIZE                        _IOR(KVMIO,     0xd7, __u32)    /* get defined ToPA size */
+#define KVM_VMX_PT_DISABLE                                      _IO(KVMIO,      0xd8)                   /* enable and lock configuration */ 
+#define KVM_VMX_PT_CHECK_TOPA_OVERFLOW          _IO(KVMIO,      0xd9)                   /* check for ToPA overflow */
+
+#define KVM_VMX_PT_ENABLE_ADDR0                         _IO(KVMIO,      0xaa)                   /* enable IP-filtering for addr0 */
+#define KVM_VMX_PT_ENABLE_ADDR1                         _IO(KVMIO,      0xab)                   /* enable IP-filtering for addr1 */
+#define KVM_VMX_PT_ENABLE_ADDR2                         _IO(KVMIO,      0xac)                   /* enable IP-filtering for addr2 */
+#define KVM_VMX_PT_ENABLE_ADDR3                         _IO(KVMIO,      0xad)                   /* enable IP-filtering for addr3 */
+
+#define KVM_VMX_PT_DISABLE_ADDR0                        _IO(KVMIO,      0xae)                   /* disable IP-filtering for addr0 */
+#define KVM_VMX_PT_DISABLE_ADDR1                        _IO(KVMIO,      0xaf)                   /* disable IP-filtering for addr1 */
+#define KVM_VMX_PT_DISABLE_ADDR2                        _IO(KVMIO,      0xe0)                   /* disable IP-filtering for addr2 */
+#define KVM_VMX_PT_DISABLE_ADDR3                        _IO(KVMIO,      0xe1)                   /* disable IP-filtering for addr3 */
+
+#define KVM_VMX_PT_ENABLE_CR3                           _IO(KVMIO,      0xe2)                   /* enable CR3 filtering */
+#define KVM_VMX_PT_DISABLE_CR3                          _IO(KVMIO,      0xe3)                   /* disable CR3 filtering */
+
+#define KVM_VMX_PT_SUPPORTED                            _IO(KVMIO,      0xe4)
+
+#define KVM_VMX_PT_CONFIGURE_HYPERCALL_HOOK     _IOW(KVMIO,     0xe5, __u64)    /* set address for hypercall hooks */
+
+#define KVM_VMX_PT_WRITE_TO_GUEST		_IOW(KVMIO,	0xe6, __u64)	/* write to guest memory (for nested VMs) */
+#define KVM_VMX_PT_READ_FROM_GUEST		_IOW(KVMIO,	0xe7, __u64)	/* read from guest memory (for nested VMs) */
+
 #define KVM_DIRTY_LOG_MANUAL_PROTECT_ENABLE    (1 << 0)
 #define KVM_DIRTY_LOG_INITIALLY_SET            (1 << 1)
 
diff --git a/meson.build b/meson.build
index c6f4b0cf5..e5e820e98 100644
--- a/meson.build
+++ b/meson.build
@@ -1713,6 +1713,7 @@ if have_system
   hx_headers += [
     ['hmp-commands.hx', 'hmp-commands.h'],
     ['hmp-commands-info.hx', 'hmp-commands-info.h'],
+    ['hmp-commands-pt.hx', 'hmp-commands-pt.h'],
   ]
 endif
 foreach d : hx_headers
@@ -1836,7 +1837,7 @@ if have_system
     'net',
     'softmmu',
     'ui',
-    'hw/remote',
+    'hw/remote'
   ]
 endif
 if have_system or have_user
@@ -1925,6 +1926,7 @@ if have_block
   # os-win32.c does not
   blockdev_ss.add(when: 'CONFIG_POSIX', if_true: files('os-posix.c'))
   softmmu_ss.add(when: 'CONFIG_WIN32', if_true: [files('os-win32.c')])
+  
 endif
 
 common_ss.add(files('cpus-common.c'))
@@ -1932,7 +1934,20 @@ common_ss.add(files('cpus-common.c'))
 subdir('softmmu')
 
 common_ss.add(capstone)
-specific_ss.add(files('cpu.c', 'disas.c', 'gdbstub.c'), capstone)
+specific_ss.add(files('cpu.c', 'disas.c', 'gdbstub.c', 'pt.c'), capstone)
+specific_ss.add(files(
+  'pt/decoder.c',
+  'pt/disassembler.c',
+  'pt/tnt_cache.c',
+  'pt/hypercall.c',
+  'pt/filter.c',
+  'pt/logger.c',
+  'pt/memory_access.c',
+  'pt/interface.c',
+  'pt/printk.c',
+  'pt/synchronization.c',
+  'pt/asm_decoder.c'
+))
 specific_ss.add(when: 'CONFIG_TCG', if_true: files(
   'fpu/softfloat.c',
   'tcg/optimize.c',
@@ -2120,6 +2135,7 @@ foreach m : block_mods + softmmu_mods
 endforeach
 
 softmmu_ss.add(authz, blockdev, chardev, crypto, io, qmp)
+
 common_ss.add(qom, qemuutil)
 
 common_ss.add_all(when: 'CONFIG_SOFTMMU', if_true: [softmmu_ss])
diff --git a/monitor/hmp-cmds.c b/monitor/hmp-cmds.c
index 0ad5b7747..2ddb9b975 100644
--- a/monitor/hmp-cmds.c
+++ b/monitor/hmp-cmds.c
@@ -62,6 +62,189 @@
 #include <spice/enums.h>
 #endif
 
+#ifdef CONFIG_PROCESSOR_TRACE
+#include "pt.h"
+#include "hw/core/cpu.h"
+#include "qapi/qapi-commands-machine.h"
+static inline bool hmp_pt_check_kvm(Monitor *mon){
+        KvmInfo *info;
+        info = qmp_query_kvm(NULL);
+        if (!info->enabled){
+                monitor_printf(mon, "kvm is not used...\n");
+                qapi_free_KvmInfo(info);
+                return false;
+        }
+        qapi_free_KvmInfo(info);
+        return true;
+}
+static inline int hmp_pt_get_cpuid(Monitor *mon, const QDict *qdict){
+        int cpuid = qdict_get_int(qdict, "id");    
+        if(cpuid < 0 || !qemu_get_cpu(cpuid)){
+                monitor_printf(mon, "invalid CPU id\n");
+                cpuid = -1;
+        }
+        return cpuid;
+}
+static inline void hmp_pt_enable_cpu(Monitor *mon, int cpuid){
+    CPUState *cpu = qemu_get_cpu(cpuid);
+    if (!cpu->pt_enabled){
+        if(!pt_enable(qemu_get_cpu(cpuid), true)){
+            monitor_printf(mon, "CPU %d: processor trace enabled!\n", cpuid);
+        }
+        else{
+            monitor_printf(mon, "CPU %d: failed...\n", cpuid);
+        }
+    }
+}
+static inline void hmp_pt_disable_cpu(Monitor *mon, int cpuid){
+    CPUState *cpu = qemu_get_cpu(cpuid);
+    if (cpu->pt_enabled){
+        if(!pt_disable(qemu_get_cpu(cpuid), true)){
+            monitor_printf(mon, "CPU %d: processor trace disabled!\n", cpuid);
+        }
+        else{
+            monitor_printf(mon, "CPU %d: failed...\n", cpuid);
+        }
+    }
+}
+static inline void hmp_pt_enable_ip_filtering_cpu(Monitor *mon, int cpuid, int addrn, uint64_t addr_a, uint64_t addr_b){
+#ifdef CONFIG_REDQUEEN
+        if(!pt_enable_ip_filtering(qemu_get_cpu(cpuid), addrn, addr_a, addr_b, false, true)){
+#else
+        if(!pt_enable_ip_filtering(qemu_get_cpu(cpuid), addrn, addr_a, addr_b, true)){    
+#endif
+        monitor_printf(mon, "CPU %d: ip filtering enabled...\n", cpuid);
+        }
+        else{
+            monitor_printf(mon, "CPU %d: failed...\n", cpuid);
+        }
+}
+static inline void hmp_pt_status_cpu(Monitor *mon, int cpuid){
+        int i;
+        CPUState *cpu = qemu_get_cpu(cpuid);
+        monitor_printf(mon, "Processor Trace Status (CPU %d)\n", cpuid);
+        if (cpu->pt_enabled){
+                monitor_printf(mon, "\tenabled:\t\tyes\n");
+        }
+        else{
+                monitor_printf(mon, "\tenabled:\t\tno\n");
+        }
+        monitor_printf(mon, "\tToPA overflows:\t\t%u\n", cpu->overflow_counter);
+        monitor_printf(mon, "\ttrace data size:\t%lu (%luMB)\n", cpu->trace_size, cpu->trace_size >> 20);
+        for(i = 0; i < 4; i++){
+                if (cpu->pt_ip_filter_enabled[i]){
+                        switch(i){
+                                case 0:
+                                case 1:
+                                case 2:
+                                case 3:
+                                        monitor_printf(mon, "\tpt_ip_filter_%d_a:\t0x%016lx\n", i, cpu->pt_ip_filter_a[i]);
+                                        monitor_printf(mon, "\tpt_ip_filter_%d_b:\t0x%016lx\n", i, cpu->pt_ip_filter_b[i]);
+                                        break;
+                        }
+                }
+        }
+}
+void hmp_pt_enable(Monitor *mon, const QDict *qdict)
+{
+        int cpuid = hmp_pt_get_cpuid(mon, qdict);
+        if (!hmp_pt_check_kvm(mon) || (cpuid < 0))
+                return;
+        hmp_pt_enable_cpu(mon, cpuid);
+}
+void hmp_pt_disable(Monitor *mon, const QDict *qdict)
+{
+        int cpuid = hmp_pt_get_cpuid(mon, qdict);
+        if (!hmp_pt_check_kvm(mon) || (cpuid < 0))
+                return;
+        hmp_pt_disable_cpu(mon, cpuid);
+}
+void hmp_pt_enable_all(Monitor *mon, const QDict *qdict)
+{
+        int cpuid;
+        CpuInfoFastList *cpu_list, *cpu;
+        if (!hmp_pt_check_kvm(mon))
+                return;
+        cpu_list = qmp_query_cpus_fast(NULL);
+        for (cpu = cpu_list; cpu; cpu = cpu->next) {
+                cpuid = cpu->value->cpu_index;    
+                if (!(monitor_set_cpu(mon, cpuid) < 0))
+                        hmp_pt_enable_cpu(mon, cpuid);
+        }
+        qapi_free_CpuInfoFastList(cpu_list);
+}
+void hmp_pt_disable_all(Monitor *mon, const QDict *qdict)
+{
+        int cpuid;
+        CpuInfoFastList *cpu_list, *cpu;
+        if (!hmp_pt_check_kvm(mon))
+                return;
+        cpu_list = qmp_query_cpus_fast(NULL);
+        for (cpu = cpu_list; cpu; cpu = cpu->next) {
+                cpuid = cpu->value->cpu_index;    
+                if (!(monitor_set_cpu(mon, cpuid) < 0))
+                        hmp_pt_disable_cpu(mon, cpuid);
+        }
+        qapi_free_CpuInfoFastList(cpu_list);
+}
+void hmp_pt_status(Monitor *mon, const QDict *qdict)
+{
+        int cpuid = hmp_pt_get_cpuid(mon, qdict);
+        if (!hmp_pt_check_kvm(mon) || (cpuid < 0))
+                return;
+        hmp_pt_status_cpu(mon, cpuid);
+}
+void hmp_pt_status_all(Monitor *mon, const QDict *qdict)
+{
+        int cpuid;
+        CpuInfoFastList *cpu_list, *cpu;
+        if (!hmp_pt_check_kvm(mon))
+                return;
+        cpu_list = qmp_query_cpus_fast(NULL);
+        for (cpu = cpu_list; cpu; cpu = cpu->next) {
+                cpuid = cpu->value->cpu_index;    
+                if (!(monitor_set_cpu(mon, cpuid) < 0))
+                        hmp_pt_status_cpu(mon, cpuid);
+        }
+        qapi_free_CpuInfoFastList(cpu_list);
+}
+void hmp_pt_ip_filtering(Monitor *mon, const QDict *qdict)
+{
+        int cpuid, addrn;    
+        uint64_t addr_a;
+        uint64_t addr_b;
+        cpuid = hmp_pt_get_cpuid(mon, qdict);
+        if (!hmp_pt_check_kvm(mon) || (cpuid < 0))
+                return;
+        addrn = qdict_get_int(qdict, "addrn");
+        if(addrn < 0 || addrn >= 4){
+                monitor_printf(mon, "invalid addrn value (0-3)\n");
+                return;
+        }
+        addr_a = qdict_get_int(qdict, "addr_a");
+        addr_b = qdict_get_int(qdict, "addr_b");
+        hmp_pt_enable_ip_filtering_cpu(mon, cpuid, addrn, addr_a, addr_b);
+}
+void hmp_pt_set_file(Monitor *mon, const QDict *qdict){
+        int cpuid;
+        CpuInfoFastList *cpu_list, *cpu;
+        const char *filename = qdict_get_str(qdict, "file");
+        char* new_filename;
+        if (!hmp_pt_check_kvm(mon))
+                return;
+        new_filename = malloc(sizeof(char)*(strlen(filename)+12));
+        cpu_list = qmp_query_cpus_fast(NULL);
+        for (cpu = cpu_list; cpu; cpu = cpu->next) {
+                cpuid = cpu->value->cpu_index;    
+                if (!(monitor_set_cpu(mon, cpuid) < 0)){
+                        sprintf(new_filename, "%s_%d", filename, cpuid);
+                        qemu_get_cpu(cpuid)->pt_target_file = fopen(new_filename, "wb");
+                }
+        }
+        free(new_filename);
+        qapi_free_CpuInfoFastList(cpu_list);
+}
+#endif
 void hmp_handle_error(Monitor *mon, Error *err)
 {
     if (err) {
diff --git a/monitor/misc.c b/monitor/misc.c
index 55f374405..b44a8a636 100644
--- a/monitor/misc.c
+++ b/monitor/misc.c
@@ -114,6 +114,9 @@ static QemuMutex mon_fdsets_lock;
 static QLIST_HEAD(, MonFdset) mon_fdsets;
 
 static HMPCommand hmp_info_cmds[];
+#if defined(CONFIG_PROCESSOR_TRACE)
+static HMPCommand hmp_pt_cmds[];
+#endif
 
 char *qmp_human_monitor_command(const char *command_line, bool has_cpu_index,
                                 int64_t cpu_index, Error **errp)
@@ -1463,6 +1466,13 @@ static HMPCommand hmp_info_cmds[] = {
     { NULL, NULL, },
 };
 
+#if defined(CONFIG_PROCESSOR_TRACE)
+static HMPCommand hmp_pt_cmds[] = {
+#include "hmp-commands-pt.h"
+    { NULL, NULL, },
+};
+#endif
+
 /* hmp_cmds and hmp_info_cmds would be sorted at runtime */
 HMPCommand hmp_cmds[] = {
 #include "hmp-commands.h"
diff --git a/pt.c b/pt.c
new file mode 100644
index 000000000..f7b1340b2
--- /dev/null
+++ b/pt.c
@@ -0,0 +1,476 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+
+#include "qemu/osdep.h"
+#include <linux/kvm.h>
+#include <sys/ioctl.h>
+#include <sys/mman.h>
+#include "qemu-common.h"
+#include "cpu.h"
+#include "pt.h"
+#include "pt/decoder.h"
+#include "exec/memory.h"
+#include "sysemu/kvm_int.h"
+#include "sysemu/kvm.h"
+#include "sysemu/cpus.h"
+#include "pt/hypercall.h"
+#include "pt/logger.h"
+#include "pt/memory_access.h"
+#include "pt/interface.h"
+#include "pt/debug.h"
+#include <libexplain/ioctl.h>
+
+#ifdef CONFIG_REDQUEEN
+#include "pt/redqueen.h"
+#include "pt/redqueen_patch.h"
+#include "pt/patcher.h"
+#endif
+
+extern uint32_t kafl_bitmap_size;
+uint8_t* bitmap = NULL;
+uint64_t last_ip = 0ULL;
+uint32_t written = 0;
+
+void pt_sync(void){
+	if(bitmap){
+		msync(bitmap, kafl_bitmap_size, MS_SYNC);
+	}
+}
+
+
+static inline int pt_cmd_hmp_context(CPUState *cpu, uint64_t cmd){
+	cpu->pt_ret = -1;
+	if(pt_hypercalls_enabled()){
+		QEMU_PT_ERROR(PT_PREFIX, "Error: HMP commands are ignored if kafl tracing mode is enabled (-kafl)!");
+	}
+	else{
+		cpu->pt_cmd = cmd;
+	}
+	return cpu->pt_ret;
+}
+
+static int pt_cmd(CPUState *cpu, uint64_t cmd, bool hmp_mode){
+	if (hmp_mode){
+		return pt_cmd_hmp_context(cpu, cmd);
+	}
+	else {
+		cpu->pt_cmd = cmd;
+		pt_pre_kvm_run(cpu);
+		return cpu->pt_ret;
+	}
+}
+
+static inline int pt_ioctl(int fd, unsigned long request, unsigned long arg){
+	if (!fd){
+		return -EINVAL;
+	}
+	return ioctl(fd, request, arg);
+}
+
+void pt_setup_bitmap(void* ptr){
+	bitmap = (uint8_t*)ptr;
+}
+
+void pt_reset_bitmap(void){
+	if(bitmap){
+		last_ip = 0ULL;
+		memset(bitmap, 0x00, kafl_bitmap_size);
+	}
+}
+
+static inline uint64_t mix_bits(uint64_t v) {
+  v ^= (v >> 31);
+  v *= 0x7fb5d329728ea185;
+  v ^= (v >> 27);
+  v *= 0x81dadef4bc2dd44d;
+  v ^= (v >> 33);
+  return v;
+}
+
+void pt_bitmap(uint64_t addr){
+
+	uint32_t transition_value = 0;
+	#ifdef SAMPLE_DECODED
+	sample_decoded(addr);
+	#endif
+	if(bitmap){		
+		printf("pt_bitmap...\n");
+		addr = mix_bits(addr);
+		transition_value = (addr ^ (last_ip >> 1)) & 0xffffff;
+		bitmap[transition_value & (kafl_bitmap_size-1)]++;
+	}
+	else {
+		printf("No bitmap...\n");
+	}
+	last_ip = addr; 
+}
+
+void pt_dump(CPUState *cpu, int bytes){
+#ifdef SAMPLE_RAW
+	sample_raw(cpu->pt_mmap, bytes);
+#endif
+#ifdef SAMPLE_RAW_SINGLE
+	sample_raw_single(cpu->pt_mmap, bytes);
+#endif
+		if (!written) {
+			written = 1;
+#ifdef SAMPLE_DECODED_DETAILED
+			init_sample_decoded_detailed();
+#endif
+		}
+
+	//pt_enable_ip_filtering(cpu, 0, 0xFFFFF802939E0000, 0xFFFFF80293C65000, true);
+	for(uint8_t i = 0; i < INTEL_PT_MAX_RANGES; i++){
+		if(cpu->pt_ip_filter_enabled[i]){
+#ifdef CONFIG_REDQUEEN	
+			if(!(cpu->redqueen_state[i] && ((redqueen_t*)(cpu->redqueen_state[i]))->intercept_mode)){
+#endif
+			/*if (cpu->pt_target_file){
+				fwrite(cpu->pt_mmap, sizeof(char), bytes, cpu->pt_target_file);
+			}*/
+			if (!cpu->intel_pt_run_trashed){
+				if(!decode_buffer(cpu->pt_decoder_state[i], cpu->pt_mmap, bytes, cpu)){
+					//cpu->intel_pt_run_trashed = true;
+				}
+			}
+			else {
+				printf("Intel PT Run Trashed!\n");
+			}
+#ifdef CONFIG_REDQUEEN			
+			}
+#endif
+		}
+	}
+	cpu->trace_size += bytes;
+}
+
+
+int pt_enable(CPUState *cpu, bool hmp_mode){
+#ifdef SAMPLE_RAW
+	init_sample_raw();
+#endif
+#ifdef SAMPLE_RAW_SINGLE
+	init_sample_raw_single(getpid());
+#endif
+#ifdef SAMPLE_DECODED
+	init_sample_decoded();
+#endif
+#ifdef SAMPLE_DECODED_DETAILED
+	init_sample_decoded_detailed();
+#endif
+	pt_reset_bitmap();
+	return pt_cmd(cpu, KVM_VMX_PT_ENABLE, hmp_mode);
+}
+	
+int pt_disable(CPUState *cpu, bool hmp_mode){
+	int r = 0;
+	r += pt_cmd(cpu, KVM_VMX_PT_DISABLE, hmp_mode);
+	for(uint8_t i = 0; i < INTEL_PT_MAX_RANGES; i++){
+		if(cpu->pt_ip_filter_enabled[i]){
+			pt_decoder_flush(cpu->pt_decoder_state[i]);
+		}
+	}
+
+	return r;
+}
+
+int pt_set_cr3(CPUState *cpu, uint64_t val, bool hmp_mode){
+	int r = 0;
+	
+	if (cpu->pt_enabled){
+		return -EINVAL;
+	}
+	/*
+	if (cpu->pt_c3_filter && cpu->pt_c3_filter != val){
+		QEMU_PT_DEBUG(PT_PREFIX, "Reconfigure CR3-Filtering!");
+		cpu->pt_c3_filter = val;
+		r += pt_cmd(cpu, KVM_VMX_PT_CONFIGURE_CR3, hmp_mode);
+		return r;
+	}
+	cpu->pt_c3_filter = val;
+	//r += pt_cmd(cpu, KVM_VMX_PT_CONFIGURE_CR3, hmp_mode);
+	*/
+	r += pt_cmd(cpu, KVM_VMX_PT_DISABLE_CR3, hmp_mode);
+	return r;
+}
+
+#ifdef CONFIG_REDQUEEN
+int pt_enable_ip_filtering(CPUState *cpu, uint8_t addrn, uint64_t ip_a, uint64_t ip_b, bool redqueen, bool hmp_mode){
+#else
+int pt_enable_ip_filtering(CPUState *cpu, uint8_t addrn, uint64_t ip_a, uint64_t ip_b, bool hmp_mode){
+#endif
+	int r = 0;
+
+	if(addrn > 3){
+		return -1;
+	}
+	
+	/*
+	if (!cpu->pt_enabled){
+		return -EINVAL;
+	}
+	*/
+		
+	if(ip_a > ip_b){
+		QEMU_PT_ERROR(PT_PREFIX, "Error (ip_a > ip_b) 0x%lx-0x%lx", ip_a, ip_b);
+		return -EINVAL;
+	}
+
+	if(cpu->pt_ip_filter_enabled[addrn]){
+		pt_disable_ip_filtering(cpu, addrn, hmp_mode);
+	}
+
+	QEMU_PT_DEBUG(PT_PREFIX, "Configuring new trace region (addr%d, 0x%lx-0x%lx)", addrn, ip_a, ip_b);
+	
+	switch(addrn){
+		case 0:
+		case 1:
+		case 2:
+		case 3:
+			cpu->pt_ip_filter_a[addrn] = ip_a;
+			cpu->pt_ip_filter_b[addrn] = ip_b;
+			r += pt_cmd(cpu, KVM_VMX_PT_CONFIGURE_ADDR0+addrn, hmp_mode);
+			r += pt_cmd(cpu, KVM_VMX_PT_ENABLE_ADDR0+addrn, hmp_mode);
+			printf("Enabling IP Filter...\n");
+			cpu->pt_ip_filter_enabled[addrn] = true;
+#ifdef CONFIG_REDQUEEN	
+			if(redqueen && !cpu->redqueen_state[addrn]){
+				cpu->redqueen_state[addrn] = new_rq_state(ip_a, ip_b, cpu);
+			}
+			cpu->pt_decoder_state[addrn] = pt_decoder_init(cpu, ip_a, ip_b, cpu->disassembler_word_width, &pt_bitmap, cpu->redqueen_state[addrn]);
+#else		
+			cpu->pt_decoder_state[addrn] = pt_decoder_init(cpu, ip_a, ip_b, cpu->disassembler_word_width, &pt_bitmap);
+#endif
+			break;
+		default:
+			r = -EINVAL;
+	}
+	return r;
+}
+
+int pt_disable_ip_filtering(CPUState *cpu, uint8_t addrn, bool hmp_mode){
+	int r = 0;
+	switch(addrn){
+		case 0:
+		case 1:
+		case 2:
+		case 3:
+			r = pt_cmd(cpu, KVM_VMX_PT_DISABLE_ADDR0+addrn, hmp_mode);
+			if(cpu->pt_ip_filter_enabled[addrn]){
+				cpu->pt_ip_filter_enabled[addrn] = false;
+#ifdef CONFIG_REDQUEEN
+				if(cpu->redqueen_state[addrn]){
+					destroy_rq_state(cpu->redqueen_state[addrn]);
+					cpu->redqueen_state[addrn] = NULL;
+				}
+#endif
+				pt_decoder_destroy(cpu->pt_decoder_state[addrn]);
+			}
+			break;
+		default:
+			r = -EINVAL;
+	}
+	return r;
+}
+
+void pt_kvm_init(CPUState *cpu){
+	int i;
+
+	cpu->pt_cmd = 0;
+	cpu->pt_arg = 0;
+	cpu->pt_enabled = false;
+	cpu->decoder_compile_init = false;
+	cpu->pt_fd = 0;
+	cpu->pt_features = 0;
+	cpu->ip_enabled = false;
+
+	for(i = 0; i < INTEL_PT_MAX_RANGES; i++){
+		cpu->pt_ip_filter_enabled[i] = false;
+		cpu->pt_ip_filter_a[i] = 0x0;
+		cpu->pt_ip_filter_b[i] = 0x0;
+		cpu->pt_decoder_state[i] = NULL;
+#ifdef CONFIG_REDQUEEN
+		cpu->redqueen_state[i]=NULL;
+#endif
+	}
+
+#ifdef CONFIG_REDQUEEN
+	cpu->redqueen_patch_state = patcher_new(cpu);
+	cpu->redqueen_enable_pending = false;
+	cpu->redqueen_disable_pending = false;
+	cpu->redqueen_instrumentation_mode = 0;
+	cpu->redqueen_update_blacklist = false;
+
+	cpu->patches_enable_pending = false;//TODO don't enable this
+	cpu->patches_disable_pending = false;
+#endif
+   	// setting the target's word with is critical to RQ operation
+	// Initialize as invalid, set by submit_CR3 or submit_mode hypercalls
+	cpu->disassembler_word_width = 64;
+
+	cpu->pt_c3_filter = 0;
+	cpu->pt_target_file = NULL;
+	cpu->overflow_counter = 0;
+	cpu->trace_size = 0;
+	cpu->reload_pending = false;
+	cpu->executing = false;
+	cpu->intel_pt_run_trashed = false;
+	
+
+	//bool debugging_code = 1;
+	//while (debugging_code) {
+	//	sleep(1);
+	//}
+}
+
+struct vmx_pt_filter_iprs {
+	__u64 a;
+	__u64 b;
+};
+
+pthread_mutex_t pt_dump_mutex = PTHREAD_MUTEX_INITIALIZER;
+
+void pt_pre_kvm_run(CPUState *cpu){
+	pthread_mutex_lock(&pt_dump_mutex);
+	int ret;
+	struct vmx_pt_filter_iprs filter_iprs;
+#ifdef CONFIG_REDQUEEN
+
+	if(cpu->patches_disable_pending){
+		QEMU_PT_DEBUG(REDQUEEN_PREFIX, "patches disable");
+		patcher_t* patcher = qemu_get_cpu(0)->redqueen_patch_state;
+		pt_disable_patches(patcher);
+		cpu->patches_disable_pending = false;
+	}
+
+	if(cpu->patches_enable_pending){
+		QEMU_PT_DEBUG(REDQUEEN_PREFIX, "patches enable");
+		patcher_t* patcher = qemu_get_cpu(0)->redqueen_patch_state;
+		pt_enable_patches(patcher);
+		cpu->patches_enable_pending = false;
+	}
+
+
+	if(cpu->redqueen_enable_pending){
+		QEMU_PT_DEBUG(REDQUEEN_PREFIX, "rq enable");
+		for(uint8_t i = 0; i < INTEL_PT_MAX_RANGES; i++){
+			if (cpu->redqueen_state[i]){
+				enable_rq_intercept_mode(cpu->redqueen_state[i]);
+			}
+		}
+		cpu->redqueen_enable_pending = false;
+		//qemu_cpu_kick_self();
+	}
+
+	if(cpu->redqueen_disable_pending){
+		QEMU_PT_DEBUG(REDQUEEN_PREFIX, "rq disable");
+		for(uint8_t i = 0; i < INTEL_PT_MAX_RANGES; i++){
+			if (cpu->redqueen_state[i]){
+				disable_rq_intercept_mode(cpu->redqueen_state[i]);
+			}
+		}
+		cpu->redqueen_disable_pending = false;
+		//qemu_cpu_kick_self();
+	}
+#endif
+	if (!cpu->pt_fd) {
+		cpu->pt_fd = kvm_vcpu_ioctl(cpu, KVM_VMX_PT_SETUP_FD, (unsigned long)0);
+		ret = ioctl(cpu->pt_fd, KVM_VMX_PT_GET_TOPA_SIZE, (unsigned long)0x0);
+		QEMU_PT_DEBUG(PT_PREFIX, "TOPA SIZE: %x\n", ret);
+		cpu->pt_mmap = mmap(0, ret, PROT_READ, MAP_SHARED, cpu->pt_fd, 0);
+	}
+	
+	if (cpu->pt_cmd){
+		switch(cpu->pt_cmd){
+			// Child partition context
+			case KVM_VMX_PT_ENABLE:
+				if (cpu->pt_fd){
+					/* dump for the very last time before enabling VMX_PT ... just in case */
+					ioctl(cpu->pt_fd, KVM_VMX_PT_CHECK_TOPA_OVERFLOW, (unsigned long)0);
+
+					if (!ioctl(cpu->pt_fd, cpu->pt_cmd, cpu->pt_arg)){
+						cpu->pt_enabled = true;
+					}
+				}
+				break;
+			// Child partition context
+			case KVM_VMX_PT_DISABLE:
+				if (cpu->pt_fd){
+					ret = ioctl(cpu->pt_fd, cpu->pt_cmd, cpu->pt_arg);
+					if (ret > 0){
+						QEMU_PT_DEBUG(PT_PREFIX, "KVM_VMX_PT_DISABLE %d", ret);
+						pt_dump(cpu, ret);
+						cpu->pt_enabled = false;
+					}
+					else {
+						QEMU_PT_DEBUG(PT_PREFIX, "KVM_VMX_PT_DISABLE 0");
+					}
+				}
+				break;
+			
+			/* ip filtering configuration */	
+			case KVM_VMX_PT_CONFIGURE_ADDR0:
+			case KVM_VMX_PT_CONFIGURE_ADDR1:
+			case KVM_VMX_PT_CONFIGURE_ADDR2:
+			case KVM_VMX_PT_CONFIGURE_ADDR3:
+				filter_iprs.a = cpu->pt_ip_filter_a[(cpu->pt_cmd)-KVM_VMX_PT_CONFIGURE_ADDR0];
+	   			filter_iprs.b = cpu->pt_ip_filter_b[(cpu->pt_cmd)-KVM_VMX_PT_CONFIGURE_ADDR0];
+				ret = pt_ioctl(cpu->pt_fd, cpu->pt_cmd, (unsigned long)&filter_iprs);
+				break;
+			case KVM_VMX_PT_ENABLE_ADDR0:
+			case KVM_VMX_PT_ENABLE_ADDR1:
+			case KVM_VMX_PT_ENABLE_ADDR2:
+			case KVM_VMX_PT_ENABLE_ADDR3:
+				ret = pt_ioctl(cpu->pt_fd, cpu->pt_cmd, (unsigned long)0);
+				break;
+			case KVM_VMX_PT_CONFIGURE_CR3:
+				ret = pt_ioctl(cpu->pt_fd, cpu->pt_cmd, cpu->pt_c3_filter);
+				break;
+			case KVM_VMX_PT_ENABLE_CR3:
+				ret = pt_ioctl(cpu->pt_fd, cpu->pt_cmd, (unsigned long)0);
+				break;
+			default:
+				if (cpu->pt_fd){
+					ioctl(cpu->pt_fd, cpu->pt_cmd, cpu->pt_arg);  
+				}
+				break;
+			}
+		cpu->pt_cmd = 0;
+		cpu->pt_ret = 0;
+	}
+	pthread_mutex_unlock(&pt_dump_mutex);
+}
+
+void pt_handle_overflow(CPUState *cpu){
+	pthread_mutex_lock(&pt_dump_mutex);
+	//printf("%s\n", __func__);
+	int overflow = ioctl(cpu->pt_fd, KVM_VMX_PT_CHECK_TOPA_OVERFLOW, (unsigned long)0);
+	if (overflow > 0){
+		cpu->overflow_counter++;
+		if(cpu->intel_pt_run_trashed){
+			//fprintf(stderr, "KAFL_PROTO_PT_TRASHED\n"); 
+			cpu->intel_pt_run_trashed = false;
+		} 
+		if (cpu->pt_enabled) {
+			pt_dump(cpu, overflow);
+		}
+		//else {
+		//	printf("PT is not enabled...\n");
+		//}
+	} 
+
+	pthread_mutex_unlock(&pt_dump_mutex);
+}
+
+void pt_post_kvm_run(CPUState *cpu){
+	//synchronization_lock(cpu);
+	pt_handle_overflow(cpu);
+	//synchronization_unlock();
+}
diff --git a/pt.h b/pt.h
new file mode 100644
index 000000000..110633e16
--- /dev/null
+++ b/pt.h
@@ -0,0 +1,35 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+#ifndef PT_H
+#define PT_H
+
+
+void pt_sync(void);
+void pt_reset_bitmap(void);
+void pt_setup_bitmap(void* ptr);
+
+int pt_enable(CPUState *cpu, bool hmp_mode);
+int pt_disable(CPUState *cpu, bool hmp_mode);
+#ifdef CONFIG_REDQUEEN
+int pt_enable_ip_filtering(CPUState *cpu, uint8_t addrn, uint64_t ip_a, uint64_t ip_b, bool redqueen, bool hmp_mode);
+#else
+int pt_enable_ip_filtering(CPUState *cpu, uint8_t addrn, uint64_t ip_a, uint64_t ip_b, bool hmp_mode);
+#endif
+int pt_disable_ip_filtering(CPUState *cpu, uint8_t addrn, bool hmp_mode);
+int pt_set_cr3(CPUState *cpu, uint64_t val, bool hmp_mode);
+
+void pt_kvm_init(CPUState *cpu);
+void pt_pre_kvm_run(CPUState *cpu);
+void pt_post_kvm_run(CPUState *cpu);
+
+void pt_handle_overflow(CPUState *cpu);
+void pt_dump(CPUState *cpu, int bytes);
+void pt_bitmap(uint64_t addr);
+#endif
diff --git a/pt/Makefile.objs b/pt/Makefile.objs
new file mode 100644
index 000000000..5cf53f3ea
--- /dev/null
+++ b/pt/Makefile.objs
@@ -0,0 +1,2 @@
+obj-y += decoder.o disassembler.o tnt_cache.o hypercall.o filter.o logger.o memory_access.o interface.o printk.o synchronization.o asm_decoder.o
+obj-$(CONFIG_REDQUEEN) += redqueen.o patcher.o redqueen_patch.o file_helper.o
diff --git a/pt/asm_decoder.c b/pt/asm_decoder.c
new file mode 100644
index 000000000..59167afa1
--- /dev/null
+++ b/pt/asm_decoder.c
@@ -0,0 +1,226 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+
+
+#ifndef _GNU_SOURCE
+#define _GNU_SOURCE
+#endif
+#include <sys/types.h>
+#include <regex.h>
+#include <stdio.h>
+#include <string.h>
+#include <stdlib.h>
+#include <stdint.h>
+#include <stdbool.h>
+#include <assert.h>
+#include "asm_decoder.h"
+
+static regex_t* op_regex_reg=NULL;
+static regex_t* op_regex_const=NULL;
+static regex_t* op_regex_mem=NULL;
+static regex_t* op_regex_mem_const=NULL;
+
+void asm_decoder_compile(void){
+	//const char *begin,*end;
+	const char *integer = "(0x[a-f0-9]+|[0-9]+)";
+	const char *reg = "(r[abcd]x|r[isb]p|r[sd]i|r[89]|r1[012345]|"
+	"e[abcd]x|e[isb]p|e[sd]i|r[89]d|r1[012345]d|"
+	"[abcd]x|[isb]p|[sd]i|r[89]w|r1[012345]w|"
+	"[abcd]l|[sb]pl|[sd]il|r[89]b|r1[012345]b|"
+	"[abcd]h|[sb]ph|[sd]ih|xmm[0-7])";
+
+	const char *ptr= "(byte ptr|word ptr|dword ptr|qword ptr|xmmword ptr)";
+	const char *segreg = "(ss|fs|ds|gs|cs|es)";
+	const char *scale ="(1|2|4|8)";
+
+	char *str_displace = NULL;
+	char *str_displace_const = NULL;
+	const char* str_const = "^(-)?(0x[a-f0-9]+|[0-9]+)$";
+	char *str_reg = NULL;
+	assert(-1 != asprintf(&str_displace,  "^%s (%s:)?\\[(%s ([+\\-]) )?%s(\\*%s)?( ([+\\-]) %s)?\\]$",ptr, segreg, reg, reg, scale, integer));
+	assert(-1 != asprintf(&str_displace_const, "^%s (%s:)?\\[%s\\]$", ptr, segreg, integer));
+	assert(-1 != asprintf(&str_reg, "^%s$", reg ));
+
+	op_regex_reg = malloc(sizeof(regex_t));
+	op_regex_const = malloc(sizeof(regex_t));
+	op_regex_mem_const = malloc(sizeof(regex_t));
+	op_regex_mem = malloc(sizeof(regex_t));
+
+	assert(!regcomp(op_regex_reg, str_reg, REG_EXTENDED));
+	assert(!regcomp(op_regex_const, str_const, REG_EXTENDED));
+	assert(!regcomp(op_regex_mem, str_displace, REG_EXTENDED));
+	assert(!regcomp(op_regex_mem_const, str_displace_const, REG_EXTENDED));
+
+	free(str_reg);
+	free(str_displace);
+	free(str_displace_const);
+}
+
+void asm_decoder_print_op(asm_operand_t* op){
+	if(op->ptr_size){
+		printf("%d %s:[%s + %s*%d + 0x%lx]\n", op->ptr_size, op->segment, op->base, op->index, op->scale, op->offset);
+		return;
+	}
+	if(op->base){
+		assert(!op->index && !op->offset);
+		printf("%s\n",op->base);
+		return;
+	} 
+	assert(!op->index && !op->base && !op->segment);
+	printf("0x%lx\n",op->offset);
+	return;
+}
+
+#define NMATCHES 24
+
+static bool has_match(regmatch_t* matches,size_t i){
+	return matches[i].rm_so >= 0;
+}
+static char *extract_match_str(char* str, regmatch_t* matches, size_t i){
+	if(has_match(matches, i)){
+		return strndup(str+matches[i].rm_so, matches[i].rm_eo-matches[i].rm_so);
+	} 
+	return NULL;
+}
+
+static char extract_match_char(char* str, regmatch_t* matches, size_t i, char defaultc){
+	if(has_match(matches, i)){
+		return str[matches[i].rm_so];
+	} 
+	return defaultc;
+}
+
+static uint64_t extract_match_u64(char* str, regmatch_t* matches, size_t i, uint64_t defaulti){
+	if(matches[i].rm_so >= 0){
+		return strtoull(str+matches[i].rm_so,0,0);
+	}
+	return defaulti;
+}
+
+static uint8_t ptr_size(char desc){
+		switch(desc){
+			case 'b' : return 1;
+			case 'w' : return 2;
+			case 'd' : return 4;
+			case 'q' : return 8;
+			case 'x' : return 16;
+			default: 
+			printf("failed to parse pointer type %c",desc);
+			assert(false);
+		}
+}
+
+//mutates opstr
+void asm_decoder_parse_op(char* opstr, asm_operand_t* op){
+	regmatch_t matches[NMATCHES] = {0};
+	op->was_present = true;
+	if( !regexec(op_regex_const, opstr, NMATCHES, &matches[0], 0) ){
+		op->offset = extract_match_u64(opstr, matches, 2, 0);
+		//printf("Matches %s const pattern %lx\n", opstr, op->offset);
+		if( has_match(matches,1) ) {
+			op->offset = -op->offset;
+		}
+	}else if (!regexec(op_regex_reg, opstr, NMATCHES, &matches[0], 0) ){
+		//printf("Matches %s reg pattern\n", opstr);
+		op->base = extract_match_str(opstr,matches,1);
+	}else if (!regexec(op_regex_mem, opstr, NMATCHES, &matches[0], 0) ){
+		//printf("Matches %s mem index pattern\n", opstr);
+		op->ptr_size = ptr_size(extract_match_char(opstr, matches, 1,'\0'));
+		op->segment = extract_match_str(opstr, matches, 3);
+		op->base = extract_match_str(opstr, matches, 5);
+		op->index = extract_match_str(opstr, matches, 7);
+		op->offset = extract_match_u64(opstr, matches, 12, 0);
+		op->scale = extract_match_u64(opstr,matches,9, 1);
+		if( extract_match_char(opstr,matches, 11, '+')=='-' ){
+			op->offset = -op->offset;
+		}
+	}else if (!regexec(op_regex_mem_const, opstr, NMATCHES, &matches[0], 0) ){
+		//printf("Matches %s mem wo index pattern\n", opstr);
+		//for(int j=0; j < NMATCHES; j++){
+		//	if(matches[j].rm_so >= 0){
+		//		printf("offset: %d (%d..%d) %s\n",j, matches[j].rm_so, matches[j].rm_eo, extract_match_str(opstr,matches,j));
+		//	}
+		//}
+		op->ptr_size = ptr_size(extract_match_char(opstr, matches, 1,'\0'));
+		op->segment = extract_match_str(opstr, matches, 3);
+		op->offset = extract_match_u64(opstr, matches, 4, 0);
+	}else {
+		fprintf( stderr,"failed to match opstr %s\n",opstr);
+		assert(false);
+	}
+}
+
+
+static bool cmp_strings(char* a, char*b ){
+	if(a == b){return true;}
+	if(a != NULL && b != NULL){return strcmp(a,b)==0;}
+	return false;
+}
+
+bool asm_decoder_op_eql(asm_operand_t* op1, asm_operand_t* op2){
+	if(op1->was_present != op2->was_present) return false;
+	if(op1->offset != op2->offset) return false;
+	if(op1->ptr_size != op2->ptr_size) return false;
+	if(!cmp_strings(op1->base, op2->base)) return false;
+	if(!cmp_strings(op1->index, op2->index)) return false;
+	if(!cmp_strings(op1->segment, op2->segment)) return false;
+	return true;
+}
+
+void asm_decoder_clear(asm_operand_t* op){
+	if(op->base) {free(op->base);}
+	if(op->index) {free(op->index);}
+	if(op->segment) {free(op->segment);}
+	op->base = NULL;
+	op->index = NULL;
+	op->segment = NULL;
+	op->was_present = false;
+	op->offset = 0;
+	op->ptr_size=0;
+}
+
+bool asm_decoder_is_imm(asm_operand_t* op){
+	return !op->base && !op->ptr_size;
+}
+
+/*
+int main(int argc, char* argv[])
+{
+	char* tests[] = {
+	"byte ptr [0x24ac8057a55c8dbd]",
+	"al",
+	"0x123",
+	"byte ptr [rcx + rbp*2]",
+	"dword ptr fs:[rax]",
+	"byte ptr ds:[0x23]",
+	"byte ptr [rbx - 0x51419c2c]",
+	"dword ptr [rdx + rbp*2 - 0x74]",
+	"dword ptr [rcx + rbx*4]",
+	"dword ptr [rbp + 0x46]",
+	"qword ptr [rip - 0x4fb843b2]",
+	"byte ptr [rdi]",
+	"-0x1ba6",
+	"byte ptr ss:[rdi]",
+	"byte ptr [rdi*4]",
+	"byte ptr [rdi*4 + 0x123]",
+	NULL};
+
+	compile();
+	for(int i = 0; tests[i]; i++){
+		asm_operand_t op = {0};
+		printf("\n");
+		parse_op(tests[i], &op);
+		print_op(&op);
+	}
+
+
+	return 0;
+}
+*/
diff --git a/pt/asm_decoder.h b/pt/asm_decoder.h
new file mode 100644
index 000000000..58ec2cdaf
--- /dev/null
+++ b/pt/asm_decoder.h
@@ -0,0 +1,32 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+
+#pragma once
+
+typedef struct asm_operand_s{
+	char* base;
+	char* index;
+	char* segment;
+	uint64_t offset;
+	uint8_t ptr_size;
+	uint8_t scale;
+	bool was_present;
+} asm_operand_t;
+
+
+void asm_decoder_compile(void);
+void asm_decoder_parse_op(char* opstr, asm_operand_t* op);
+
+void asm_decoder_print_op(asm_operand_t* op);
+
+bool asm_decoder_is_imm(asm_operand_t* op);
+void asm_decoder_clear(asm_operand_t* op);
+
+bool asm_decoder_op_eql(asm_operand_t* op1, asm_operand_t* op2);
diff --git a/pt/cfg.h b/pt/cfg.h
new file mode 100644
index 000000000..f7539a9a7
--- /dev/null
+++ b/pt/cfg.h
@@ -0,0 +1,80 @@
+/*
+Copyright (c) 2020 Sergej Schumilo, Cornelius Aschermann
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
+*/
+
+#pragma once
+#define _GNU_SOURCE
+#include <stdint.h>
+#include "khash.h"
+#include <stdlib.h>
+
+KHASH_MAP_INIT_INT(ADDR0, uint64_t)
+
+typedef enum cofi_types{
+	COFI_TYPE_CONDITIONAL_BRANCH, 
+	COFI_TYPE_UNCONDITIONAL_DIRECT_BRANCH, 
+	COFI_TYPE_INDIRECT_BRANCH, 
+	COFI_TYPE_NEAR_RET, 
+	COFI_TYPE_FAR_TRANSFERS,
+	NO_COFI_TYPE, //COFI_FALLTHROUGH_BASIC_BLOCK
+	OUT_OF_BOUNDS,
+	INFINITE_LOOP,
+	PAGE_CACHE_FAILED,
+} cofi_type;
+
+typedef uint32_t  node_id_t; 
+
+typedef struct cfg_branch_s {
+    node_id_t node_id;
+    uint32_t bitmap_id;
+} cfg_branch_t;
+
+#define NODE_PAGE_FAULT 0x0 //NODE_PAGE_FAULT is used to indicate that disassembly failed due to missing memory
+#define NODE_OOB 0x1 //NODE_OOB is used to indicate that disassembly failed to to trace area OOB
+#define NODE_NOT_DEFINED 0xffffffff
+
+typedef struct disassembler_cfg_s{
+
+	cfg_branch_t* br1;
+	cfg_branch_t* br2;
+	uint64_t* base_addr;
+    uint64_t* cofi_addr;
+    uint64_t* br1_addr;
+    uint64_t* br2_addr;
+    cofi_type* type;
+
+    uint32_t max_size;
+    uint32_t next_node_id;
+    uint32_t next_bitmap_id;
+    khash_t(ADDR0) *ip_to_node_id;
+} disassembler_cfg_t;
+
+void                disassembler_cfg_init(disassembler_cfg_t* res, uint32_t size);
+void                disassembler_cfg_destroy(disassembler_cfg_t* self);
+void                disassembler_cfg_inspect(disassembler_cfg_t* self, node_id_t nid);
+void                disassembler_cfg_resize(disassembler_cfg_t* self);
+uint32_t            disassembler_cfg_get_node_id(disassembler_cfg_t* self, uint64_t ip);
+node_id_t           disassembler_cfg_add_node(disassembler_cfg_t* self, uint64_t base_ip, uint64_t cofi_ip, cofi_type type);
+void                disassembler_cfg_add_br1_addr(disassembler_cfg_t* self, node_id_t node, uint64_t target);
+void                disassembler_cfg_add_br1_nid(disassembler_cfg_t* self, node_id_t node, node_id_t target_nid);
+void                disassembler_cfg_add_br2_addr(disassembler_cfg_t* self, node_id_t node, uint64_t target);
+void                disassembler_cfg_add_br2_nid(disassembler_cfg_t* self, node_id_t node, node_id_t target_nid);
+node_id_t           disassembler_cfg_prefix_node(disassembler_cfg_t* self, uint64_t base_address, node_id_t old_node);
\ No newline at end of file
diff --git a/pt/debug.h b/pt/debug.h
new file mode 100644
index 000000000..c17744bcd
--- /dev/null
+++ b/pt/debug.h
@@ -0,0 +1,36 @@
+/* 
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later 
+ */
+
+
+
+#pragma once
+
+#include "qemu/osdep.h"
+#include "qemu-common.h"
+#include "qemu/log.h"
+
+#define QEMU_PT_PREFIX		"[QEMU-PT] "
+#define CORE_PREFIX			"Core:  "
+#define MEM_PREFIX			"Mem:   "
+#define RELOAD_PREFIX		"Reload:"
+#define PT_PREFIX			"PT:    "
+#define INTERFACE_PREFIX	"Iface: "
+#define REDQUEEN_PREFIX		"Redq.: "
+#define DISASM_PREFIX		"Diasm: "
+
+#define COLOR	"\033[1;35m"
+#define ENDC	"\033[0m"
+
+/* _PRINTF is the standard logging enabled with -D */
+/* _DEBUG is activated with -d kafl cmdline */
+/* _ERROR is printed to stdout (or logged if logging is enabled) */
+#define QEMU_PT_PRINTF(PREFIX, format, ...) qemu_log(QEMU_PT_PREFIX PREFIX format "\n", ##__VA_ARGS__)
+#define QEMU_PT_DEBUG(PREFIX, format, ...)  qemu_log_mask(LOG_KAFL, QEMU_PT_PREFIX PREFIX format "\n", ##__VA_ARGS__)
+//#define QEMU_PT_DEBUG(PREFIX, format, ...) qemu_log_mask(LOG_KAFL, PREFIX "(%s#:%d)\t"format, __BASE_FILE__, __LINE__, ##__VA_ARGS__)
+#define QEMU_PT_ERROR(PREFIX, format, ...)  printf(QEMU_PT_PREFIX PREFIX format "\n", ##__VA_ARGS__)
diff --git a/pt/decoder.c b/pt/decoder.c
new file mode 100644
index 000000000..cff1ada8c
--- /dev/null
+++ b/pt/decoder.c
@@ -0,0 +1,738 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later 
+ *
+ *
+ * Note:
+ *
+ * This Intel PT software decoder is partially inspired and based on
+ * Andi Kleen's fastdecode.c (simple-pt).
+ * See: https://github.com/andikleen/simple-pt/blob/master/fastdecode.c
+ *
+ * Simple PT dumper
+ *
+ * Copyright (c) 2015, Intel Corporation
+ * Author: Andi Kleen
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright notice,
+ * this list of conditions and the following disclaimer.
+ *
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in the
+ * documentation and/or other materials provided with the distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+ * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
+ * COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,
+ * INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
+ * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
+ * STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED
+ * OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ */
+
+#define _GNU_SOURCE 1
+#include "pt/decoder.h"
+
+#define LEFT(x) ((end - p) >= (x))
+#define BIT(x) (1U << (x))
+#define out_of_bounds(self, addr) ((addr < self->min_addr) | (addr > self->max_addr))
+
+#define SAMPLE_DECODED_DETAILED
+#define BENCHMARK 				1
+
+#define PT_PKT_GENERIC_LEN		2
+#define PT_PKT_GENERIC_BYTE0	0b00000010
+
+#define PT_PKT_LTNT_LEN			8
+#define PT_PKT_LTNT_BYTE0		PT_PKT_GENERIC_BYTE0
+#define PT_PKT_LTNT_BYTE1		0b10100011
+
+#define PT_PKT_PIP_LEN			8
+#define PT_PKT_PIP_BYTE0		PT_PKT_GENERIC_BYTE0
+#define PT_PKT_PIP_BYTE1		0b01000011
+
+#define PT_PKT_CBR_LEN			4
+#define PT_PKT_CBR_BYTE0		PT_PKT_GENERIC_BYTE0
+#define PT_PKT_CBR_BYTE1		0b00000011
+
+#define PT_PKT_OVF_LEN			8
+#define PT_PKT_OVF_BYTE0		PT_PKT_GENERIC_BYTE0
+#define PT_PKT_OVF_BYTE1		0b11110011
+
+#define PT_PKT_PSB_LEN			16
+#define PT_PKT_PSB_BYTE0		PT_PKT_GENERIC_BYTE0
+#define PT_PKT_PSB_BYTE1		0b10000010
+
+#define PT_PKT_PSBEND_LEN		2
+#define PT_PKT_PSBEND_BYTE0		PT_PKT_GENERIC_BYTE0
+#define PT_PKT_PSBEND_BYTE1		0b00100011
+
+#define PT_PKT_MNT_LEN			11
+#define PT_PKT_MNT_BYTE0		PT_PKT_GENERIC_BYTE0
+#define PT_PKT_MNT_BYTE1		0b11000011
+#define PT_PKT_MNT_BYTE2		0b10001000
+
+#define PT_PKT_TMA_LEN			7
+#define PT_PKT_TMA_BYTE0		PT_PKT_GENERIC_BYTE0
+#define PT_PKT_TMA_BYTE1		0b01110011
+
+#define PT_PKT_VMCS_LEN			7
+#define PT_PKT_VMCS_BYTE0		PT_PKT_GENERIC_BYTE0
+#define PT_PKT_VMCS_BYTE1		0b11001000
+
+#define	PT_PKT_TS_LEN			2
+#define PT_PKT_TS_BYTE0			PT_PKT_GENERIC_BYTE0
+#define PT_PKT_TS_BYTE1			0b10000011
+
+#define PT_PKT_MODE_LEN			2
+#define PT_PKT_MODE_BYTE0		0b10011001
+
+#define PT_PKT_TIP_LEN			8
+#define PT_PKT_TIP_SHIFT		5
+#define PT_PKT_TIP_MASK			0b00000111
+#define PT_PKT_TIP_BYTE0		0b00001101
+#define PT_PKT_TIP_PGE_BYTE0	0b00010001
+#define PT_PKT_TIP_PGD_BYTE0	0b00000001
+#define PT_PKT_TIP_FUP_BYTE0	0b00011101
+
+
+#define TIP_VALUE_0				(0x0<<5)
+#define TIP_VALUE_1				(0x1<<5)
+#define TIP_VALUE_2				(0x2<<5)
+#define TIP_VALUE_3				(0x3<<5)
+#define TIP_VALUE_4				(0x4<<5)
+#define TIP_VALUE_5				(0x5<<5)
+#define TIP_VALUE_6				(0x6<<5)
+#define TIP_VALUE_7				(0x7<<5)
+
+//#define DEBUG
+
+static decoder_state_machine_t* decoder_statemachine_new(void);
+static void decoder_statemachine_reset(decoder_state_machine_t* self);
+
+static uint8_t psb[16] = {
+	0x02, 0x82, 0x02, 0x82, 0x02, 0x82, 0x02, 0x82,
+	0x02, 0x82, 0x02, 0x82, 0x02, 0x82, 0x02, 0x82
+};
+
+#ifdef DECODER_LOG
+static void flush_log(decoder_t* self){
+	self->log.tnt64 = 0;
+	self->log.tnt8 = 0;
+	self->log.pip = 0;
+	self->log.cbr = 0;
+	self->log.ts = 0;
+	self->log.ovf = 0;
+	self->log.psbc = 0;
+	self->log.psbend = 0;
+	self->log.mnt = 0;
+	self->log.tma = 0;
+	self->log.vmcs = 0;
+	self->log.pad = 0;
+	self->log.tip = 0;
+	self->log.tip_pge = 0;
+	self->log.tip_pgd = 0;
+	self->log.tip_fup = 0;
+	self->log.mode = 0;
+}
+#endif
+
+#ifdef CONFIG_REDQUEEN
+decoder_t* pt_decoder_init(CPUState *cpu, uint64_t min_addr, uint64_t max_addr, int disassembler_word_width, void (*handler)(uint64_t), redqueen_t *redqueen_state){
+#else
+decoder_t* pt_decoder_init(CPUState *cpu, uint64_t min_addr, uint64_t max_addr, int disassembler_word_width, void (*handler)(uint64_t)){
+#endif
+	decoder_t* res = malloc(sizeof(decoder_t));
+	res->min_addr = min_addr;
+	res->max_addr = max_addr;
+	res->handler = handler;
+
+	res->last_tip = 0;
+	res->fup_bind_pending = false;
+#ifdef DECODER_LOG
+	flush_log(res);
+#endif
+#ifdef CONFIG_REDQUEEN
+	res->disassembler_state = init_disassembler(cpu, min_addr, max_addr, disassembler_word_width, handler, redqueen_state);	
+#else
+	res->disassembler_state = init_disassembler(cpu, min_addr, max_addr, disassembler_word_width, handler);
+#endif
+	res->tnt_cache_state = tnt_cache_init();
+		/* ToDo: Free! */
+	res->decoder_state = decoder_statemachine_new();
+	res->decoder_state_result = malloc(sizeof(should_disasm_t));
+	res->decoder_state_result->start = 0;
+	res->decoder_state_result->valid = 0;
+	res->decoder_state_result->valid = false;
+
+	return res;
+}
+
+void pt_decoder_destroy(decoder_t* self){
+	if(self->tnt_cache_state){
+		destroy_disassembler(self->disassembler_state);
+		tnt_cache_destroy(self->tnt_cache_state);
+		self->tnt_cache_state = NULL;
+	}
+	free(self->decoder_state);
+	free(self->decoder_state_result);
+	free(self);
+}
+
+void pt_decoder_flush(decoder_t* self){
+	self->last_tip = 0;
+	self->fup_bind_pending = false;
+#ifdef DECODER_LOG
+	flush_log(self);
+#endif
+
+	tnt_cache_flush(self->tnt_cache_state);
+	disassembler_flush(self->disassembler_state);
+	decoder_statemachine_reset(self->decoder_state);
+	self->decoder_state_result->start = 0;
+	self->decoder_state_result->valid = 0;
+	self->decoder_state_result->valid = false;
+}	
+
+
+static inline void _set_disasm(should_disasm_t* self, uint64_t from, uint64_t to){
+	self->valid = true;
+	self->start = from;
+	self->end = to;
+}
+
+static decoder_state_machine_t* decoder_statemachine_new(void){
+	decoder_state_machine_t * res = (decoder_state_machine_t*)malloc(sizeof(decoder_state_machine_t));
+	res->state = TraceDisabled;
+	res->last_ip = 0;
+	return res;
+}
+
+static void decoder_statemachine_reset(decoder_state_machine_t* self){
+	self->state = TraceDisabled;
+	self->last_ip = 0;
+}
+
+static inline void decoder_handle_tip(decoder_state_machine_t *self, uint64_t addr, should_disasm_t *res){
+	//assert(self->state);
+	res->valid= false;
+	switch(self->state){
+		case TraceDisabled:
+			_set_disasm(res, addr, 0);
+			self->state = TraceEnabledWithLastIP;
+			self->last_ip = addr;
+			//assert(false);
+			break;
+		case TraceEnabledWithLastIP:
+			_set_disasm(res, self->last_ip, 0);
+			self->state = TraceEnabledWithLastIP;
+			self->last_ip = addr;
+			break;
+		case TraceEnabledWOLastIP:
+			self->state = TraceEnabledWithLastIP;
+			self->last_ip = addr;
+			break;
+	}
+}
+
+static inline void decoder_handle_pgd(decoder_state_machine_t *self, uint64_t addr, should_disasm_t *res){
+	//assert(self->state);
+	res->valid= false;
+	switch(self->state){
+		case TraceDisabled:
+			//assert(false);
+			break;
+		case TraceEnabledWithLastIP:
+			_set_disasm(res, self->last_ip, addr);
+			self->state = TraceDisabled;
+			self->last_ip = 0;
+			break;
+		case TraceEnabledWOLastIP:
+			self->state = TraceDisabled;
+			break;
+	}
+}
+
+static inline void decoder_handle_pge(decoder_state_machine_t *self, uint64_t addr, should_disasm_t *res){
+	//assert(self->state);
+	res->valid= false;
+	switch(self->state){
+		case TraceDisabled:
+			self->state = TraceEnabledWithLastIP;
+			self->last_ip = addr;
+			break;
+		case TraceEnabledWithLastIP:
+			//assert(false);
+			break;
+		case TraceEnabledWOLastIP:
+			self->state = TraceEnabledWithLastIP;
+			self->last_ip = addr;
+			break;
+	}
+}
+
+
+static inline void decoder_handle_fup(decoder_state_machine_t *self, uint64_t addr, should_disasm_t *res){
+	//assert(self->state);
+	res->valid= false;
+	switch(self->state){
+		case TraceDisabled:
+			self->state = TraceDisabled;
+			break;
+		case TraceEnabledWithLastIP:
+			_set_disasm(res, self->last_ip, addr);
+			self->state = TraceEnabledWOLastIP;
+			self->last_ip = 0;
+		      break;
+		case TraceEnabledWOLastIP:
+			//assert(false);
+			break;
+	}
+}
+
+static inline uint64_t get_ip_val(uint8_t **pp, uint64_t *last_ip){
+    const uint8_t type = (*(*pp)++ >> PT_PKT_TIP_SHIFT);
+    uint64_t aligned_last_ip, aligned_pp;
+    memcpy(&aligned_pp, *pp, sizeof(uint64_t));
+    memcpy(&aligned_last_ip, last_ip, sizeof(uint64_t));
+
+    if (unlikely(type == 0)) {
+        return 0;
+    }
+
+    const uint8_t new_bits = 0xFF40FF30302010FFull >> (type * 8);
+    if (unlikely(type == 3)) {
+        aligned_last_ip = (int64_t)(aligned_pp << 16) >> 16;
+    } else {
+        const uint8_t old_bits = sizeof(aligned_last_ip) * 8 - new_bits;   // always less than 64
+        const uint64_t new_mask = (~0ull) >> old_bits;
+        const uint64_t old_mask = ~new_mask;
+        aligned_last_ip = (aligned_last_ip & old_mask) | (aligned_pp & new_mask);
+    }
+    memcpy(last_ip, &aligned_last_ip, sizeof(uint64_t));
+    *pp += new_bits >> 3;
+    return aligned_last_ip;
+ }
+
+static inline uint64_t get_val(uint8_t **pp, uint8_t len){
+	uint8_t*p = *pp;
+	uint64_t v = 0;
+	uint8_t i;
+	uint8_t shift = 0;
+
+	for (i = 0; i < len; i++, shift += 8)
+		v |= ((uint64_t)(*p++)) << shift;
+	*pp = p;
+	return v;
+}
+
+static inline void disasm(decoder_t* self){
+	should_disasm_t* res = self->decoder_state_result;
+	if(res->valid){
+		printf("\n\ndisasm(%lx,%lx)\tTNT: %ld\n", res->start, res->end, count_tnt(self->tnt_cache_state));
+		WRITE_SAMPLE_DECODED_DETAILED("\n\ndisasm(%lx,%lx)\tTNT: %ld\n", res->start, res->end, count_tnt(self->tnt_cache_state));
+		trace_disassembler(self->disassembler_state, res->start, res->end, self->tnt_cache_state);
+	}
+}
+
+static void tip_handler(decoder_t* self, uint8_t** p, uint8_t** end){
+	if(unlikely(self->fup_bind_pending)){
+		self->fup_bind_pending = false;
+		decoder_handle_fup(self->decoder_state, self->last_tip, self->decoder_state_result);
+		disasm(self);
+	}
+
+	get_ip_val(p, &self->last_tip);
+	if (self->last_tip > self->max_addr || self->last_tip < self->min_addr) {
+		//printf("self->last_tip: 0x%lx\n", self->last_tip);
+		return;
+	}
+	WRITE_SAMPLE_DECODED_DETAILED("TIP    \t%lx\n", self->last_tip);
+	decoder_handle_tip(self->decoder_state, self->last_tip, self->decoder_state_result);
+	disasm(self);
+#ifdef DECODER_LOG
+	self->log.tip++;
+#endif
+}
+
+static void tip_pge_handler(decoder_t* self, uint8_t** p, uint8_t** end){
+	if(unlikely(self->fup_bind_pending)){
+		self->fup_bind_pending = false;
+		decoder_handle_fup(self->decoder_state, self->last_tip, self->decoder_state_result);
+		disasm(self);
+	}
+
+	get_ip_val(p, &self->last_tip);
+	if (self->last_tip > self->max_addr || self->last_tip < self->min_addr) {
+		//printf("self->last_tip: 0x%lx\n", self->last_tip);
+		return;
+	}
+	WRITE_SAMPLE_DECODED_DETAILED("PGE    \t%lx\n", self->last_tip);
+	decoder_handle_pge(self->decoder_state, self->last_tip, self->decoder_state_result);
+	disasm(self);
+#ifdef CONFIG_REDQUEEN
+	if(self->disassembler_state->redqueen_mode){
+	disassembler_flush(self->disassembler_state);
+		redqueen_trace_enabled(self->disassembler_state->redqueen_state, self->last_tip);
+	}
+#endif
+#ifdef DECODER_LOG
+	self->log.tip_pge++;
+#endif
+}
+
+static void tip_pgd_handler(decoder_t* self, uint8_t** p, uint8_t** end){
+	if(unlikely(self->fup_bind_pending)){
+		self->fup_bind_pending = false;
+		decoder_handle_fup(self->decoder_state, self->last_tip, self->decoder_state_result);
+		disasm(self);
+	}
+
+	get_ip_val(p, &self->last_tip);
+	if (self->last_tip > self->max_addr || self->last_tip < self->min_addr) {
+		//printf("self->last_tip: 0x%lx\n", self->last_tip);
+		return;
+	}
+	WRITE_SAMPLE_DECODED_DETAILED("PGD    \t%lx\n", self->last_tip);
+	decoder_handle_pgd(self->decoder_state, self->last_tip, self->decoder_state_result);
+	disasm(self);
+
+#ifdef CONFIG_REDQUEEN
+	if(self->disassembler_state->redqueen_mode){
+	//disassembler_flush(self->disassembler_state);
+		redqueen_trace_disabled(self->disassembler_state->redqueen_state, self->last_tip);
+	}
+#endif
+#ifdef DECODER_LOG
+	self->log.tip_pgd++;
+#endif
+}
+
+static void tip_fup_handler(decoder_t* self, uint8_t** p, uint8_t** end){
+	get_ip_val(p, &self->last_tip);
+	self->fup_bind_pending = true;
+	if (self->last_tip > self->max_addr || self->last_tip < self->min_addr) {
+		//printf("self->last_tip: 0x%lx\n", self->last_tip);
+		return;
+	}
+#ifdef DECODER_LOG
+	self->log.tip_fup++;
+#endif
+}
+
+static inline void pip_handler(decoder_t* self, uint8_t** p){
+	if(unlikely(self->fup_bind_pending)){
+		self->fup_bind_pending = false;
+	}
+#ifdef SAMPLE_DECODED_DETAILED
+	(*p) += PT_PKT_PIP_LEN-6;
+	WRITE_SAMPLE_DECODED_DETAILED("\tTNT %d (PGE %d)\n", count_tnt(self->tnt_cache_state), self->last_tip);
+#else
+	(*p) += PT_PKT_PIP_LEN;
+#endif
+#ifdef DECODER_LOG
+	self->log.pip++;
+#endif
+}
+
+ __attribute__((hot)) bool decode_buffer(decoder_t* self, uint8_t* map, size_t len, CPUState *cpu){
+	uint8_t *end = map + len;
+	
+	uint8_t *p;
+
+#ifdef DECODER_LOG
+	flush_log(self);
+#endif
+
+	//printf("Inside decode_buffer...\n");
+	for (p = map; p < end; ) {
+		p = memmem(p, end - p, psb, PT_PKT_PSB_LEN);
+		if (!p) {
+			p = end;
+			printf("decode_buffer: p=end!!!\n");
+			break;
+		}
+
+	
+		while (p < end) {			
+			
+			switch(p[0]){
+				case 0x00:
+					while(!(*(++p)) && p < end){}
+					#ifdef DECODER_LOG
+					self->log.pad++;
+					#endif
+					break;
+				case PT_PKT_MODE_BYTE0:
+					if(unlikely(self->fup_bind_pending)){
+						self->fup_bind_pending = false;
+					}
+					p += PT_PKT_MODE_LEN;
+					WRITE_SAMPLE_DECODED_DETAILED("MODE\n");
+					#ifdef DECODER_LOG
+					self->log.mode++;
+					#endif
+					break;
+				case (PT_PKT_TIP_BYTE0 + TIP_VALUE_0):
+				case (PT_PKT_TIP_BYTE0 + TIP_VALUE_1):
+				case (PT_PKT_TIP_BYTE0 + TIP_VALUE_2):
+				case (PT_PKT_TIP_BYTE0 + TIP_VALUE_3):
+				case (PT_PKT_TIP_BYTE0 + TIP_VALUE_4):
+				case (PT_PKT_TIP_BYTE0 + TIP_VALUE_5):
+				case (PT_PKT_TIP_BYTE0 + TIP_VALUE_6):
+				case (PT_PKT_TIP_BYTE0 + TIP_VALUE_7):
+					tip_handler(self, &p, &end);
+					break;
+				case (PT_PKT_TIP_PGE_BYTE0 + TIP_VALUE_0):
+				case (PT_PKT_TIP_PGE_BYTE0 + TIP_VALUE_1):
+				case (PT_PKT_TIP_PGE_BYTE0 + TIP_VALUE_2):
+				case (PT_PKT_TIP_PGE_BYTE0 + TIP_VALUE_3):
+				case (PT_PKT_TIP_PGE_BYTE0 + TIP_VALUE_4):
+				case (PT_PKT_TIP_PGE_BYTE0 + TIP_VALUE_5):
+				case (PT_PKT_TIP_PGE_BYTE0 + TIP_VALUE_6):
+				case (PT_PKT_TIP_PGE_BYTE0 + TIP_VALUE_7):
+					tip_pge_handler(self, &p, &end);
+					break;
+				case (PT_PKT_TIP_PGD_BYTE0 + TIP_VALUE_0):
+				case (PT_PKT_TIP_PGD_BYTE0 + TIP_VALUE_1):
+				case (PT_PKT_TIP_PGD_BYTE0 + TIP_VALUE_2):
+				case (PT_PKT_TIP_PGD_BYTE0 + TIP_VALUE_3):
+				case (PT_PKT_TIP_PGD_BYTE0 + TIP_VALUE_4):
+				case (PT_PKT_TIP_PGD_BYTE0 + TIP_VALUE_5):
+				case (PT_PKT_TIP_PGD_BYTE0 + TIP_VALUE_6):
+				case (PT_PKT_TIP_PGD_BYTE0 + TIP_VALUE_7):
+					tip_pgd_handler(self, &p, &end);
+					break;
+				case (PT_PKT_TIP_FUP_BYTE0 + TIP_VALUE_0):
+				case (PT_PKT_TIP_FUP_BYTE0 + TIP_VALUE_1):
+				case (PT_PKT_TIP_FUP_BYTE0 + TIP_VALUE_2):
+				case (PT_PKT_TIP_FUP_BYTE0 + TIP_VALUE_3):
+				case (PT_PKT_TIP_FUP_BYTE0 + TIP_VALUE_4):
+				case (PT_PKT_TIP_FUP_BYTE0 + TIP_VALUE_5):
+				case (PT_PKT_TIP_FUP_BYTE0 + TIP_VALUE_6):
+				case (PT_PKT_TIP_FUP_BYTE0 + TIP_VALUE_7):
+					tip_fup_handler(self, &p, &end);
+					break;
+				case PT_PKT_GENERIC_BYTE0:
+					switch(p[1]){
+						case PT_PKT_LTNT_BYTE1:
+							append_tnt_cache_ltnt(self->tnt_cache_state, (uint64_t)*p);
+							p += PT_PKT_LTNT_LEN;
+							#ifdef DECODER_LOG
+							self->log.tnt64++;
+							#endif
+							break;
+						case PT_PKT_PIP_BYTE1:
+							pip_handler(self, &p);
+							break;
+						case PT_PKT_CBR_BYTE1:
+							p += PT_PKT_CBR_LEN;
+							#ifdef DECODER_LOG
+							self->log.cbr++;
+							#endif
+							break;
+						case PT_PKT_VMCS_BYTE1:
+							if(unlikely(self->fup_bind_pending)){
+								self->fup_bind_pending = false;
+							}
+							WRITE_SAMPLE_DECODED_DETAILED("VMCS\n");
+							p += PT_PKT_VMCS_LEN;
+							#ifdef DECODER_LOG
+							self->log.vmcs++;
+							#endif
+							break;
+						case PT_PKT_OVF_BYTE1:
+						case PT_PKT_TS_BYTE1:
+							return false;
+							break;
+						case PT_PKT_PSBEND_BYTE1:
+							p += PT_PKT_PSBEND_LEN;
+							WRITE_SAMPLE_DECODED_DETAILED("PSBEND\n");
+							#ifdef DECODER_LOG
+							self->log.psbend++;
+							#endif
+							break;
+						case PT_PKT_PSB_BYTE1:
+							self->last_tip = 0;
+							p += PT_PKT_PSB_LEN;
+							WRITE_SAMPLE_DECODED_DETAILED("PSB\n");
+							#ifdef DECODER_LOG
+							self->log.psbc++;
+							#endif
+							break;
+						default:
+							pt_decoder_flush(self);
+							return true;
+							//assert(false);
+					}
+					break;
+				/* :( */
+				case PT_PKT_CBR_BYTE1:
+					p += PT_PKT_CBR_LEN;
+					#ifdef DECODER_LOG
+					self->log.cbr++;
+					#endif
+					break;
+				case 4:
+				case 6:
+				case 8:
+				case 10:
+				case 12:
+				case 14:
+				case 16:
+				case 18:
+				case 20:
+				case 22:
+				case 24:
+				case 26:
+				case 28:
+				case 30:
+				case 32:
+				case 34:
+				case 36:
+				case 38:
+				case 40:
+				case 42:
+				case 44:
+				case 46:
+				case 48:
+				case 50:
+				case 52:
+				case 54:
+				case 56:
+				case 58:
+				case 60:
+				case 62:
+				case 64:
+				case 66:
+				case 68:
+				case 70:
+				case 72:
+				case 74:
+				case 76:
+				case 78:
+				case 80:
+				case 82:
+				case 84:
+				case 86:
+				case 88:
+				case 90:
+				case 92:
+				case 94:
+				case 96:
+				case 98:
+				case 100:
+				case 102:
+				case 104:
+				case 106:
+				case 108:
+				case 110:
+				case 112:
+				case 114:
+				case 116:
+				case 118:
+				case 120:
+				case 122:
+				case 124:
+				case 126:
+				case 130:
+				case 128:
+				case 132:
+				case 134:
+				case 136:
+				case 138:
+				case 140:
+				case 142:
+				case 144:
+				case 146:
+				case 148:
+				case 150:
+				case 152:
+				case 154:
+				case 156:
+				case 158:
+				case 160:
+				case 162:
+				case 164:
+				case 166:
+				case 168:
+				case 170:
+				case 172:
+				case 174:
+				case 176:
+				case 178:
+				case 180:
+				case 182:
+				case 184:
+				case 186:
+				case 188:
+				case 190:
+				case 192:
+				case 194:
+				case 196:
+				case 198:
+				case 200:
+				case 202:
+				case 204:
+				case 206:
+				case 208:
+				case 210:
+				case 212:
+				case 214:
+				case 216:
+				case 218:
+				case 220:
+				case 222:
+				case 224:
+				case 226:
+				case 228:
+				case 230:
+				case 232:
+				case 234:
+				case 236:
+				case 238:
+				case 240:
+				case 242:
+				case 244:
+				case 246:
+				case 248:
+				case 250:
+				case 252:
+				case 254:
+					append_tnt_cache(self->tnt_cache_state, (uint64_t)(*p));
+					p++;
+					#ifdef DECODER_LOG
+					self->log.tnt8++;
+					#endif
+					break;
+				default:
+					//fprintf(stderr, "unkown packet : %x %x\n", *p, *(p+1));
+					pt_decoder_flush(self);
+					return true;
+					//assert(false);
+					}	
+		}
+	}
+#ifdef DEBUG
+	if(count_tnt(self->tnt_cache_state))
+		WRITE_SAMPLE_DECODED_DETAILED("\tTNT %d (PGE: %d)\n", count_tnt(self->tnt_cache_state), self->pge_enabled);
+	else{
+		WRITE_SAMPLE_DECODED_DETAILED("\tTNT %d (PGE: %d)\n", count_tnt(self->tnt_cache_state), self->pge_enabled);
+	}
+#endif
+	return true;
+}
diff --git a/pt/decoder.h b/pt/decoder.h
new file mode 100644
index 000000000..9d9d4dcb1
--- /dev/null
+++ b/pt/decoder.h
@@ -0,0 +1,98 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later 
+ */
+
+
+#ifndef DECODER_H
+#define DECODER_H
+
+#include <sys/mman.h>
+#include <sys/fcntl.h>
+#include <sys/stat.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <stdint.h>
+#include <unistd.h>
+#include <stddef.h>
+#include <sys/time.h>
+#include <stdbool.h>
+#include "pt/tnt_cache.h"
+#include "pt/disassembler.h"
+#include "pt/logger.h"
+#ifdef CONFIG_REDQUEEN
+#include "pt/redqueen.h"
+#endif
+
+//#define DECODER_LOG
+
+typedef enum decoder_state { 
+	TraceDisabled=1,
+	TraceEnabledWithLastIP,
+	TraceEnabledWOLastIP} 
+decoder_state_e;
+
+typedef struct DecoderStateMachine{
+  decoder_state_e state;
+  uint64_t last_ip;
+} decoder_state_machine_t;
+
+/*
+Used as return type for statemachine updates, start and end are undefined unless valid is true
+*/
+typedef struct ShouldDisasm{
+  uint64_t start;
+  uint64_t end;
+  bool valid;
+} should_disasm_t;
+
+
+typedef struct decoder_s{
+	uint64_t min_addr;
+	uint64_t max_addr;
+	void (*handler)(uint64_t);
+	uint64_t last_tip;
+	bool fup_bind_pending;
+	disassembler_t* disassembler_state;
+	tnt_cache_t* tnt_cache_state;
+	decoder_state_machine_t* decoder_state;
+	should_disasm_t* decoder_state_result;
+
+#ifdef DECODER_LOG
+	struct decoder_log_s{
+		uint64_t tnt64;
+		uint64_t tnt8;
+		uint64_t pip;
+		uint64_t cbr;
+		uint64_t ts;
+		uint64_t ovf;
+		uint64_t psbc;
+		uint64_t psbend;
+		uint64_t mnt;
+		uint64_t tma;
+		uint64_t vmcs;
+		uint64_t pad;
+		uint64_t tip;
+		uint64_t tip_pge;
+		uint64_t tip_pgd;
+		uint64_t tip_fup;
+		uint64_t mode;
+	} log;
+#endif
+} decoder_t;
+#ifdef CONFIG_REDQUEEN
+decoder_t* pt_decoder_init(CPUState *cpu, uint64_t min_addr, uint64_t max_addr, int disassembler_word_with,  void (*handler)(uint64_t), redqueen_t *redqueen_state);
+#else
+decoder_t* pt_decoder_init(CPUState *cpu, uint64_t min_addr, uint64_t max_addr, int disassembler_word_with, void (*handler)(uint64_t));
+#endif
+/* returns false if the CPU trashed our tracing run ... thank you Intel btw ... */
+ __attribute__((hot)) bool decode_buffer(decoder_t* self, uint8_t* map, size_t len, CPUState *cpu);
+void pt_decoder_destroy(decoder_t* self);
+void pt_decoder_flush(decoder_t* self);
+
+#endif
diff --git a/pt/disassembler.c b/pt/disassembler.c
new file mode 100644
index 000000000..5dd66d0ab
--- /dev/null
+++ b/pt/disassembler.c
@@ -0,0 +1,762 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later 
+ */
+
+
+#include "debug.h"
+#include "pt/disassembler.h"
+#include "qemu/log.h"
+#include "pt/memory_access.h"
+#ifdef CONFIG_REDQUEEN
+#include "pt/redqueen.h"
+#endif
+
+#define LOOKUP_TABLES		5
+#define IGN_MOD_RM			0
+#define IGN_OPODE_PREFIX	0
+#define MODRM_REG(x)		(x << 3)
+#define MODRM_AND			0b00111000
+
+static bool limit_check(uint64_t bb_start, uint64_t bb_end, uint64_t limit_exit, uint64_t entry) {
+	bool covers_exit = (bb_start <= limit_exit) && (limit_exit <= bb_end);
+	bool hit_exit = (limit_exit == entry);
+	return !covers_exit || hit_exit;
+}
+#define out_of_bounds(self, addr) ((addr < self->min_addr) | (addr > self->max_addr))
+
+#define FAST_ARRAY_LOOKUP
+#define SAMPLE_DECODED_DETAILED
+#ifdef FAST_ARRAY_LOOKUP
+uint64_t* lookup_area = NULL;
+#endif
+cofi_ins cb_lookup[] = {
+	{X86_INS_JAE,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JA,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JBE,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JB,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JCXZ,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JECXZ,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JE,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JGE,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JG,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JLE,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JL,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JNE,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JNO,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JNP,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JNS,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JO,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JP,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JRCXZ,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JS,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_LOOP,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_LOOPE,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_LOOPNE,	IGN_MOD_RM,	IGN_OPODE_PREFIX},
+};
+
+/* unconditional direct branch */
+cofi_ins udb_lookup[] = {
+	{X86_INS_JMP,		IGN_MOD_RM,	0xe9},
+	{X86_INS_JMP,		IGN_MOD_RM, 0xeb},
+	{X86_INS_CALL,		IGN_MOD_RM,	0xe8},	
+};
+
+/* indirect branch */
+cofi_ins ib_lookup[] = {
+	{X86_INS_JMP,		MODRM_REG(4),	0xff},
+	{X86_INS_CALL,		MODRM_REG(2),	0xff},	
+};
+
+/* near ret */
+cofi_ins nr_lookup[] = {
+	{X86_INS_RET,		IGN_MOD_RM,	0xc3},
+	{X86_INS_RET,		IGN_MOD_RM,	0xc2},
+};
+ 
+/* far transfers */ 
+cofi_ins ft_lookup[] = {
+	{X86_INS_INT3,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_INT,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_INT1,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_INTO,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_IRET,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_IRETD,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_IRETQ,		IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_JMP,		IGN_MOD_RM,		0xea},
+	{X86_INS_JMP,		MODRM_REG(5),	0xff},
+	{X86_INS_CALL,		IGN_MOD_RM,		0x9a},
+	{X86_INS_CALL,		MODRM_REG(3),	0xff},
+	{X86_INS_RET,		IGN_MOD_RM,		0xcb},
+	{X86_INS_RET,		IGN_MOD_RM,		0xca},
+	{X86_INS_SYSCALL,	IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_SYSENTER,	IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_SYSEXIT,	IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_SYSRET,	IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_VMLAUNCH,	IGN_MOD_RM,	IGN_OPODE_PREFIX},
+	{X86_INS_VMRESUME,	IGN_MOD_RM,	IGN_OPODE_PREFIX},
+};
+
+uint16_t cmp_lookup[] = {
+	X86_INS_CMP,
+	X86_INS_CMPPD,
+	X86_INS_CMPPS,
+	X86_INS_CMPSB,
+	X86_INS_CMPSD,
+	X86_INS_CMPSQ,
+	X86_INS_CMPSS,
+	X86_INS_CMPSW,
+	X86_INS_CMPXCHG16B,
+	X86_INS_CMPXCHG,
+	X86_INS_CMPXCHG8B,
+};
+
+
+cofi_ins* lookup_tables[] = {
+	cb_lookup,
+	udb_lookup,
+	ib_lookup,
+	nr_lookup,
+	ft_lookup,
+};
+
+uint8_t lookup_table_sizes[] = {
+	22,
+	3,
+	2,
+	2,
+	19
+};
+
+/* ===== kAFL disassembler cofi list ===== */
+
+static cofi_list* create_list_head(void){
+	cofi_list* head = malloc(sizeof(cofi_list));
+	if (head != NULL){
+		head->list_ptr = NULL;
+		head->cofi_ptr = NULL;
+		head->cofi_target_ptr = NULL;
+		//head->cofi = NULL;
+		head->cofi.type = NO_DISASSEMBLY;
+		return head;
+	}
+	return NULL;
+}
+
+static void free_list(cofi_list* head){
+	cofi_list *tmp1, *tmp2;
+	tmp1 = head;
+	while (1){
+		tmp2 = tmp1;
+		if(tmp1 == NULL){
+			break;
+		}
+		tmp1 = tmp1->list_ptr;
+		//if (tmp2->cofi != NULL){
+		//	free(tmp2->cofi);
+		//}
+		free(tmp2);
+	}
+}
+
+static cofi_list* new_list_element(cofi_list* predecessor){ //, cofi_header* cofi){
+	if(predecessor){
+		cofi_list* next = malloc(sizeof(cofi_list));
+		if (next){
+			predecessor->list_ptr = next;
+			next->list_ptr = NULL;
+			next->cofi_ptr = NULL;
+			next->cofi_target_ptr = NULL;
+			//next->cofi = cofi;
+			next->cofi.type = NO_DISASSEMBLY;
+			return next;
+		}
+	}
+	return NULL;
+}
+
+static void edit_cofi_ptr(cofi_list* element, cofi_list* target){
+	if (element){
+		element->cofi_ptr = target;
+	}
+}
+
+/* ===== kAFL disassembler hashmap ===== */
+
+#ifdef FAST_ARRAY_LOOKUP
+static void map_put(disassembler_t* self, uint64_t addr, uint64_t ref){
+	lookup_area[self->max_addr-addr] = ref;
+}
+
+static int map_get(disassembler_t* self, uint64_t addr, uint64_t* ref){
+	*ref = lookup_area[self->max_addr-addr];
+	return !(*ref);
+}
+
+#else
+
+static void map_put(disassembler_t* self, uint64_t addr, uint64_t ref){
+	int ret;
+	khiter_t k;
+	k = kh_put(ADDR0, self->map, addr, &ret); 
+	kh_value(self->map, k) = ref;
+}
+
+static int map_get(disassembler_t* self, uint64_t addr, uint64_t* ref){
+	khiter_t k;
+	k = kh_get(ADDR0, self->map, addr); 
+	if(k != kh_end(self->map)){
+		*ref = kh_value(self->map, k); 
+		return 0;
+	} 
+	return 1;
+}
+#endif
+
+/* ===== kAFL disassembler engine ===== */
+
+static inline uint64_t fast_strtoull(const char *hexstring){
+	uint64_t result = 0;
+	uint8_t i = 0;
+	if (hexstring[1] == 'x' || hexstring[1] == 'X')
+		i = 2;
+	for (; hexstring[i]; i++)
+		result = (result << 4) + (9 * (hexstring[i] >> 6) + (hexstring[i] & 017));
+	return result;
+}
+
+static inline uint64_t hex_to_bin(char* str){
+	//return (uint64_t)strtoull(str, NULL, 16);
+	return fast_strtoull(str);
+}
+
+#ifdef CONFIG_REDQUEEN
+static bool is_interessting_lea_at(disassembler_t* self, uint64_t addr){
+	asm_operand_t op1 = {0};
+	asm_operand_t op2 = {0};
+	bool res = false;
+	if( redqueen_get_operands_at(self->redqueen_state, addr, &op1, &op2) ) {
+		assert(op1.was_present && op2.was_present);
+		assert(op2.ptr_size);
+	
+		int64_t oint = (int64_t)op2.offset;
+		res = oint < 0 && (-oint) > 0xff && op2.scale == 1 && op2.base == NULL && op2.index != NULL;
+	
+		if(res){
+			if(!strcmp(op2.index,"rbp") || !strcmp(op2.index,"ebp") || !strcmp(op2.index,"rip")){ 
+				QEMU_PT_PRINTF(REDQUEEN_PREFIX, "got boring index");
+				res = false;
+			} //don't instrument local stack offset computations
+		}
+		asm_decoder_clear(&op1);
+		asm_decoder_clear(&op2);
+	}
+	return res;
+}
+
+static bool is_interessting_add_at(disassembler_t* self, uint64_t addr){
+	asm_operand_t op1 = {0};
+	asm_operand_t op2 = {0};
+	bool res = false;
+	if( redqueen_get_operands_at(self->redqueen_state, addr, &op1, &op2) ) {
+		assert(op1.was_present && op2.was_present);
+
+		//offsets needs to be negative, < -0xff to ensure we only look at multi byte substractions
+		res = op2.offset > 0x7fff && (((op2.offset>>8)&0xff) != 0xff) && op2.scale == 1 && op2.base == NULL && op2.index == NULL;
+
+		if( (op1.index && strstr(op1.index,"bp")) || (op2.index && strstr(op2.index,"sp") ) ){
+			res = false;
+		} //don't instrument local stack offset computations
+		asm_decoder_clear(&op1);
+		asm_decoder_clear(&op2);
+	}
+	return res;
+}
+
+static bool is_interessting_sub_at(disassembler_t* self, uint64_t addr){
+	asm_operand_t op1 = {0};
+	asm_operand_t op2 = {0};
+	bool res = false;
+	if( redqueen_get_operands_at(self->redqueen_state, addr, &op1, &op2) ) {
+		assert(op1.was_present && op2.was_present);
+		res = false;
+		if(op2.offset > 0xff && op2.scale == 1 && op2.base == NULL && op2.index == NULL){
+			if( (op1.index && strstr(op1.index,"bp")) || (op2.index && strstr(op2.index,"sp") ) ){
+				res = false;
+			} else {
+				//don't instrument local stack offset computations 
+				res = true;
+			}
+		}
+		asm_decoder_clear(&op1);
+		asm_decoder_clear(&op2);
+	}
+	return res;
+}
+
+static bool is_interessting_xor_at(disassembler_t* self, uint64_t addr){
+	asm_operand_t op1 = {0};
+	asm_operand_t op2 = {0};
+	bool res = false;
+	if( redqueen_get_operands_at(self->redqueen_state, addr, &op1, &op2) ) {
+		assert(op1.was_present && op2.was_present);
+		res = !asm_decoder_op_eql(&op1, &op2);
+	}
+	asm_decoder_clear(&op1);
+	asm_decoder_clear(&op2);
+	return res;
+}
+#endif
+
+static cofi_type opcode_analyzer(disassembler_t* self, cs_insn *ins){
+	uint8_t i, j;
+	cs_x86 details = ins->detail->x86;
+#ifdef CONFIG_REDQUEEN
+	if(self->redqueen_mode){
+		  if(ins->id == X86_INS_CMP){
+			  set_rq_instruction(self->redqueen_state, ins->address);
+		}
+		if(ins->id == X86_INS_LEA && is_interessting_lea_at(self, ins->address)){
+			QEMU_PT_PRINTF(REDQUEEN_PREFIX, "hooking lea %lx", ins->address);
+			set_rq_instruction(self->redqueen_state, ins->address);
+		}
+		if(ins->id == X86_INS_SUB && is_interessting_sub_at(self, ins->address)){
+			QEMU_PT_PRINTF(REDQUEEN_PREFIX, "hooking sub %lx", ins->address);
+			set_rq_instruction(self->redqueen_state, ins->address);
+		}
+		if(ins->id == X86_INS_ADD && is_interessting_add_at(self, ins->address)){
+			QEMU_PT_PRINTF(REDQUEEN_PREFIX, "hooking add %lx", ins->address);
+			set_rq_instruction(self->redqueen_state, ins->address);
+		}
+		if(ins->id == X86_INS_XOR && is_interessting_xor_at(self, ins->address)){
+			QEMU_PT_PRINTF(REDQUEEN_PREFIX, "hooking xor %lx", ins->address);
+			set_rq_instruction(self->redqueen_state, ins->address);
+		}
+		if( ins->id != X86_INS_LEA && (ins->id == X86_INS_RET || ins->id == X86_INS_POP || 
+			(strstr(ins->op_str,"[") && 
+			(ins->id != X86_INS_NOP) &&
+			!(ins->size == 2 && 
+			ins->bytes[0] == 0x00 && 
+			ins->bytes[1] == 0x00)))){ /* ignore "add	byte ptr [rax], al" [0000] */
+				set_se_instruction(self->redqueen_state, ins->address);
+			}
+		if(ins->id ==X86_INS_CALL || ins->id == X86_INS_LCALL){
+			QEMU_PT_DEBUG(REDQUEEN_PREFIX, "insert hook call %lx", ins->address);
+			set_rq_instruction(self->redqueen_state, ins->address);
+		}
+	}
+#endif
+	
+	for (i = 0; i < LOOKUP_TABLES; i++){
+		for (j = 0; j < lookup_table_sizes[i]; j++){
+			if (ins->id == lookup_tables[i][j].opcode){
+				/* check MOD R/M */
+				if (lookup_tables[i][j].modrm != IGN_MOD_RM && lookup_tables[i][j].modrm != (details.modrm & MODRM_AND))
+						continue;	
+						
+				/* check opcode prefix byte */
+				if (lookup_tables[i][j].opcode_prefix != IGN_OPODE_PREFIX && lookup_tables[i][j].opcode_prefix != details.opcode[0])
+						continue;
+#ifdef DEBUG
+				/* found */
+				//printf("%lx (%d)\t%s\t%s\t\t", ins->address, i, ins->mnemonic, ins->op_str);
+				//print_string_hex("      \t", ins->bytes, ins->size);
+#endif
+				return i;
+				
+			}
+		}
+	}
+	return NO_COFI_TYPE;
+}
+
+int get_capstone_mode(CPUState *cpu){
+	switch(cpu->disassembler_word_width){
+		case 64: 
+			return CS_MODE_64;
+		case 32: 
+			return CS_MODE_32;
+		default:
+			assert(false);
+	}
+}
+
+static cofi_list* analyse_assembly(disassembler_t* self, uint64_t base_address, bool across_page){
+	csh handle;
+	cs_insn *insn;
+	cofi_type type;
+	uint64_t tmp_list_element = 0;
+	bool last_nop = false, no_munmap = true;
+	uint64_t cofi = 0;
+	const uint8_t* code; //mmap_virtual_memory(base_address, self->cpu);
+	uint8_t tmp_code[x86_64_PAGE_SIZE*2] = {0};
+	size_t code_size = x86_64_PAGE_SIZE - (base_address & ~x86_64_PAGE_MASK);
+	struct kvm_translation translation = {0};
+	char tmp_buf[3] = {0};
+	uint64_t address = base_address;
+	cofi_list* predecessor = NULL;
+	cofi_list* first = NULL;
+	FILE *test = NULL;
+	int i = 0;
+	//bool abort_disassembly = false;
+	
+	assert(cs_open(CS_ARCH_X86, get_capstone_mode(self->cpu), &handle) == CS_ERR_OK);
+	cs_option(handle, CS_OPT_DETAIL, CS_OPT_ON);
+	// parse unrecognized instructions as data (endbr32/endbr64)
+	//cs_option(handle, CS_OPT_SKIPDATA, CS_OPT_ON);
+
+	insn = cs_malloc(handle);
+	
+	/*
+		* We must parse instructions in two consecutive pages.
+		* */
+	if (across_page)
+		code_size = x86_64_PAGE_SIZE*2 - (address & ~x86_64_PAGE_MASK);
+	
+	translation.linear_address = address;
+	kvm_vcpu_ioctl(self->cpu, KVM_TRANSLATE, &translation);
+		printf("GVA: 0x%llx, GPA: 0x%llx, valid: 0x%x\n",
+					translation.linear_address, translation.physical_address, translation.valid);
+	if (translation.physical_address == 0xFFFFFFFFFFFFFFFF) {
+		goto out;
+	}
+	code = mmap_physical_memory(translation.physical_address, self->cpu);
+	
+	no_munmap = false;
+
+	QEMU_PT_DEBUG(DISASM_PREFIX, "Analyse ASM: %lx (%zd), max_addr=%lx\n", address, code_size, self->max_addr);
+
+
+	while(cs_disasm_iter(handle, (const uint8_t**)&code, &code_size, &address, insn)) {	
+
+		QEMU_PT_DEBUG(DISASM_PREFIX, "Loop: %lx:\t%s\t%s, last_nop=%d", insn->address, insn->mnemonic, insn->op_str, last_nop);
+
+		if (insn->address > self->max_addr){
+			break;
+		}
+			
+		type = opcode_analyzer(self, insn);
+		
+		if (!last_nop){
+			if (cofi)
+				predecessor = self->list_element;
+
+			self->list_element = new_list_element(self->list_element);
+			self->list_element->cofi.type = NO_COFI_TYPE;
+			self->list_element->cofi.ins_addr = insn->address;
+			self->list_element->cofi.ins_size = insn->size;
+			self->list_element->cofi.target_addr = 0;
+
+			edit_cofi_ptr(predecessor, self->list_element);
+		}
+		
+		if (!map_get(self, insn->address, (uint64_t *)&tmp_list_element)){
+			if(((cofi_list *)tmp_list_element)->cofi_ptr){
+				edit_cofi_ptr(self->list_element, (cofi_list *)tmp_list_element);
+				break;
+			} else {
+				self->list_element = (cofi_list *)tmp_list_element;
+			}
+		}
+		
+		if (type != NO_COFI_TYPE){
+			cofi++;
+			last_nop = false;
+			self->list_element->cofi.type = type;
+			self->list_element->cofi.ins_addr = insn->address;
+			self->list_element->cofi.ins_size = insn->size;
+			if (type == COFI_TYPE_CONDITIONAL_BRANCH || type == COFI_TYPE_UNCONDITIONAL_DIRECT_BRANCH){
+				self->list_element->cofi.target_addr = hex_to_bin(insn->op_str);	
+			} else {
+				self->list_element->cofi.target_addr = 0;
+			}
+			//self->list_element->cofi = tmp;
+			map_put(self, self->list_element->cofi.ins_addr, (uint64_t)(self->list_element));
+			//if(type == COFI_TYPE_INDIRECT_BRANCH || type == COFI_TYPE_NEAR_RET || type == COFI_TYPE_FAR_TRANSFERS){
+				//don't disassembly through ret and similar instructions to avoid disassembly inline data
+				//however we need to finish the cofi ptr datatstructure therefore we take a second loop iteration and abort
+				//after last_nop = false ist handeled
+				//abort_disassembly = true;
+				//QEMU_PT_DEBUG(DISASM_PREFIX, "ABORT_ASSEMBLY=TRUE");
+			//}
+		} else {
+			last_nop = true;
+			map_put(self, insn->address, (uint64_t)(self->list_element));
+		}
+		
+		if (!first){
+			first = self->list_element;
+		}
+
+		//if (abort_disassembly){
+		//	break;
+		//}
+	}
+
+	munmap_virtual_memory((void *)code, self->cpu);
+out:
+	cs_free(insn, 1);
+	cs_close(&handle);
+//	if (no_munmap) {
+//	}
+	return first;
+}
+
+#ifdef CONFIG_REDQUEEN
+disassembler_t* init_disassembler(CPUState *cpu, uint64_t min_addr, uint64_t max_addr, int disassembler_word_width, void (*handler)(uint64_t), redqueen_t *redqueen_state){
+#else
+disassembler_t* init_disassembler(CPUState *cpu, uint64_t min_addr, uint64_t max_addr, int disassembler_word_width, void (*handler)(uint64_t)){
+#endif
+	disassembler_t* res = malloc(sizeof(disassembler_t));
+	res->cpu = cpu;
+	res->min_addr = min_addr;
+	res->max_addr = max_addr;
+	res->handler = handler;
+	res->list_head = create_list_head();
+	res->word_width = disassembler_word_width;
+	res->list_element = res->list_head;
+	res->has_pending_indirect_branch = false;
+	res->pending_indirect_branch_src = 0;
+
+#ifdef FAST_ARRAY_LOOKUP
+	assert((max_addr-min_addr) <= (128 << 20)); /* up to 128MB trace region (results in 512MB lookup table...) */
+	lookup_area = malloc(sizeof(uint64_t) * (max_addr-min_addr+1));
+	memset(lookup_area, 0x00, (sizeof(uint64_t) * (max_addr-min_addr+1)));
+#else
+	res->map = kh_init(ADDR0);
+#endif
+
+#ifdef CONFIG_REDQUEEN
+	if (redqueen_state != NULL){
+		res->redqueen_mode = true;
+		res->redqueen_state = redqueen_state;
+	}
+	else{
+		res->redqueen_mode = false;
+	}
+#endif
+	return res;
+}
+
+void destroy_disassembler(disassembler_t* self){
+#ifdef FAST_ARRAY_LOOKUP
+	free(lookup_area);
+#else
+	kh_destroy(ADDR0, self->map);
+#endif
+	free_list(self->list_head);
+	free(self);
+}
+
+static inline cofi_list* get_obj(disassembler_t* self, uint64_t entry_point){
+	cofi_list *tmp_obj;
+
+	if (out_of_bounds(self, entry_point)){
+		return NULL;
+	}
+
+	if(map_get(self, entry_point, (uint64_t *)&tmp_obj)){
+		tmp_obj = analyse_assembly(self, entry_point, false);
+	}
+
+	// Decoding can fail on code read or decoding errors
+	// Fuzzing will usually still work but traces may not be accurate.
+	if (!tmp_obj || !tmp_obj->cofi_ptr)
+		return NULL;
+
+	return tmp_obj;
+}
+
+
+void disassembler_flush(disassembler_t* self){
+	self->has_pending_indirect_branch = false;
+	self->pending_indirect_branch_src = 0;
+}
+
+void inform_disassembler_target_ip(disassembler_t* self, uint64_t target_ip){
+	if(self->has_pending_indirect_branch){
+#ifdef CONFIG_REDQUEEN
+		if(self->redqueen_mode){
+			WRITE_SAMPLE_DECODED_DETAILED("** %lx -rq-> %lx \n", self->pending_indirect_branch_src, target_ip);
+			redqueen_register_transition(self->redqueen_state, self->pending_indirect_branch_src, target_ip);
+		}
+#endif
+		disassembler_flush(self);
+	}
+}
+
+static inline cofi_list* get_cofi_ptr(disassembler_t* self, cofi_list *obj)
+{
+	cofi_list *tmp_obj;
+
+	if (!obj->cofi_ptr) {
+		tmp_obj = analyse_assembly(self, obj->cofi.ins_addr, true);
+		if (!tmp_obj) {
+			return NULL;
+		}
+		if (!tmp_obj->cofi_ptr) {
+			printf("Fatal error 1 in get_cofi_ptr.\n");
+			asm("int $3\r\n");
+		}
+	} else {
+		printf("Already exists, didn't analyse assembly for 0x%lx\n", obj->cofi_ptr->cofi.ins_addr);
+		tmp_obj = obj->cofi_ptr;
+	}
+
+	return tmp_obj;
+}
+
+#ifndef DEBUG_TRACE_RETURN
+#define check_return(msg) do { return true; } while (0)
+#else
+#define check_return(msg) \
+	do { \
+		if (count_tnt(tnt_cache_state)) { \
+			WRITE_SAMPLE_DECODED_DETAILED("Error %s\n", msg); \
+			printf("Trap %s: in trace_disassembler()\n", msg); \
+			asm("int $3\r\n"); \
+			return false; \
+		} \
+		return true; \
+	} while (0)
+#endif
+
+#define debug_false() { asm("int $3\r\n"); goto __ret_false; }
+  __attribute__((hot)) bool trace_disassembler(disassembler_t* self, uint64_t entry_point, uint64_t limit, tnt_cache_t* tnt_cache_state){
+
+	cofi_list *obj, *last_obj;
+#ifdef CONFIG_REDQUEEN
+	bool redqueen_tracing = (self->redqueen_mode && self->redqueen_state->trace_mode);
+#endif
+		
+	inform_disassembler_target_ip(self, entry_point);
+
+	obj = get_obj(self, entry_point);
+
+	if (!obj) {
+		printf("1\n");
+		check_return("1");
+	}
+
+	self->handler(entry_point);
+
+	while(true){
+		
+		if (!obj) return false;
+
+		switch(obj->cofi.type){
+
+			case COFI_TYPE_CONDITIONAL_BRANCH:
+				switch(process_tnt_cache(tnt_cache_state)){
+
+					case TNT_EMPTY:
+						WRITE_SAMPLE_DECODED_DETAILED("(%d)\t%%lx\tCACHE EMPTY\n", COFI_TYPE_CONDITIONAL_BRANCH, obj->cofi.ins_addr);
+						return false;
+
+					case TAKEN:
+						WRITE_SAMPLE_DECODED_DETAILED("(%d)\t%lx\t(Taken)\n", COFI_TYPE_CONDITIONAL_BRANCH, obj->cofi.ins_addr);			
+#ifdef CONFIG_REDQUEEN
+						if(redqueen_tracing){
+							WRITE_SAMPLE_DECODED_DETAILED("** %lx -rq-> %lx \n", obj->cofi.ins_addr, obj->cofi.target_addr);
+							redqueen_register_transition(self->redqueen_state, obj->cofi.ins_addr, obj->cofi.target_addr);
+						}
+#endif
+						last_obj = obj;
+						self->handler(obj->cofi.target_addr);
+						if(!obj->cofi_target_ptr){
+							obj->cofi_target_ptr = get_obj(self, obj->cofi.target_addr);
+						}
+						obj = obj->cofi_target_ptr;
+
+						if (!obj || !limit_check(last_obj->cofi.target_addr, obj->cofi.ins_addr, limit, entry_point)){
+							printf("2\n");
+							check_return("2");
+						}
+						break;
+					case NOT_TAKEN:
+						WRITE_SAMPLE_DECODED_DETAILED("(%d)\t%lx\t(Not Taken)\n", COFI_TYPE_CONDITIONAL_BRANCH ,obj->cofi.ins_addr);
+#ifdef CONFIG_REDQUEEN
+						if(redqueen_tracing){
+							WRITE_SAMPLE_DECODED_DETAILED("** %lx -rq-> %lx \n", obj->cofi.ins_addr, obj->cofi.ins_addr + obj->cofi.ins_size);
+							redqueen_register_transition(self->redqueen_state, obj->cofi.ins_addr, obj->cofi.ins_addr + obj->cofi.ins_size);
+						}
+#endif
+
+						last_obj = obj;
+						self->handler((obj->cofi.ins_addr)+obj->cofi.ins_size);
+						/* fix if cofi_ptr is null */
+    					if(!obj->cofi_ptr){
+    						obj->cofi_ptr = get_obj(self, obj->cofi.ins_addr+obj->cofi.ins_size);
+    					}
+						obj = obj->cofi_ptr;
+
+						if(!obj || !limit_check(last_obj->cofi.ins_addr, obj->cofi.ins_addr, limit, entry_point)){
+							printf("3\n");
+							check_return("3");
+						}
+						break;
+				}
+				break;
+
+			case COFI_TYPE_UNCONDITIONAL_DIRECT_BRANCH:
+				WRITE_SAMPLE_DECODED_DETAILED("(%d)\t%lx\n", COFI_TYPE_UNCONDITIONAL_DIRECT_BRANCH ,obj->cofi.ins_addr);
+				last_obj = obj;
+				if(!obj->cofi_target_ptr){
+					obj->cofi_target_ptr = get_obj(self, obj->cofi.target_addr);
+				}
+				obj = obj->cofi_target_ptr;
+
+				if(!obj || !limit_check(last_obj->cofi.target_addr, obj->cofi.ins_addr, limit, entry_point)){
+					printf("4\n");
+					check_return("4");
+				}
+				break;
+
+			case COFI_TYPE_INDIRECT_BRANCH:
+				self->handler(obj->cofi.ins_addr); //BROKEN, TODO move to inform_disassembler_target_ip
+				
+#ifdef CONFIG_REDQUEEN
+				if(redqueen_tracing){
+					self->has_pending_indirect_branch = true;
+					self->pending_indirect_branch_src = obj->cofi.ins_addr;
+				}
+#endif
+				
+				WRITE_SAMPLE_DECODED_DETAILED("(2)\t%lx\n",obj->cofi.ins_addr);
+				return true;
+
+			case COFI_TYPE_NEAR_RET:
+#ifdef CONFIG_REDQUEEN
+				if(redqueen_tracing){
+					self->has_pending_indirect_branch = true;
+					self->pending_indirect_branch_src = obj->cofi.ins_addr;
+				}
+#endif
+				WRITE_SAMPLE_DECODED_DETAILED("(3)\t%lx\n",obj->cofi.ins_addr);
+				return true;
+
+			case COFI_TYPE_FAR_TRANSFERS:
+				WRITE_SAMPLE_DECODED_DETAILED("(4)\t%lx\n",obj->cofi.ins_addr);
+				return true;
+
+			case NO_COFI_TYPE:
+				WRITE_SAMPLE_DECODED_DETAILED("(5)\t%lx\n",obj->cofi.ins_addr);
+
+				if(!(obj->cofi_ptr) || !limit_check(obj->cofi.ins_addr, obj->cofi.ins_addr, limit, entry_point)){
+					printf("5\n");
+					check_return("(5)");
+				}
+				obj = obj->cofi_ptr;
+				break;
+			case NO_DISASSEMBLY:
+				assert(false);
+		}
+	}
+
+	assert(false);
+	return false;
+}
\ No newline at end of file
diff --git a/pt/disassembler.h b/pt/disassembler.h
new file mode 100644
index 000000000..6a306cdcd
--- /dev/null
+++ b/pt/disassembler.h
@@ -0,0 +1,96 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later 
+ */
+
+
+#ifndef DISASSEMBLER_H
+#define DISASSEMBLER_H
+
+#include <stdint.h>
+#include <stdbool.h>
+#include <unistd.h>
+#include <sys/time.h>
+#include <inttypes.h>
+#include <capstone/capstone.h>
+#include <capstone/x86.h>
+#include <stdbool.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <fcntl.h>
+#include "qemu/osdep.h"
+#include "pt/khash.h"
+#include "pt/tnt_cache.h"
+#include "pt/logger.h"
+#ifdef CONFIG_REDQUEEN
+#include "pt/redqueen.h"
+#endif
+
+KHASH_MAP_INIT_INT(ADDR0, uint64_t)
+
+typedef struct{
+	uint16_t opcode;
+	uint8_t modrm;
+	uint8_t opcode_prefix;
+} cofi_ins;
+
+typedef enum cofi_types{
+	COFI_TYPE_CONDITIONAL_BRANCH,
+	COFI_TYPE_UNCONDITIONAL_DIRECT_BRANCH,
+	COFI_TYPE_INDIRECT_BRANCH,
+	COFI_TYPE_NEAR_RET,
+	COFI_TYPE_FAR_TRANSFERS,
+	NO_COFI_TYPE,
+	NO_DISASSEMBLY,
+} cofi_type;
+
+
+typedef struct {
+	uint64_t ins_addr;
+	uint64_t target_addr;
+	uint16_t ins_size;
+	cofi_type type;
+} cofi_header;
+
+typedef struct cofi_list {
+	struct cofi_list *list_ptr;
+	struct cofi_list *cofi_ptr;
+	struct cofi_list *cofi_target_ptr;
+	cofi_header cofi;
+} cofi_list;
+
+typedef struct disassembler_s{
+	CPUState *cpu;
+	uint64_t min_addr;
+	uint64_t max_addr;
+	void (*handler)(uint64_t);
+	khash_t(ADDR0) *map;
+	cofi_list* list_head;
+	cofi_list* list_element;
+	bool debug;
+	bool has_pending_indirect_branch;
+	int word_width;
+	uint64_t pending_indirect_branch_src;
+#ifdef CONFIG_REDQUEEN
+	bool redqueen_mode;
+	redqueen_t* redqueen_state;
+#endif
+} disassembler_t;
+
+#ifdef CONFIG_REDQUEEN
+disassembler_t* init_disassembler(CPUState *cpu, uint64_t min_addr, uint64_t max_addr, int disassembler_word_width, void (*handler)(uint64_t), redqueen_t *redqueen_state);
+#else
+disassembler_t* init_disassembler(CPUState *cpu, uint64_t min_addr, uint64_t max_addr, int disassembler_word_width, void (*handler)(uint64_t));
+#endif
+
+int get_capstone_mode(CPUState *cpu);
+void disassembler_flush(disassembler_t* self);
+void inform_disassembler_target_ip(disassembler_t* self, uint64_t target_ip);
+ __attribute__((hot)) bool trace_disassembler(disassembler_t* self, uint64_t entry_point, uint64_t limit, tnt_cache_t* tnt_cache_state);
+void destroy_disassembler(disassembler_t* self);
+
+#endif
diff --git a/pt/file_helper.c b/pt/file_helper.c
new file mode 100644
index 000000000..c5231e6af
--- /dev/null
+++ b/pt/file_helper.c
@@ -0,0 +1,137 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later 
+ */
+
+#include <assert.h>
+#include <string.h>
+
+#include <sys/stat.h> 
+#include <fcntl.h>
+#include <unistd.h>
+#include <errno.h>
+
+#include "redqueen.h"
+#include "debug.h"
+#include "file_helper.h"
+
+
+///////////////////////////////////////////////////////////////////////////////////
+// Private Helper Functions Declarations
+///////////////////////////////////////////////////////////////////////////////////
+
+size_t _count_lines_in_file(FILE* fp);
+
+void _parse_addresses_in_file(FILE* fp, size_t num_addrs, uint64_t* addrs);
+
+///////////////////////////////////////////////////////////////////////////////////
+// Public Functions
+///////////////////////////////////////////////////////////////////////////////////
+
+void write_debug_result(char* buf){
+  int unused __attribute__((unused));
+	int fd = open("/tmp/qemu_debug.txt", O_WRONLY | O_CREAT | O_APPEND, S_IRWXU);
+  assert(fd > 0);
+	unused = write(fd, buf, strlen(buf));
+  close(fd);
+}
+
+void parse_address_file(char* path, size_t* num_addrs, uint64_t** addrs){
+  FILE* fp = fopen(path,"r");
+  if(!fp){
+    *num_addrs = 0;
+    *addrs = NULL;
+    return;
+  }
+
+  *num_addrs = _count_lines_in_file(fp);
+  if(*num_addrs == 0){
+    *addrs = NULL;
+    goto exit_function;
+  }
+
+  assert(*num_addrs < 0xffff);
+  *addrs = malloc(sizeof(uint64_t)*(*num_addrs));
+  _parse_addresses_in_file(fp, *num_addrs, *addrs);
+
+  exit_function:
+  fclose(fp);
+}
+
+
+int re_fd = 0;
+int se_fd = 0;
+int trace_fd = 0;
+
+void write_re_result(char* buf){
+  int unused __attribute__((unused));
+	if (!re_fd)
+	  re_fd = open(redqueen_workdir.redqueen_results, O_WRONLY | O_CREAT | O_APPEND, S_IRWXU);
+	unused = write(re_fd, buf, strlen(buf));
+}
+
+void write_trace_result(char* buf){
+	//int fd;
+  int unused __attribute__((unused));
+	if (!trace_fd)
+		trace_fd = open(redqueen_workdir.pt_trace_results, O_WRONLY | O_CREAT | O_APPEND, S_IRWXU);
+	unused = write(trace_fd, buf, strlen(buf));
+	//close(fd);
+}
+
+void write_se_result(char* buf){
+	//int fd;
+  int unused __attribute__((unused));
+	if (!se_fd)
+		se_fd = open(redqueen_workdir.symbolic_results, O_WRONLY | O_CREAT | O_APPEND, S_IRWXU);
+	unused = write(se_fd, buf, strlen(buf));
+	//close(fd);
+}
+
+void delete_trace_files(void){
+  int unused __attribute__((unused));
+	if (!trace_fd)
+		trace_fd = open(redqueen_workdir.pt_trace_results, O_WRONLY | O_CREAT | O_APPEND, S_IRWXU);
+	unused = ftruncate(trace_fd, 0);
+}
+
+void delete_redqueen_files(void){
+  int unused __attribute__((unused));
+	if (!re_fd)
+		re_fd = open(redqueen_workdir.redqueen_results, O_WRONLY | O_CREAT | O_APPEND, S_IRWXU);
+	if (!se_fd)
+		se_fd = open(redqueen_workdir.symbolic_results, O_WRONLY | O_CREAT | O_APPEND, S_IRWXU);
+	unused = ftruncate(re_fd, 0);
+	unused = ftruncate(se_fd, 0);
+}
+
+///////////////////////////////////////////////////////////////////////////////////
+// Private Helper Functions Definitions
+///////////////////////////////////////////////////////////////////////////////////
+
+size_t _count_lines_in_file(FILE* fp){
+  size_t val = 0;
+  size_t count = 0;
+  while(1){
+    int scanres = fscanf(fp, "%lx", &val);
+    if(scanres == 0){
+      printf("WARNING, invalid line in address file");
+      assert(scanres != 0);
+    }
+    if(scanres == -1){break;}
+    count+=1;
+  }
+  rewind(fp);
+  return count;
+}
+
+void _parse_addresses_in_file(FILE* fp, size_t num_addrs, uint64_t* addrs){
+  for(size_t i = 0; i < num_addrs; i++){
+    assert(fscanf(fp, "%lx", &addrs[i]) == 1);
+  }
+}
+
diff --git a/pt/file_helper.h b/pt/file_helper.h
new file mode 100644
index 000000000..c7ff29e8e
--- /dev/null
+++ b/pt/file_helper.h
@@ -0,0 +1,31 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later 
+ */
+
+#include <stdio.h>
+#include <stdint.h>
+#include <stdlib.h>
+
+//doesn't take ownership of path, num_addrs or addrs
+void parse_address_file(char* path, size_t* num_addrs, uint64_t** addrs);
+
+//doesn't take ownership of buf
+void write_re_result(char* buf);
+
+//doesn't take ownership of buf
+void write_se_result(char* buf);
+
+//doesn't take ownership of buf
+void write_trace_result(char* buf);
+
+//doesn' take ownership of buf
+void write_debug_result(char* buf);
+
+void delete_redqueen_files(void);
+
+void delete_trace_files(void);
diff --git a/pt/filter.c b/pt/filter.c
new file mode 100644
index 000000000..f109daa77
--- /dev/null
+++ b/pt/filter.c
@@ -0,0 +1,109 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later 
+ */
+
+#include "filter.h"
+#include <fcntl.h>
+
+/* http://zimbry.blogspot.ch/2011/09/better-bit-mixing-improving-on.html */
+static inline uint64_t mix_bits(uint64_t v) {
+  v ^= (v >> 31);
+  v *= 0x7fb5d329728ea185;
+  v ^= (v >> 27);
+  v *= 0x81dadef4bc2dd44d;
+  v ^= (v >> 33);
+  return v;
+}
+
+static inline uint64_t mix_tuple(uint64_t curent_addr, uint64_t prev_addr){
+  return mix_bits((curent_addr<<32) + (prev_addr&0xFFFFFFFF));
+}
+
+static bool filter_get_bitmap(filter_t* self, uint8_t* bitmap, uint64_t offset){
+  assert(offset <= self->size);
+  return (bitmap[offset/8] & (1<< offset%8));
+}
+
+static void filter_set_bitmap(filter_t* self, uint8_t* bitmap, uint64_t offset){
+  assert(offset <= self->size);
+  bitmap[offset/8] |= (1<< offset%8);
+}
+
+static bool filter_get_bitmap_sync(filter_t* self, uint8_t* bitmap, uint64_t offset){
+  assert(offset <= self->size);
+  return bitmap[offset];
+}
+
+static void filter_set_bitmap_sync(filter_t* self, uint8_t* bitmap, uint64_t offset){
+  assert(offset <= self->size);
+  if(!bitmap[offset]){
+    bitmap[offset] = 1;  
+    self->blacklist_count++;
+  }
+}
+
+/* default: 128MB */
+filter_t* new_filter(uint64_t from, uint64_t to, uint8_t *filter_bitmap){
+  filter_t* res = malloc(sizeof(filter_t));
+  assert(from < to);
+  res->size = to-from;
+  res->execs = 0;
+  res->counters = malloc(res->size*2);
+  res->from_addr = from;
+  res->to_addr = to;
+  res->hit_bitmap = malloc(res->size/8);
+  res->filter_bitmap = filter_bitmap;
+  res->prev_addr = 0x0;
+  res->blacklist_count = 0;
+  return res;
+}
+
+void filter_init_determinism_run(filter_t* self){
+  self->execs = 0;
+  memset(self->counters, 0, self->size*2);
+}
+
+void filter_init_new_exec(filter_t* self){
+  memset(self->hit_bitmap, 0, self->size/8);
+}
+
+void filter_add_address(filter_t* self, uint64_t addr){
+  if(self->from_addr <= addr && addr <= self->to_addr){
+    filter_set_bitmap(self,self->hit_bitmap,addr-self->from_addr);
+  }
+}
+
+void filter_finalize_exec(filter_t* self){
+  self->execs ++;
+  for(uint64_t a = self->from_addr; a < self->to_addr; a++){
+    if(filter_get_bitmap(self, self->hit_bitmap,a - self->from_addr)){
+      self->counters[a - self->from_addr] += 1;
+    }
+  }
+}
+
+
+void filter_finalize_determinism_run(filter_t* self){
+  for(uint64_t a = self->from_addr; a < self->to_addr; a++){
+    uint64_t o = a-self->from_addr;
+    if(self->counters[o] != self->execs && self->counters[o]){
+      filter_set_bitmap_sync(self, self->filter_bitmap, o);
+    }
+  }
+}
+
+bool filter_is_address_nondeterministic(filter_t* self, uint64_t addr){
+  if(self->from_addr <= addr && addr <= self->to_addr){
+    return filter_get_bitmap_sync(self, self->filter_bitmap,addr-self->from_addr);
+  }
+  return false;
+}
+
+uint32_t filter_count_new_addresses(filter_t* self){
+  return self->blacklist_count;
+}
diff --git a/pt/filter.h b/pt/filter.h
new file mode 100644
index 000000000..287f46165
--- /dev/null
+++ b/pt/filter.h
@@ -0,0 +1,51 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later 
+ */
+
+
+#ifndef __FILTER__
+#define __FILTER__
+
+#include <stddef.h>
+#include <stdlib.h>
+#include <string.h>
+#include <stdint.h>
+#include <stdbool.h>
+#include <assert.h>
+
+typedef struct filter_s {
+  size_t size;
+  uint16_t execs;
+  uint16_t *counters;
+  uint8_t *hit_bitmap;
+  uint8_t *filter_bitmap;
+  uint64_t prev_addr;
+  uint64_t from_addr;
+  uint64_t to_addr;
+  uint32_t blacklist_count;
+} filter_t;
+
+
+
+filter_t* new_filter(uint64_t from, uint64_t to, uint8_t *filter_bitmap);
+
+void filter_init_determinism_run(filter_t* self);
+
+void filter_init_new_exec(filter_t* self);
+
+void filter_add_address(filter_t* self, uint64_t addr);
+
+void filter_finalize_exec(filter_t* self);
+
+void filter_finalize_determinism_run(filter_t* self);
+
+bool filter_is_address_nondeterministic(filter_t* self, uint64_t addr);
+
+uint32_t filter_count_new_addresses(filter_t* self);
+
+#endif
diff --git a/pt/hypercall.c b/pt/hypercall.c
new file mode 100644
index 000000000..b6e0ece45
--- /dev/null
+++ b/pt/hypercall.c
@@ -0,0 +1,626 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later 
+ */
+
+
+#include "qemu/osdep.h"
+#include <linux/kvm.h>
+#include <sys/ioctl.h>
+#include <sys/mman.h>
+#include "qemu-common.h"
+#include "qemu/log.h"
+#include "qemu/main-loop.h"
+#include "qapi/error.h"
+#include "exec/memory.h"
+#include "sysemu/runstate.h"
+#include "sysemu/kvm_int.h"
+#include "sysemu/kvm.h"
+#include "migration/snapshot.h"
+#include "pt.h"
+#include "pt/hypercall.h"
+#include "pt/filter.h"
+#include "pt/memory_access.h"
+#include "pt/interface.h"
+#include "pt/printk.h"
+#include "pt/debug.h"
+#include "pt/synchronization.h"
+#include <unistd.h>
+
+#ifdef CONFIG_REDQUEEN
+#include "pt/redqueen.h"
+#endif
+
+#define CRASH_DUMP_FILE "/root/crash.dmp"
+bool hprintf_enabled = false;
+bool notifiers_enabled = false;
+uint32_t hprintf_counter = 0;
+
+bool create_snapshot_enabled = true;
+bool hypercall_enabled = false;
+void* payload_buffer = NULL;
+void* payload_buffer_guest = NULL;
+void* program_buffer = NULL;
+char info_buffer[INFO_SIZE];
+char hprintf_buffer[HPRINTF_SIZE];
+static uint64_t crash_dump_size = 0;
+static uint64_t crash_dump_offset = 0;
+void* argv = NULL;
+
+static bool init_state = true;
+
+void (*handler)(char, void*) = NULL; 
+void* s = NULL;
+
+uint64_t filter[INTEL_PT_MAX_RANGES][2];
+bool filter_enabled[INTEL_PT_MAX_RANGES] = {false, false, false, false};
+/* vertex filter */
+filter_t *det_filter[INTEL_PT_MAX_RANGES] = {NULL, NULL, NULL, NULL};
+/* edge filter */
+filter_t *det_tfilter = NULL;
+bool det_filter_enabled[INTEL_PT_MAX_RANGES] = {false, false, false, false};
+
+//static void hypercall_lock(void);
+
+static void wait_hypercall_enabled(void) {
+	while (!hypercall_enabled) {
+		usleep(1000*100);
+	}
+}
+
+void pt_setup_disable_create_snapshot(void){
+	create_snapshot_enabled = false;
+}
+
+bool pt_hypercalls_enabled(void){
+	return hypercall_enabled;
+}
+
+void pt_setup_enable_hypercalls(void){
+	hypercall_enabled = true;
+}
+
+void pt_setup_snd_handler(void (*tmp)(char, void*), void* tmp_s){
+	s = tmp_s;
+	handler = tmp;
+}
+
+bool hypercall_snd_char(char val){
+	if (handler != NULL){
+		handler(val, s);
+		return true;
+	}
+	return false;
+}
+
+void hypercall_reset_hprintf_counter(void){
+	hprintf_counter = 0;
+}
+
+void pt_setup_ip_filters(uint8_t filter_id, uint64_t start, uint64_t end, void* filter_bitmap, void* tfilter_bitmap){
+	if (filter_id < INTEL_PT_MAX_RANGES){
+		filter_enabled[filter_id] = true;
+		filter[filter_id][0] = start;
+		filter[filter_id][1] = end;
+		if (filter_bitmap){
+			det_filter[filter_id] = new_filter(start, end, filter_bitmap);
+			//printf("det_filter enabled\n");
+			if(!det_tfilter){
+				det_tfilter = new_filter(0, DEFAULT_EDGE_FILTER_SIZE, tfilter_bitmap);
+				//printf("det_tfilter enabled\n");
+			}
+		}
+	}
+}
+
+static inline void init_det_filter(void){
+	int i;
+	for(i = 0; i < INTEL_PT_MAX_RANGES; i++){
+		if (det_filter_enabled[i]){
+			filter_init_new_exec(det_filter[i]);
+			filter_init_new_exec(det_tfilter);
+		}	
+	}
+}
+
+static inline void fin_det_filter(void){
+	//printf("%s \n", __func__);
+	for(int i = 0; i < INTEL_PT_MAX_RANGES; i++){
+		if (det_filter_enabled[i]){
+			filter_finalize_exec(det_filter[i]);
+			filter_finalize_exec(det_tfilter);
+		}
+	}
+}
+
+void hypercall_submit_address(uint64_t address){
+	for(int i = 0; i < INTEL_PT_MAX_RANGES; i++){
+		if(det_filter[i] && det_filter_enabled[i]){
+			//printf("%s %lx \n", __func__, address);
+			filter_add_address(det_filter[i], address);
+		}
+	}
+}
+
+void hypercall_submit_transition(uint32_t value){
+	for(int i = 0; i < INTEL_PT_MAX_RANGES; i++){
+		if(det_tfilter && det_filter_enabled[i]){
+			//printf("%s %lx \n", __func__, value);
+			filter_add_address(det_tfilter, value);
+		}
+	}
+}
+
+bool hypercall_check_tuple(uint64_t current_addr, uint64_t prev_addr){
+	for(int i = 0; i < INTEL_PT_MAX_RANGES; i++){
+		if(det_filter[i]){
+			if(filter_is_address_nondeterministic(det_filter[i], current_addr) ||  filter_is_address_nondeterministic(det_filter[i], prev_addr)){
+				return true;
+			}
+		}
+	}
+	return false;
+}
+
+bool hypercall_check_transition(uint64_t value){
+	for(int i = 0; i < INTEL_PT_MAX_RANGES; i++){
+		if(det_tfilter){
+			if(filter_is_address_nondeterministic(det_tfilter, value)){
+				return true;
+			}
+		}
+	}
+	return false;
+}
+
+
+void hypercall_check_in_range(uint64_t* addr){
+	for(int i = 0; i < INTEL_PT_MAX_RANGES; i++){
+		if (*addr < filter[i][0]){
+			*addr = filter[i][0];
+			return;
+		}
+
+		if (*addr > filter[i][1]){
+			*addr = filter[i][1];
+			return;
+		}
+	}
+}
+
+void hypercall_enable_filter(void){
+	for(int i = 0; i < INTEL_PT_MAX_RANGES; i++){
+		if(det_filter[i] && !det_filter_enabled[i]){
+			//printf("%s (%d)\n", __func__, i);
+			det_filter_enabled[i] = true;
+			filter_init_determinism_run(det_filter[i]);
+			filter_init_determinism_run(det_tfilter);
+		}
+	}
+}
+
+void hypercall_disable_filter(void){
+	for(int i = 0; i < INTEL_PT_MAX_RANGES; i++){
+		if(det_filter[i] && det_filter_enabled[i]){
+			//printf("%s (%d)\n", __func__, i);
+			filter_finalize_determinism_run(det_filter[i]);
+			if(!filter_count_new_addresses(det_filter[i])){
+				filter_finalize_determinism_run(det_tfilter);
+			}
+			det_filter_enabled[i] = false;
+		}
+	}
+}
+
+void hypercall_commit_filter(void){
+	fin_det_filter();
+}
+
+bool setup_snapshot_once = false;
+
+
+void pt_setup_program(void* ptr){
+	program_buffer = ptr;
+}
+
+void pt_setup_payload(void* ptr){
+	payload_buffer = ptr;
+}
+
+bool handle_hypercall_kafl_next_payload(struct kvm_run *run, CPUState *cpu){
+		if(hypercall_enabled){
+		if (init_state){
+			synchronization_lock(cpu);
+		} else {
+			if(!setup_snapshot_once){  //TODO???
+				pt_reset_bitmap();
+				/* decrease RIP value by vmcall instruction size */
+				X86CPU *x86_cpu = X86_CPU(cpu);
+				CPUX86State *env = &x86_cpu->env;
+				kvm_cpu_synchronize_state(cpu);
+				env->eip -= 3; /* vmcall size */
+				kvm_arch_put_registers(cpu, KVM_PUT_FULL_STATE);
+
+
+				setup_snapshot_once = true;
+				for(int i = 0; i < INTEL_PT_MAX_RANGES; i++){
+					//printf("=> %d\n", i);
+					if(filter_enabled[i]){
+#ifdef CONFIG_REDQUEEN
+						pt_enable_ip_filtering(cpu, i, filter[i][0], filter[i][1], true, false);
+#else					
+						pt_enable_ip_filtering(cpu, i, filter[i][0], filter[i][1], false);
+#endif			
+					}
+				}
+			}
+			else{
+				synchronization_lock(cpu);
+				write_virtual_memory_via_kvm((uint64_t)payload_buffer_guest, payload_buffer, PAYLOAD_SIZE, true, cpu);
+				return true;
+			}
+		}
+	}
+
+	return false;
+}
+
+ void handle_hypercall_kafl_acquire(struct kvm_run *run, CPUState *cpu){
+	if(hypercall_enabled){
+		if (!init_state){
+			init_det_filter();
+			if (pt_enable(cpu, false) == 0){
+				cpu->pt_enabled = true;
+			}
+	wait_hypercall_enabled();
+	if (!init_state){
+		init_det_filter();
+		if (pt_enable(cpu, false) == 0){
+			cpu->pt_enabled = true;
+ 				}
+ 			}
+ 		}
+	}
+ }
+
+void handle_hypercall_get_payload(struct kvm_run *run, CPUState *cpu){
+	if(hypercall_enabled){
+		printf("Get Payload...\n");
+		if(payload_buffer){
+			QEMU_PT_PRINTF(CORE_PREFIX, "Got payload address:\t%llx", run->hypercall.args[0]);
+			printf("Got payload address:\t%llx", run->hypercall.args[0]);
+			payload_buffer_guest = (void*)run->hypercall.args[0];
+			write_virtual_memory_via_kvm((uint64_t)payload_buffer_guest, payload_buffer, PAYLOAD_SIZE, true, cpu);
+		}
+		else {
+			printf("No payload buffer\n");
+		}
+	}
+}
+
+void handle_hypercall_get_program(struct kvm_run *run, CPUState *cpu){
+	printf("handle_hypercall_get_program: 0x%llx\n", run->hypercall.args[0]);
+	if(hypercall_enabled){
+		printf("Hypercall enabled...\n");
+		if(program_buffer){
+			cpu->disassembler_word_width = 64;	
+			printf("Got program address: 0x%llx, 0x%lx, 0x%lx\n", run->hypercall.args[0], ((char*)program_buffer)[0], ((char*)program_buffer)[1]);
+			QEMU_PT_PRINTF(CORE_PREFIX, "Got program address:\t%llx", run->hypercall.args[0]);
+			write_virtual_memory_via_kvm((uint64_t)run->hypercall.args[0], program_buffer, PROGRAM_SIZE, true, cpu);
+		}
+	}
+}
+
+void handle_hypercall_kafl_release(struct kvm_run *run, CPUState *cpu){
+	wait_hypercall_enabled();
+	if (init_state){
+		init_state = false;
+		hypercall_snd_char(KAFL_PROTO_RELEASE);
+	} else {
+		synchronization_disable_pt(cpu);
+	}
+}
+
+
+void handle_hypercall_kafl_cr3(struct kvm_run *run, CPUState *cpu){
+	if(hypercall_enabled){
+		QEMU_PT_PRINTF(CORE_PREFIX, "Got CR3 address:\t\t%llx", run->hypercall.args[0]);
+		pt_set_cr3(cpu, run->hypercall.args[0], false);
+
+		if (run->hypercall.longmode) {
+			QEMU_PT_PRINTF(CORE_PREFIX, "Auto-detected word width as 64bit (longmode=%d)", run->hypercall.longmode);
+			cpu->disassembler_word_width = 64;
+		} else {
+			QEMU_PT_PRINTF(CORE_PREFIX, "Auto-detected word width as 32bit (longmode=%d)", run->hypercall.longmode);
+			cpu->disassembler_word_width = 32;
+		}
+	}
+}
+
+void handle_hypercall_kafl_submit_panic(struct kvm_run *run, CPUState *cpu){
+	if(hypercall_enabled){
+		QEMU_PT_PRINTF(CORE_PREFIX, "NOT Patching PANIC address:\t%llx, longmode=%x", run->hypercall.args[0], run->hypercall.longmode);
+		/*if(notifiers_enabled){
+			if (run->hypercall.longmode) {
+				write_virtual_memory(run->hypercall.args[0], (uint8_t*)PANIC_PAYLOAD_64, PAYLOAD_BUFFER_SIZE, cpu);
+			} else {
+				write_virtual_memory(run->hypercall.args[0], (uint8_t*)PANIC_PAYLOAD_32, PAYLOAD_BUFFER_SIZE, cpu);
+			}
+		}
+		*/
+	}
+	
+}
+
+void handle_hypercall_kafl_submit_kasan(struct kvm_run *run, CPUState *cpu){
+	if(hypercall_enabled){
+		QEMU_PT_PRINTF(CORE_PREFIX, "Patching kASAN address:\t%llx, longmode=%x", run->hypercall.args[0], run->hypercall.longmode);
+		if(notifiers_enabled){
+			if (run->hypercall.longmode){
+				write_virtual_memory_via_kvm(run->hypercall.args[0], (uint8_t*)KASAN_PAYLOAD_64, PAYLOAD_BUFFER_SIZE, false, cpu);
+			} else {
+				write_virtual_memory_via_kvm(run->hypercall.args[0], (uint8_t*)KASAN_PAYLOAD_32, PAYLOAD_BUFFER_SIZE, false, cpu);
+			}
+		}
+	}
+}
+
+void handle_hypercall_kafl_panic(struct kvm_run *run, CPUState *cpu){
+	if(hypercall_enabled){
+		if(run->hypercall.args[0]){
+			QEMU_PT_DEBUG(CORE_PREFIX, "Panic in user mode!");
+			printf("Panic in user mode!\n");
+		} else{
+			QEMU_PT_DEBUG(CORE_PREFIX, "Panic in kernel mode!");
+			printf("Panic in kernel mode!\n");
+		}
+		synchronization_disable_pt(cpu);
+		hypercall_snd_char(KAFL_PROTO_CRASH);
+	}
+}
+
+void handle_hypercall_kafl_timeout(struct kvm_run *run, CPUState *cpu){
+	if(hypercall_enabled){
+		QEMU_PT_DEBUG(CORE_PREFIX, "Timeout detected!");
+		synchronization_disable_pt(cpu);
+		hypercall_snd_char(KAFL_PROTO_TIMEOUT);
+	}
+}
+
+void handle_hypercall_kafl_kasan(struct kvm_run *run, CPUState *cpu){
+	if(hypercall_enabled){
+		if(run->hypercall.args[0]){
+			QEMU_PT_DEBUG(CORE_PREFIX, "ASan notification in user mode!");
+		} else{
+			QEMU_PT_DEBUG(CORE_PREFIX, "ASan notification in kernel mode!");
+		}
+		synchronization_disable_pt(cpu);
+		hypercall_snd_char(KAFL_PROTO_KASAN);
+	}
+}
+
+void handle_hypercall_kafl_lock(struct kvm_run *run, CPUState *cpu){
+	if(create_snapshot_enabled){
+		Error *err = NULL;
+		printf("Creating snapshot <kafl> ...\n");
+		qemu_mutex_lock_iothread();
+		kvm_cpu_synchronize_state(cpu);
+		save_snapshot("kafl",
+                  true, NULL, false, NULL, &err);
+	if (err)
+		error_reportf_err(err, "Error: ");
+
+		qemu_mutex_unlock_iothread();
+		printf("Done. Shutting down..\n");
+		vm_stop(RUN_STATE_PAUSED);
+		qemu_system_shutdown_request(SHUTDOWN_CAUSE_HOST_SIGNAL);
+	}
+}
+
+void handle_hypercall_kafl_info(struct kvm_run *run, CPUState *cpu){
+	read_virtual_memory_via_kvm((uint64_t)run->hypercall.args[0], (uint8_t*)info_buffer, INFO_SIZE, true, cpu);
+	FILE* info_file_fd = fopen(INFO_FILE, "w");
+	fprintf(info_file_fd, "%s\n", info_buffer);
+	fclose(info_file_fd);
+	if(hypercall_enabled){
+		hypercall_snd_char(KAFL_PROTO_INFO);
+	}
+	qemu_system_shutdown_request(SHUTDOWN_CAUSE_HOST_SIGNAL);
+}
+
+void handle_hypercall_kafl_crash_dump_size(struct kvm_run *run, CPUState *cpu){
+	crash_dump_size = (uint64_t)run->hypercall.args[0];
+	//QEMU_PT_PRINTF(CORE_PREFIX, "Got Crash Dump Size Hypercall: 0x%x!", crash_dump_size);
+	printf("Got Crash Dump Size Hypercall: 0x%x!\n", crash_dump_size);
+	hypercall_snd_char(KAFL_PROTO_CRASH_DUMP);
+}
+
+void handle_hypercall_kafl_crash_dump_offset(struct kvm_run *run, CPUState *cpu){
+	crash_dump_offset = (uint64_t)run->hypercall.args[0];
+	QEMU_PT_PRINTF(CORE_PREFIX, "Got Crash Dump Offset Hypercall: 0x%x!", crash_dump_offset);
+	hypercall_snd_char(KAFL_PROTO_CRASH_DUMP);
+}
+
+void handle_hypercall_kafl_crash_dump(struct kvm_run *run, CPUState *cpu){
+	char crashPath[256] = {0};
+	int32_t pid = (int32_t)getpid();
+	sprintf(crashPath, "/root/tmp_crashes/%d.log", pid);
+	QEMU_PT_PRINTF(CORE_PREFIX, "Got Crash Dump Hypercall!");
+	char *crash_dump_buffer = NULL;
+	crash_dump_buffer = (char*)malloc(crash_dump_size);
+	memset(crash_dump_buffer, 0, crash_dump_size);
+	read_virtual_memory_via_kvm((uint64_t)run->hypercall.args[0], (uint8_t*)crash_dump_buffer, crash_dump_size, false, cpu);
+	FILE* crash_dump_fd = fopen(crashPath, "a+b");
+	fwrite(crash_dump_buffer, crash_dump_size, 1, crash_dump_fd);
+ 	fflush(crash_dump_fd);
+	fclose(crash_dump_fd);
+	free(crash_dump_buffer);
+	hypercall_snd_char(KAFL_PROTO_CRASH_DUMP);
+
+}
+
+void enable_hprintf(void){
+	QEMU_PT_DEBUG(CORE_PREFIX, "Enable hprintf support");
+	hprintf_enabled = true;
+}
+
+void enable_notifies(void){
+	notifiers_enabled = true;
+}
+
+void enable_reload_mode(void){
+	assert(false);
+}
+
+void hprintf(char* msg){
+	char file_name[256];
+	if(!(hprintf_counter >= HPRINTF_LIMIT) && hprintf_enabled){
+		if(hypercall_enabled){
+			snprintf(file_name, 256, "%s.%d", HPRINTF_FILE, hprintf_counter);
+			//printf("%s: %s\n", __func__, msg);
+			FILE* printf_file_fd = fopen(file_name, "w");
+			fprintf(printf_file_fd, "%s", msg);
+			fclose(printf_file_fd);
+			hypercall_snd_char(KAFL_PROTO_PRINTF);
+		}
+		hprintf_counter++;
+	}
+}
+
+void handle_hypercall_kafl_printf(struct kvm_run *run, CPUState *cpu){
+	//printf("%s\n", __func__);
+	if(!(hprintf_counter >= HPRINTF_LIMIT) && hprintf_enabled){
+		read_virtual_memory_via_kvm((uint64_t)run->hypercall.args[0], (uint8_t*)hprintf_buffer, HPRINTF_SIZE, true, cpu);
+		hprintf(hprintf_buffer);
+	}
+}
+
+
+void handle_hypercall_kafl_printk(struct kvm_run *run, CPUState *cpu){
+	if(!notifiers_enabled){
+		if (hypercall_enabled && hprintf_enabled){
+			if(kafl_linux_printk(cpu)){
+				handle_hypercall_kafl_panic(run, cpu);
+			}
+		}
+	}
+}
+
+void handle_hypercall_kafl_printk_addr(struct kvm_run *run, CPUState *cpu){
+	if(!notifiers_enabled){
+		printf("%s\n", __func__);
+		printf("%lx\n", (uint64_t)run->hypercall.args[0]);
+		write_virtual_memory_via_kvm((uint64_t)run->hypercall.args[0], (uint8_t*)PRINTK_PAYLOAD, PRINTK_PAYLOAD_SIZE, false, cpu);
+		printf("Done\n");
+	}		
+}
+
+void handle_hypercall_kafl_user_range_advise(struct kvm_run *run, CPUState *cpu){
+	kAFL_ranges* buf = malloc(sizeof(kAFL_ranges));
+
+	for(int i = 0; i < INTEL_PT_MAX_RANGES; i++){
+		buf->ip[i] = filter[i][0];
+		buf->size[i] = (filter[i][1]-filter[i][0]);
+		buf->enabled[i] = (uint8_t)filter_enabled[i];
+	}
+
+	write_virtual_memory_via_kvm((uint64_t)run->hypercall.args[0], (uint8_t *)buf, sizeof(kAFL_ranges), true, cpu);
+}
+
+void handle_hypercall_kafl_user_submit_mode(struct kvm_run *run, CPUState *cpu){
+	//printf("%s\n", __func__);
+	switch((uint64_t)run->hypercall.args[0]){
+		case KAFL_MODE_64:
+			QEMU_PT_PRINTF(CORE_PREFIX, "Target reports 64bit word width");
+			cpu->disassembler_word_width = 64;
+			break;
+		case KAFL_MODE_32:
+			QEMU_PT_PRINTF(CORE_PREFIX, "Target reports 32bit word width");
+			cpu->disassembler_word_width = 32;
+			break;
+		case KAFL_MODE_16:
+			QEMU_PT_PRINTF(CORE_PREFIX, "Target reports 16bit word width");
+			cpu->disassembler_word_width = 16;
+			break;
+		default:
+			QEMU_PT_ERROR(CORE_PREFIX, "Error: target uses unknown word width!");
+			cpu->disassembler_word_width = -1;
+			break;
+	}
+}
+
+void handle_hypercall_kafl_user_abort(struct kvm_run *run, CPUState *cpu){
+	if(hypercall_enabled){
+		hypercall_snd_char(KAFL_PROTO_PT_ABORT);
+	}
+	qemu_system_shutdown_request(SHUTDOWN_CAUSE_HOST_SIGNAL);
+}
+
+#ifdef CONFIG_REDQUEEN
+bool handle_hypercall_kafl_hook(struct kvm_run *run, CPUState *cpu){
+	X86CPU *cpux86 = X86_CPU(cpu);
+	CPUX86State *env = &cpux86->env;
+
+	for(uint8_t i = 0; i < INTEL_PT_MAX_RANGES; i++){
+		if (cpu->redqueen_state[i]){
+			if (((env->eip >= cpu->pt_ip_filter_a[i]) && (env->eip <= cpu->pt_ip_filter_b[i])) ||
+				(cpu->singlestep_enabled && ((redqueen_t*)cpu->redqueen_state[i])->singlestep_enabled)){
+				handle_hook(cpu->redqueen_state[i]);
+				return true;
+			}
+		}
+	}
+	return false;
+}
+
+void pt_enable_rqi(CPUState *cpu){
+	((uint8_t*) payload_buffer)[PAYLOAD_SIZE-1] = 1;
+	cpu->redqueen_enable_pending = true;
+}
+
+void pt_disable_rqi(CPUState *cpu){
+	cpu->redqueen_disable_pending = true;
+	cpu->redqueen_instrumentation_mode = REDQUEEN_NO_INSTRUMENTATION;
+	((uint8_t*) payload_buffer)[PAYLOAD_SIZE-1] = 0;
+
+}
+
+void pt_set_enable_patches_pending(CPUState *cpu){
+	cpu->patches_enable_pending = true;
+}
+
+void pt_set_redqueen_instrumentation_mode(CPUState *cpu, int redqueen_mode){
+	cpu->redqueen_instrumentation_mode = redqueen_mode;
+}
+
+void pt_set_redqueen_update_blacklist(CPUState *cpu, bool newval){
+	assert(!newval || !cpu->redqueen_update_blacklist);
+	cpu->redqueen_update_blacklist = newval;
+}
+
+void pt_set_disable_patches_pending(CPUState *cpu){
+	cpu->patches_disable_pending = true;
+}
+
+void pt_enable_rqi_trace(CPUState *cpu){
+	for(uint8_t i = 0; i < INTEL_PT_MAX_RANGES; i++){
+		if (cpu->redqueen_state[i]) {
+			redqueen_set_trace_mode((redqueen_t*)cpu->redqueen_state[i]);
+		}
+	}
+}
+
+void pt_disable_rqi_trace(CPUState *cpu){
+	for(uint8_t i = 0; i < INTEL_PT_MAX_RANGES; i++){
+		if (cpu->redqueen_state[i] ){
+			((redqueen_t*)cpu->redqueen_state[i])->trace_mode = false;
+			return;
+		}
+	}
+}
+
+#endif
diff --git a/pt/hypercall.h b/pt/hypercall.h
new file mode 100644
index 000000000..1bb800c71
--- /dev/null
+++ b/pt/hypercall.h
@@ -0,0 +1,153 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later 
+ */
+
+#ifndef HYPERCALL_H
+#define HYPERCALL_H
+
+#define PAYLOAD_BUFFER_SIZE		26
+#define PRINTK_PAYLOAD_SIZE		4
+
+#define KAFL_MODE_64	0
+#define KAFL_MODE_32	1
+#define KAFL_MODE_16	2
+
+typedef struct{
+	uint64_t ip[4];
+	uint64_t size[4];
+	uint8_t enabled[4];
+} kAFL_ranges; 
+
+//#define PANIC_DEBUG
+
+/*
+ * Panic Notifier Payload (x86-64)
+ * fa                      cli
+ * 48 c7 c0 1f 00 00 00    mov    rax,0x1f
+ * 48 c7 c3 08 00 00 00    mov    rbx,0x8
+ * 48 c7 c1 00 00 00 00    mov    rcx,0x0
+ * 0f 01 c1                vmcall
+ * f4                      hlt
+ */
+#define PANIC_PAYLOAD_64 "\xFA\x48\xC7\xC0\x1F\x00\x00\x00\x48\xC7\xC3\x08\x00\x00\x00\x48\xC7\xC1\x00\x00\x00\x00\x0F\x01\xC1\xF4"
+
+/*
+ * Panic Notifier Payload (x86-32)
+ * fa                      cli
+ * b8 1f 00 00 00          mov    $0x1f,%eax
+ * bb 08 00 00 00          mov    $0x8,%ebx
+ * b9 00 00 00 00          mov    $0x0,%ecx
+ * 0f 01 c1                vmcall
+ * f4                      hlt
+ */
+#define PANIC_PAYLOAD_32 "\xFA\xB8\x1F\x00\x00\x00\xBB\x08\x00\x00\x00\xB9\x00\x00\x00\x00\x0F\x01\xC1\xF4"
+
+/*
+ * KASAN Notifier Payload (x86-64)
+ * fa                      cli
+ * 48 c7 c0 1f 00 00 00    mov    rax,0x1f
+ * 48 c7 c3 09 00 00 00    mov    rbx,0x9
+ * 48 c7 c1 00 00 00 00    mov    rcx,0x0
+ * 0f 01 c1                vmcall
+ * f4                      hlt
+ */
+#define KASAN_PAYLOAD_64 "\xFA\x48\xC7\xC0\x1F\x00\x00\x00\x48\xC7\xC3\x09\x00\x00\x00\x48\xC7\xC1\x00\x00\x00\x00\x0F\x01\xC1\xF4"
+
+/*
+ * KASAN Notifier Payload (x86-32)
+ * fa                      cli
+ * b8 1f 00 00 00          mov    $0x1f,%eax
+ * bb 09 00 00 00          mov    $0x9,%ebx
+ * b9 00 00 00 00          mov    $0x0,%ecx
+ * 0f 01 c1                vmcall
+ * f4                      hlt
+ */
+#define KASAN_PAYLOAD_32 "\xFA\xB8\x1F\x00\x00\x00\xBB\x09\x00\x00\x00\xB9\x00\x00\x00\x00\x0F\x01\xC1\xF4"
+
+/*
+ * printk Notifier Payload (x86-64)
+ * 0f 01 c1                vmcall
+ * c3                      retn
+ */
+#define PRINTK_PAYLOAD "\x0F\x01\xC1\xC3"
+
+void pt_setup_program(void* ptr);
+void pt_setup_payload(void* ptr);
+void pt_setup_snd_handler(void (*tmp)(char, void*), void* tmp_s);
+void pt_setup_ip_filters(uint8_t filter_id, uint64_t start, uint64_t end, void* filter_bitmap, void* tfilter_bitmap);
+void pt_setup_enable_hypercalls(void);
+
+void pt_disable_wrapper(CPUState *cpu);
+
+void hypercall_submit_address(uint64_t address);
+bool hypercall_check_tuple(uint64_t current_addr, uint64_t prev_addr);
+void hypercall_check_in_range(uint64_t* addr);
+
+
+bool hypercall_check_transition(uint64_t value);
+void hypercall_submit_transition(uint32_t value);
+
+void hypercall_enable_filter(void);
+void hypercall_disable_filter(void);
+void hypercall_commit_filter(void);
+
+bool pt_hypercalls_enabled(void);
+
+void hypercall_unlock(void);
+void hypercall_reload(void);
+
+void handle_hypercall_kafl_acquire(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_get_payload(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_get_program(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_release(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_cr3(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_submit_panic(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_submit_kasan(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_panic(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_kasan(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_timeout(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_lock(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_info(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_printf(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_printk_addr(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_printk(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_user_range_advise(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_user_submit_mode(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_user_abort(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_crash_dump(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_crash_dump_size(struct kvm_run *run, CPUState *cpu);
+void handle_hypercall_kafl_crash_dump_offset(struct kvm_run *run, CPUState *cpu);
+int handle_hypercall_get_hello_world(struct kvm_run *run, CPUState *cpu);
+
+void hprintf(char* msg);
+void enable_hprintf(void);
+void enable_notifies(void);
+void enable_reload_mode(void);
+void pt_setup_disable_create_snapshot(void);
+
+bool handle_hypercall_kafl_next_payload(struct kvm_run *run, CPUState *cpu);
+void hypercall_reset_hprintf_counter(void);
+bool hypercall_snd_char(char val);
+
+#ifdef CONFIG_REDQUEEN
+
+
+bool handle_hypercall_kafl_hook(struct kvm_run *run, CPUState *cpu);
+bool handle_hypercall_kafl_mtf(struct kvm_run *run, CPUState *cpu);
+void pt_enable_rqo(CPUState *cpu);
+void pt_disable_rqo(CPUState *cpu);
+void pt_enable_rqi(CPUState *cpu);
+void pt_disable_rqi(CPUState *cpu);
+void pt_enable_rqi_trace(CPUState *cpu);
+void pt_disable_rqi_trace(CPUState *cpu);
+void pt_set_redqueen_instrumentation_mode(CPUState *cpu, int redqueen_instruction_mode);
+void pt_set_redqueen_update_blacklist(CPUState *cpu, bool newval);
+void pt_set_enable_patches_pending(CPUState *cpu);
+void pt_set_disable_patches_pending(CPUState *cpu);
+#endif
+#endif
diff --git a/pt/interface.c b/pt/interface.c
new file mode 100644
index 000000000..320cacbb2
--- /dev/null
+++ b/pt/interface.c
@@ -0,0 +1,408 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later 
+ */
+
+#include "qemu/osdep.h"
+#include "qapi/error.h"
+#include "qemu/cutils.h"
+#include "hw/hw.h"
+#include "hw/i386/pc.h"
+#include "hw/pci/pci.h"
+#include "hw/pci/msi.h"
+#include "hw/pci/msix.h"
+#include "hw/qdev-properties-system.h"
+#include "hw/qdev-properties.h"
+#include "sysemu/kvm.h"
+#include "migration/migration.h"
+#include "qemu/error-report.h"
+#include "qemu/event_notifier.h"
+#include "qom/object_interfaces.h"
+#include "chardev/char-fe.h"
+#include "sysemu/hostmem.h"
+#include "sysemu/qtest.h"
+#include "qapi/visitor.h"
+#include "exec/ram_addr.h"
+#include <sys/mman.h>
+#include <sys/stat.h>
+#include "pt.h"
+#include "pt/hypercall.h"
+#include "pt/filter.h"
+#include "pt/interface.h"
+#include "pt/debug.h"
+#include "pt/synchronization.h"
+#include "pt/asm_decoder.h"
+
+#include <time.h>
+
+#ifdef CONFIG_REDQUEEN
+#include "redqueen.h"
+#endif
+
+#define CONVERT_UINT64(x) (uint64_t)(strtoull(x, NULL, 16))
+
+#define TYPE_KAFLMEM "kafl"
+#define KAFLMEM(obj) \
+		OBJECT_CHECK(kafl_mem_state, (obj), TYPE_KAFLMEM)
+
+uint32_t kafl_bitmap_size = DEFAULT_KAFL_BITMAP_SIZE;
+
+static void pci_kafl_guest_realize(DeviceState *dev, Error **errp);
+
+typedef struct kafl_mem_state {
+	DeviceState parent_obj;
+
+	Chardev *kafl_chr_drv_state;
+	CharBackend chr;
+	
+	char* redqueen_workdir;
+	char* data_bar_fd_0;
+	char* data_bar_fd_1;
+	char* data_bar_fd_2;
+	char* bitmap_file;
+
+	char* filter_bitmap[4];
+	char* ip_filter[4][2];
+
+	bool irq_filter;
+	uint64_t bitmap_size;
+
+	bool debug_mode; 	/* support for hprintf */
+	bool notifier;
+	bool reload_mode;
+	bool disable_snapshot;
+	bool lazy_vAPIC_reset;
+
+#ifdef CONFIG_REDQUEEN
+	bool redqueen;
+#endif
+	
+} kafl_mem_state;
+
+static void kafl_guest_event(void *opaque, QEMUChrEvent event){
+}
+
+static void send_char(char val, void* tmp_s){
+        //debugging_code
+        int res;
+	kafl_mem_state *s = tmp_s;
+	res = qemu_chr_fe_write(&s->chr, (const uint8_t *) &val, 1);
+        printf("send char: %c, res: %d\n", val, res);
+}
+
+static int kafl_guest_can_receive(void * opaque){
+	return sizeof(int64_t);
+}
+
+static void kafl_guest_receive(void *opaque, const uint8_t * buf, int size){
+	kafl_mem_state *s = opaque;
+	int i;				
+	for(i = 0; i < size; i++){
+		printf("kafl_guest_receive: %c\n", buf[i]);
+		switch(buf[i]){
+			case KAFL_PROTO_RELEASE:
+				synchronization_unlock();
+				break;
+
+			case KAFL_PROTO_RELOAD:
+				assert(false);
+				synchronization_reload_vm();
+				break;
+
+			/* active sampling mode */
+			case KAFL_PROTO_ENABLE_SAMPLING:	
+				hypercall_enable_filter();
+				break;
+
+			/* deactivate sampling mode */
+			case KAFL_PROTO_DISABLE_SAMPLING:
+				hypercall_disable_filter();
+				break;
+
+			/* commit sampling result */
+			case KAFL_PROTO_COMMIT_FILTER:
+				hypercall_commit_filter();
+				break;
+
+			/* fuzzer frontend has connected */
+			case KAFL_PROTO_CONNECT:
+				pt_setup_enable_hypercalls();
+				break;
+
+			/* finalize iteration (dump and decode PT data) in case of timeouts */
+			case KAFL_PROTO_FINALIZE:
+				synchronization_disable_pt(qemu_get_cpu(0));
+				send_char(KAFL_PROTO_FINALIZE, s);
+				break;
+#ifdef CONFIG_REDQUEEN
+				
+			/* enable redqueen intercept mode */
+			case KAFL_PROTO_ENABLE_RQI_MODE:
+				QEMU_PT_DEBUG(REDQUEEN_PREFIX, "proto enable rqi");
+				assert(qemu_get_cpu(0)->redqueen_instrumentation_mode != REDQUEEN_NO_INSTRUMENTATION);
+				pt_enable_rqi(qemu_get_cpu(0));
+				send_char(KAFL_PROTO_ENABLE_RQI_MODE, s);
+				break;
+
+			/* disable redqueen intercept mode */
+			case KAFL_PROTO_DISABLE_RQI_MODE:
+				QEMU_PT_DEBUG(REDQUEEN_PREFIX, "proto disable rqi");
+				pt_set_redqueen_instrumentation_mode(qemu_get_cpu(0),REDQUEEN_NO_INSTRUMENTATION);
+				pt_set_redqueen_update_blacklist(qemu_get_cpu(0), false);
+				pt_disable_rqi(qemu_get_cpu(0));
+				send_char(KAFL_PROTO_DISABLE_RQI_MODE, s);
+				break;
+
+			case KAFL_PROTO_REDQUEEN_SET_LIGHT_INSTRUMENTATION:
+				QEMU_PT_DEBUG(REDQUEEN_PREFIX, "proto set light");
+				pt_set_redqueen_instrumentation_mode(qemu_get_cpu(0),REDQUEEN_LIGHT_INSTRUMENTATION);
+				send_char(KAFL_PROTO_REDQUEEN_SET_LIGHT_INSTRUMENTATION, s);
+				break;
+
+			case KAFL_PROTO_REDQUEEN_SET_SE_INSTRUMENTATION:
+				QEMU_PT_DEBUG(REDQUEEN_PREFIX, "proto set se");
+				pt_set_redqueen_instrumentation_mode(qemu_get_cpu(0),REDQUEEN_SE_INSTRUMENTATION);
+				send_char(KAFL_PROTO_REDQUEEN_SET_SE_INSTRUMENTATION, s);
+				break;
+
+			case KAFL_PROTO_REDQUEEN_SET_WHITELIST_INSTRUMENTATION:
+				QEMU_PT_DEBUG(REDQUEEN_PREFIX, "proto set whitelist");
+				pt_set_redqueen_instrumentation_mode(qemu_get_cpu(0),REDQUEEN_WHITELIST_INSTRUMENTATION);
+				send_char(KAFL_PROTO_REDQUEEN_SET_WHITELIST_INSTRUMENTATION, s);
+				break;
+
+			case KAFL_PROTO_REDQUEEN_SET_BLACKLIST:
+				QEMU_PT_DEBUG(REDQUEEN_PREFIX, "proto set blacklist");
+				pt_set_redqueen_update_blacklist(qemu_get_cpu(0), true);
+				send_char(KAFL_PROTO_REDQUEEN_SET_BLACKLIST, s);
+				break;
+
+			/* enable symbolic execution mode */
+			case KAFL_PROTO_ENABLE_TRACE_MODE:
+				QEMU_PT_DEBUG(REDQUEEN_PREFIX, "proto enable trace");
+				pt_enable_rqi_trace(qemu_get_cpu(0));
+				send_char(KAFL_PROTO_ENABLE_TRACE_MODE, s);
+				break;
+
+			/* disable symbolic execution mode */
+			case KAFL_PROTO_DISABLE_TRACE_MODE:
+				QEMU_PT_DEBUG(REDQUEEN_PREFIX, "proto disable trace");
+				pt_disable_rqi_trace(qemu_get_cpu(0));
+				send_char(KAFL_PROTO_DISABLE_TRACE_MODE, s);
+				break;
+			/* apply patches to target */
+			case KAFL_PROTO_ENABLE_PATCHES:
+				QEMU_PT_DEBUG(REDQUEEN_PREFIX, "proto patches enable");
+				pt_set_enable_patches_pending(qemu_get_cpu(0));
+				send_char(KAFL_PROTO_ENABLE_PATCHES, s);
+				break;
+
+			/* remove all patches from the target */
+			case KAFL_PROTO_DISABLE_PATCHES:
+				QEMU_PT_DEBUG(REDQUEEN_PREFIX, "proto patches disable");
+				pt_set_disable_patches_pending(qemu_get_cpu(0));
+				send_char(KAFL_PROTO_DISABLE_PATCHES, s);
+				break;
+#endif
+		}
+	}
+}
+
+static int kafl_guest_create_memory_bar(kafl_mem_state *s, int region_num, uint64_t bar_size, const char* file, Error **errp){
+	void * ptr;
+	int fd;
+	struct stat st;
+	
+	fd = open(file, O_CREAT|O_RDWR, S_IRWXU|S_IRWXG|S_IRWXO);
+	assert(ftruncate(fd, bar_size) == 0);
+	stat(file, &st);
+	QEMU_PT_DEBUG(INTERFACE_PREFIX, "new shm file: (max size: %lx) %lx", bar_size, st.st_size);
+	
+	assert(bar_size >= st.st_size);
+	ptr = mmap(0, bar_size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);
+	if (ptr == MAP_FAILED) {
+		error_setg_errno(errp, errno, "Failed to mmap memory");
+		return -1;
+	}
+
+	switch(region_num){
+		case 1:	pt_setup_program((void*)ptr);
+				break;
+		case 2:	pt_setup_payload((void*)ptr);
+				break;
+	}
+
+	pt_setup_snd_handler(&send_char, s);
+
+	return 0;
+}
+
+static int kafl_guest_setup_bitmap(kafl_mem_state *s, uint32_t bitmap_size, Error **errp){
+	void * ptr;
+	int fd;
+	struct stat st;
+	
+	fd = open(s->bitmap_file, O_CREAT|O_RDWR, S_IRWXU|S_IRWXG|S_IRWXO);
+	assert(ftruncate(fd, bitmap_size) == 0);
+	stat(s->bitmap_file, &st);
+	assert(bitmap_size == st.st_size);
+	ptr = mmap(0, bitmap_size, PROT_READ|PROT_WRITE, MAP_SHARED, fd, 0);
+	if (ptr == MAP_FAILED) {
+		error_setg_errno(errp, errno, "Failed to mmap memory");
+		return -1;
+	}
+	pt_setup_bitmap((void*)ptr);
+
+	return 0;
+}
+
+static void* kafl_guest_setup_filter_bitmap(kafl_mem_state *s, char* filter, uint64_t size){
+	void * ptr;
+	int fd;
+	struct stat st;
+	
+	QEMU_PT_DEBUG(INTERFACE_PREFIX, "setup filter file: %s", filter);
+	fd = open(filter, O_CREAT|O_RDWR, S_IRWXU|S_IRWXG|S_IRWXO);
+	stat(filter, &st);
+	if (st.st_size != size){
+		assert(ftruncate(fd, size) == 0);
+	}
+	ptr = mmap(NULL, size, PROT_READ|PROT_WRITE, MAP_SHARED, fd, 0);
+	QEMU_PT_DEBUG(INTERFACE_PREFIX, "filter file size: %lx (addr: %p)", size, ptr);
+	return ptr;
+	//pt_setup_bitmap((void*)ptr);
+}
+
+static void pci_kafl_guest_realize(DeviceState *dev, Error **errp){
+	uint64_t tmp0, tmp1;
+	kafl_mem_state *s = KAFLMEM(dev);
+	void* tmp = NULL;
+
+	void* tfilter = kafl_guest_setup_filter_bitmap(s, (char*) "/dev/shm/kafl_tfilter", DEFAULT_EDGE_FILTER_SIZE);
+
+	if(s->bitmap_size <= 0){
+		s->bitmap_size = DEFAULT_KAFL_BITMAP_SIZE;
+	}
+	kafl_bitmap_size = (uint32_t)s->bitmap_size;
+	
+	if (s->data_bar_fd_0 != NULL)
+		kafl_guest_create_memory_bar(s, 1, PROGRAM_SIZE, s->data_bar_fd_0, errp);
+	if (s->data_bar_fd_1 != NULL)
+		kafl_guest_create_memory_bar(s, 2, PAYLOAD_SIZE, s->data_bar_fd_1, errp);
+#ifdef CONFIG_REDQUEEN
+	if (s->redqueen_workdir){
+		setup_redqueen_workdir(s->redqueen_workdir);
+	}
+#endif
+	
+	if(&s->chr)
+		qemu_chr_fe_set_handlers(&s->chr, kafl_guest_can_receive, kafl_guest_receive, kafl_guest_event, NULL, s, NULL, true);
+	if(s->bitmap_file)
+		kafl_guest_setup_bitmap(s, kafl_bitmap_size, errp);
+
+	for(uint8_t i = 0; i < INTEL_PT_MAX_RANGES; i++){
+		if(s->ip_filter[i][0] && s->ip_filter[i][1]){
+			tmp0 = CONVERT_UINT64(s->ip_filter[i][0]);
+			tmp1 = CONVERT_UINT64(s->ip_filter[i][1]);
+			if (tmp0 < tmp1){
+				tmp = NULL;
+				if(s->filter_bitmap[i]){
+					tmp = kafl_guest_setup_filter_bitmap(s, s->filter_bitmap[i], (uint64_t)(tmp1-tmp0));
+				}
+				pt_setup_ip_filters(i, tmp0, tmp1, tmp, tfilter);
+			}
+		}
+	}
+
+	if(s->irq_filter){
+	}
+
+	if(s->debug_mode){
+		enable_hprintf();
+	}
+
+	if(s->notifier){
+		enable_notifies();
+	}
+
+	if(s->reload_mode){
+		enable_reload_mode();
+	}
+
+	if(s->disable_snapshot){
+		pt_setup_disable_create_snapshot();
+	}
+
+	if(s->lazy_vAPIC_reset){
+    assert(false);
+	}
+
+
+	//pt_setup_enable_hypercalls();
+	asm_decoder_compile();
+}
+
+static Property kafl_guest_properties[] = {
+	DEFINE_PROP_CHR("chardev", kafl_mem_state, chr),
+	DEFINE_PROP_STRING("redqueen_workdir", kafl_mem_state, redqueen_workdir),
+	DEFINE_PROP_STRING("shm0", kafl_mem_state, data_bar_fd_0),
+	DEFINE_PROP_STRING("shm1", kafl_mem_state, data_bar_fd_1),
+	DEFINE_PROP_STRING("bitmap", kafl_mem_state, bitmap_file),
+	DEFINE_PROP_STRING("filter0", kafl_mem_state, filter_bitmap[0]),
+	DEFINE_PROP_STRING("filter1", kafl_mem_state, filter_bitmap[1]),
+	DEFINE_PROP_STRING("filter2", kafl_mem_state, filter_bitmap[2]),
+	DEFINE_PROP_STRING("filter3", kafl_mem_state, filter_bitmap[3]),
+	/* 
+	 * Since DEFINE_PROP_UINT64 is somehow broken (signed/unsigned madness),
+	 * let's use DEFINE_PROP_STRING and post-process all values via strtol...
+	 */
+	DEFINE_PROP_STRING("ip0_a", kafl_mem_state, ip_filter[0][0]),
+	DEFINE_PROP_STRING("ip0_b", kafl_mem_state, ip_filter[0][1]),
+	DEFINE_PROP_STRING("ip1_a", kafl_mem_state, ip_filter[1][0]),
+	DEFINE_PROP_STRING("ip1_b", kafl_mem_state, ip_filter[1][1]),
+	DEFINE_PROP_STRING("ip2_a", kafl_mem_state, ip_filter[2][0]),
+	DEFINE_PROP_STRING("ip2_b", kafl_mem_state, ip_filter[2][1]),
+	DEFINE_PROP_STRING("ip3_a", kafl_mem_state, ip_filter[3][0]),
+	DEFINE_PROP_STRING("ip3_b", kafl_mem_state, ip_filter[3][1]),
+	DEFINE_PROP_BOOL("irq_filter", kafl_mem_state, irq_filter, false),
+	DEFINE_PROP_UINT64("bitmap_size", kafl_mem_state, bitmap_size, DEFAULT_KAFL_BITMAP_SIZE),
+	DEFINE_PROP_BOOL("debug_mode", kafl_mem_state, debug_mode, false),
+	DEFINE_PROP_BOOL("crash_notifier", kafl_mem_state, notifier, true),
+	DEFINE_PROP_BOOL("reload_mode", kafl_mem_state, reload_mode, true),
+	DEFINE_PROP_BOOL("disable_snapshot", kafl_mem_state, disable_snapshot, false),
+	DEFINE_PROP_BOOL("lazy_vAPIC_reset", kafl_mem_state, lazy_vAPIC_reset, false),
+
+	DEFINE_PROP_END_OF_LIST(),
+};
+
+static void kafl_guest_class_init(ObjectClass *klass, void *data){
+	DeviceClass *dc = DEVICE_CLASS(klass);
+	//PCIDeviceClass *k = PCI_DEVICE_CLASS(klass);
+	dc->realize = pci_kafl_guest_realize;
+	//k->class_id = PCI_CLASS_MEMORY_RAM;
+	//dc->props = kafl_guest_properties;
+	device_class_set_props(dc, kafl_guest_properties);
+	set_bit(DEVICE_CATEGORY_MISC, dc->categories);
+	dc->desc = "KAFL Inter-VM shared memory";
+}
+
+static void kafl_guest_init(Object *obj){
+}
+
+static const TypeInfo kafl_guest_info = {
+	.name          = TYPE_KAFLMEM,
+	.parent        = TYPE_DEVICE,
+	.instance_size = sizeof(kafl_mem_state),
+	.instance_init = kafl_guest_init,
+	.class_init    = kafl_guest_class_init,
+};
+
+static void kafl_guest_register_types(void){
+	type_register_static(&kafl_guest_info);
+}
+
+type_init(kafl_guest_register_types)
diff --git a/pt/interface.h b/pt/interface.h
new file mode 100644
index 000000000..d99ce50fa
--- /dev/null
+++ b/pt/interface.h
@@ -0,0 +1,70 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later 
+ */
+
+
+#ifndef INTERFACE_H
+#define INTERFACE_H
+
+#define INTEL_PT_MAX_RANGES			4
+
+#define DEFAULT_KAFL_BITMAP_SIZE	0x10000
+#define DEFAULT_EDGE_FILTER_SIZE	0x1000000
+
+#define PROGRAM_SIZE				(10 << 20) /* 128MB Application Data */
+#define PAYLOAD_SIZE				(128 << 10)	/* 128KB Payload Data */
+#define INFO_SIZE					(128 << 10)	/* 128KB Info Data */
+#define HPRINTF_SIZE				0x1000 		/* 4KB hprintf Data */
+
+#define INFO_FILE					"/tmp/kAFL_info.txt"
+#define HPRINTF_FILE				"/tmp/kAFL_printf.txt"
+
+#define HPRINTF_LIMIT				512
+
+
+#define KAFL_PROTO_ACQUIRE			'R'
+#define KAFL_PROTO_RELEASE			'D'
+
+#define KAFL_PROTO_RELOAD			'L'
+#define KAFL_PROTO_ENABLE_SAMPLING	'S'
+#define KAFL_PROTO_DISABLE_SAMPLING	'O'
+#define KAFL_PROTO_COMMIT_FILTER	'T'
+#define KAFL_PROTO_FINALIZE			'F'
+#define KAFL_PROTO_CONNECT			'J'
+
+#ifdef CONFIG_REDQUEEN
+#define KAFL_PROTO_ENABLE_RQI_MODE	'A'
+#define KAFL_PROTO_DISABLE_RQI_MODE	'B'
+#define KAFL_PROTO_ENABLE_TRACE_MODE 'E'
+#define KAFL_PROTO_DISABLE_TRACE_MODE 'G'
+#define KAFL_PROTO_ENABLE_PATCHES 'P'
+#define KAFL_PROTO_DISABLE_PATCHES 'Q'
+#define KAFL_PROTO_REDQUEEN_SET_LIGHT_INSTRUMENTATION     'U'
+#define KAFL_PROTO_REDQUEEN_SET_SE_INSTRUMENTATION        'V'
+#define KAFL_PROTO_REDQUEEN_SET_WHITELIST_INSTRUMENTATION 'W'
+#define KAFL_PROTO_REDQUEEN_SET_BLACKLIST 'X'
+#endif
+
+#define KAFL_PROTO_CRASH_DUMP			'Y'
+
+#define KAFL_PROTO_CRASH			'C'
+#define KAFL_PROTO_KASAN			'K'
+#define KAFL_PROTO_TIMEOUT		't'
+#define KAFL_PROTO_INFO				'I'
+
+#define KAFL_PROTO_PRINTF			'X'
+
+#define KAFL_PROTO_PT_TRASHED			'Z'	/* thank you Intel! */
+#define KAFL_PROTO_PT_TRASHED_CRASH		'M'
+#define KAFL_PROTO_PT_TRASHED_KASAN		'N'
+
+#define KAFL_PROTO_PT_ABORT				'H'
+
+
+
+#endif
diff --git a/pt/khash.h b/pt/khash.h
new file mode 100644
index 000000000..78194014d
--- /dev/null
+++ b/pt/khash.h
@@ -0,0 +1,607 @@
+/*
+ * Copyright (c) 2008, 2009, 2011 by Attractive Chaos <attractor@live.co.uk>
+ * SPDX-License-Identifier: MIT
+ */
+
+/*
+  An example:
+
+#include "khash.h"
+KHASH_MAP_INIT_INT(32, char)
+int main() {
+	int ret, is_missing;
+	khiter_t k;
+	khash_t(32) *h = kh_init(32);
+	k = kh_put(32, h, 5, &ret);
+	kh_value(h, k) = 10;
+	k = kh_get(32, h, 10);
+	is_missing = (k == kh_end(h));
+	k = kh_get(32, h, 5);
+	kh_del(32, h, k);
+	for (k = kh_begin(h); k != kh_end(h); ++k)
+		if (kh_exist(h, k)) kh_value(h, k) = 1;
+	kh_destroy(32, h);
+	return 0;
+}
+*/
+
+/*
+  2013-05-02 (0.2.8):
+
+	* Use quadratic probing. When the capacity is power of 2, stepping function
+	  i*(i+1)/2 guarantees to traverse each bucket. It is better than double
+	  hashing on cache performance and is more robust than linear probing.
+
+	  In theory, double hashing should be more robust than quadratic probing.
+	  However, my implementation is probably not for large hash tables, because
+	  the second hash function is closely tied to the first hash function,
+	  which reduce the effectiveness of double hashing.
+
+	Reference: http://research.cs.vt.edu/AVresearch/hashing/quadratic.php
+
+  2011-12-29 (0.2.7):
+
+    * Minor code clean up; no actual effect.
+
+  2011-09-16 (0.2.6):
+
+	* The capacity is a power of 2. This seems to dramatically improve the
+	  speed for simple keys. Thank Zilong Tan for the suggestion. Reference:
+
+	   - http://code.google.com/p/ulib/
+	   - http://nothings.org/computer/judy/
+
+	* Allow to optionally use linear probing which usually has better
+	  performance for random input. Double hashing is still the default as it
+	  is more robust to certain non-random input.
+
+	* Added Wang's integer hash function (not used by default). This hash
+	  function is more robust to certain non-random input.
+
+  2011-02-14 (0.2.5):
+
+    * Allow to declare global functions.
+
+  2009-09-26 (0.2.4):
+
+    * Improve portability
+
+  2008-09-19 (0.2.3):
+
+	* Corrected the example
+	* Improved interfaces
+
+  2008-09-11 (0.2.2):
+
+	* Improved speed a little in kh_put()
+
+  2008-09-10 (0.2.1):
+
+	* Added kh_clear()
+	* Fixed a compiling error
+
+  2008-09-02 (0.2.0):
+
+	* Changed to token concatenation which increases flexibility.
+
+  2008-08-31 (0.1.2):
+
+	* Fixed a bug in kh_get(), which has not been tested previously.
+
+  2008-08-31 (0.1.1):
+
+	* Added destructor
+*/
+
+
+#ifndef __AC_KHASH_H
+#define __AC_KHASH_H
+
+/*!
+  @header
+
+  Generic hash table library.
+ */
+
+#define AC_VERSION_KHASH_H "0.2.8"
+
+#include <stdlib.h>
+#include <string.h>
+#include <limits.h>
+
+/* compiler specific configuration */
+
+#if UINT_MAX == 0xffffffffu
+typedef unsigned int khint32_t;
+#elif ULONG_MAX == 0xffffffffu
+typedef unsigned long khint32_t;
+#endif
+
+#if ULONG_MAX == ULLONG_MAX
+typedef unsigned long khint64_t;
+#else
+typedef unsigned long long khint64_t;
+#endif
+
+#ifndef kh_inline
+#ifdef _MSC_VER
+#define kh_inline __inline
+#else
+#define kh_inline inline
+#endif
+#endif /* kh_inline */
+
+#ifndef klib_unused
+#if (defined __clang__ && __clang_major__ >= 3) || (defined __GNUC__ && __GNUC__ >= 3)
+#define klib_unused __attribute__ ((__unused__))
+#else
+#define klib_unused
+#endif
+#endif /* klib_unused */
+
+typedef khint64_t khint_t;
+typedef khint_t khiter_t;
+
+#define __ac_isempty(flag, i) ((flag[i>>4]>>((i&0xfU)<<1))&2)
+#define __ac_isdel(flag, i) ((flag[i>>4]>>((i&0xfU)<<1))&1)
+#define __ac_iseither(flag, i) ((flag[i>>4]>>((i&0xfU)<<1))&3)
+#define __ac_set_isdel_false(flag, i) (flag[i>>4]&=~(1ul<<((i&0xfU)<<1)))
+#define __ac_set_isempty_false(flag, i) (flag[i>>4]&=~(2ul<<((i&0xfU)<<1)))
+#define __ac_set_isboth_false(flag, i) (flag[i>>4]&=~(3ul<<((i&0xfU)<<1)))
+#define __ac_set_isdel_true(flag, i) (flag[i>>4]|=1ul<<((i&0xfU)<<1))
+
+#define __ac_fsize(m) ((m) < 16? 1 : (m)>>4)
+
+#ifndef kroundup32
+#define kroundup32(x) (--(x), (x)|=(x)>>1, (x)|=(x)>>2, (x)|=(x)>>4, (x)|=(x)>>8, (x)|=(x)>>16, ++(x))
+#endif
+
+#ifndef kcalloc
+#define kcalloc(N,Z) calloc(N,Z)
+#endif
+#ifndef kmalloc
+#define kmalloc(Z) malloc(Z)
+#endif
+#ifndef krealloc
+#define krealloc(P,Z) realloc(P,Z)
+#endif
+#ifndef kfree
+#define kfree(P) free(P)
+#endif
+
+static const double __ac_HASH_UPPER = 0.77;
+
+#define __KHASH_TYPE(name, khkey_t, khval_t) \
+	typedef struct kh_##name##_s { \
+		khint_t n_buckets, size, n_occupied, upper_bound; \
+		khint32_t *flags; \
+		khkey_t *keys; \
+		khval_t *vals; \
+	} kh_##name##_t;
+
+#define __KHASH_PROTOTYPES(name, khkey_t, khval_t)	 					\
+	extern kh_##name##_t *kh_init_##name(void);							\
+	extern void kh_destroy_##name(kh_##name##_t *h);					\
+	extern void kh_clear_##name(kh_##name##_t *h);						\
+	extern khint_t kh_get_##name(const kh_##name##_t *h, khkey_t key); 	\
+	extern int kh_resize_##name(kh_##name##_t *h, khint_t new_n_buckets); \
+	extern khint_t kh_put_##name(kh_##name##_t *h, khkey_t key, int *ret); \
+	extern void kh_del_##name(kh_##name##_t *h, khint_t x);
+
+#define __KHASH_IMPL(name, SCOPE, khkey_t, khval_t, kh_is_map, __hash_func, __hash_equal) \
+	SCOPE kh_##name##_t *kh_init_##name(void) {							\
+		return (kh_##name##_t*)kcalloc(1, sizeof(kh_##name##_t));		\
+	}																	\
+	SCOPE void kh_destroy_##name(kh_##name##_t *h)						\
+	{																	\
+		if (h) {														\
+			kfree((void *)h->keys); kfree(h->flags);					\
+			kfree((void *)h->vals);										\
+			kfree(h);													\
+		}																\
+	}																	\
+	SCOPE void kh_clear_##name(kh_##name##_t *h)						\
+	{																	\
+		if (h && h->flags) {											\
+			memset(h->flags, 0xaa, __ac_fsize(h->n_buckets) * sizeof(khint32_t)); \
+			h->size = h->n_occupied = 0;								\
+		}																\
+	}																	\
+	SCOPE khint_t kh_get_##name(const kh_##name##_t *h, khkey_t key) 	\
+	{																	\
+		if (h->n_buckets) {												\
+			khint_t k, i, last, mask, step = 0; \
+			mask = h->n_buckets - 1;									\
+			k = __hash_func(key); i = k & mask;							\
+			last = i; \
+			while (!__ac_isempty(h->flags, i) && (__ac_isdel(h->flags, i) || !__hash_equal(h->keys[i], key))) { \
+				i = (i + (++step)) & mask; \
+				if (i == last) return h->n_buckets;						\
+			}															\
+			return __ac_iseither(h->flags, i)? h->n_buckets : i;		\
+		} else return 0;												\
+	}																	\
+	SCOPE int kh_resize_##name(kh_##name##_t *h, khint_t new_n_buckets) \
+	{ /* This function uses 0.25*n_buckets bytes of working space instead of [sizeof(key_t+val_t)+.25]*n_buckets. */ \
+		khint32_t *new_flags = 0;										\
+		khint_t j = 1;													\
+		{																\
+			kroundup32(new_n_buckets); 									\
+			if (new_n_buckets < 4) new_n_buckets = 4;					\
+			if (h->size >= (khint_t)(new_n_buckets * __ac_HASH_UPPER + 0.5)) j = 0;	/* requested size is too small */ \
+			else { /* hash table size to be changed (shrink or expand); rehash */ \
+				new_flags = (khint32_t*)kmalloc(__ac_fsize(new_n_buckets) * sizeof(khint32_t));	\
+				if (!new_flags) return -1;								\
+				memset(new_flags, 0xaa, __ac_fsize(new_n_buckets) * sizeof(khint32_t)); \
+				if (h->n_buckets < new_n_buckets) {	/* expand */		\
+					khkey_t *new_keys = (khkey_t*)krealloc((void *)h->keys, new_n_buckets * sizeof(khkey_t)); \
+					if (!new_keys) { kfree(new_flags); return -1; }		\
+					h->keys = new_keys;									\
+					if (kh_is_map) {									\
+						khval_t *new_vals = (khval_t*)krealloc((void *)h->vals, new_n_buckets * sizeof(khval_t)); \
+						if (!new_vals) { kfree(new_flags); return -1; }	\
+						h->vals = new_vals;								\
+					}													\
+				} /* otherwise shrink */								\
+			}															\
+		}																\
+		if (j) { /* rehashing is needed */								\
+			for (j = 0; j != h->n_buckets; ++j) {						\
+				if (__ac_iseither(h->flags, j) == 0) {					\
+					khkey_t key = h->keys[j];							\
+					khval_t val;										\
+					khint_t new_mask;									\
+					new_mask = new_n_buckets - 1; 						\
+					if (kh_is_map) val = h->vals[j];					\
+					__ac_set_isdel_true(h->flags, j);					\
+					while (1) { /* kick-out process; sort of like in Cuckoo hashing */ \
+						khint_t k, i, step = 0; \
+						k = __hash_func(key);							\
+						i = k & new_mask;								\
+						while (!__ac_isempty(new_flags, i)) i = (i + (++step)) & new_mask; \
+						__ac_set_isempty_false(new_flags, i);			\
+						if (i < h->n_buckets && __ac_iseither(h->flags, i) == 0) { /* kick out the existing element */ \
+							{ khkey_t tmp = h->keys[i]; h->keys[i] = key; key = tmp; } \
+							if (kh_is_map) { khval_t tmp = h->vals[i]; h->vals[i] = val; val = tmp; } \
+							__ac_set_isdel_true(h->flags, i); /* mark it as deleted in the old hash table */ \
+						} else { /* write the element and jump out of the loop */ \
+							h->keys[i] = key;							\
+							if (kh_is_map) h->vals[i] = val;			\
+							break;										\
+						}												\
+					}													\
+				}														\
+			}															\
+			if (h->n_buckets > new_n_buckets) { /* shrink the hash table */ \
+				h->keys = (khkey_t*)krealloc((void *)h->keys, new_n_buckets * sizeof(khkey_t)); \
+				if (kh_is_map) h->vals = (khval_t*)krealloc((void *)h->vals, new_n_buckets * sizeof(khval_t)); \
+			}															\
+			kfree(h->flags); /* free the working space */				\
+			h->flags = new_flags;										\
+			h->n_buckets = new_n_buckets;								\
+			h->n_occupied = h->size;									\
+			h->upper_bound = (khint_t)(h->n_buckets * __ac_HASH_UPPER + 0.5); \
+		}																\
+		return 0;														\
+	}																	\
+	SCOPE khint_t kh_put_##name(kh_##name##_t *h, khkey_t key, int *ret) \
+	{																	\
+		khint_t x;														\
+		if (h->n_occupied >= h->upper_bound) { /* update the hash table */ \
+			if (h->n_buckets > (h->size<<1)) {							\
+				if (kh_resize_##name(h, h->n_buckets - 1) < 0) { /* clear "deleted" elements */ \
+					*ret = -1; return h->n_buckets;						\
+				}														\
+			} else if (kh_resize_##name(h, h->n_buckets + 1) < 0) { /* expand the hash table */ \
+				*ret = -1; return h->n_buckets;							\
+			}															\
+		} /* TODO: to implement automatically shrinking; resize() already support shrinking */ \
+		{																\
+			khint_t k, i, site, last, mask = h->n_buckets - 1, step = 0; \
+			x = site = h->n_buckets; k = __hash_func(key); i = k & mask; \
+			if (__ac_isempty(h->flags, i)) x = i; /* for speed up */	\
+			else {														\
+				last = i; \
+				while (!__ac_isempty(h->flags, i) && (__ac_isdel(h->flags, i) || !__hash_equal(h->keys[i], key))) { \
+					if (__ac_isdel(h->flags, i)) site = i;				\
+					i = (i + (++step)) & mask; \
+					if (i == last) { x = site; break; }					\
+				}														\
+				if (x == h->n_buckets) {								\
+					if (__ac_isempty(h->flags, i) && site != h->n_buckets) x = site; \
+					else x = i;											\
+				}														\
+			}															\
+		}																\
+		if (__ac_isempty(h->flags, x)) { /* not present at all */		\
+			h->keys[x] = key;											\
+			__ac_set_isboth_false(h->flags, x);							\
+			++h->size; ++h->n_occupied;									\
+			*ret = 1;													\
+		} else if (__ac_isdel(h->flags, x)) { /* deleted */				\
+			h->keys[x] = key;											\
+			__ac_set_isboth_false(h->flags, x);							\
+			++h->size;													\
+			*ret = 2;													\
+		} else *ret = 0; /* Don't touch h->keys[x] if present and not deleted */ \
+		return x;														\
+	}																	\
+	SCOPE void kh_del_##name(kh_##name##_t *h, khint_t x)				\
+	{																	\
+		if (x != h->n_buckets && !__ac_iseither(h->flags, x)) {			\
+			__ac_set_isdel_true(h->flags, x);							\
+			--h->size;													\
+		}																\
+	}
+
+#define KHASH_DECLARE(name, khkey_t, khval_t)		 					\
+	__KHASH_TYPE(name, khkey_t, khval_t) 								\
+	__KHASH_PROTOTYPES(name, khkey_t, khval_t)
+
+#define KHASH_INIT2(name, SCOPE, khkey_t, khval_t, kh_is_map, __hash_func, __hash_equal) \
+	__KHASH_TYPE(name, khkey_t, khval_t) 								\
+	__KHASH_IMPL(name, SCOPE, khkey_t, khval_t, kh_is_map, __hash_func, __hash_equal)
+
+#define KHASH_INIT(name, khkey_t, khval_t, kh_is_map, __hash_func, __hash_equal) \
+	KHASH_INIT2(name, static kh_inline klib_unused, khkey_t, khval_t, kh_is_map, __hash_func, __hash_equal)
+
+/* --- BEGIN OF HASH FUNCTIONS --- */
+
+/*! @function
+  @abstract     Integer hash function
+  @param  key   The integer [khint32_t]
+  @return       The hash value [khint_t]
+ */
+#define kh_int_hash_func(key) (khint32_t)(key)
+/*! @function
+  @abstract     Integer comparison function
+ */
+#define kh_int_hash_equal(a, b) ((a) == (b))
+/*! @function
+  @abstract     64-bit integer hash function
+  @param  key   The integer [khint64_t]
+  @return       The hash value [khint_t]
+ */
+#define kh_int64_hash_func(key) (khint32_t)((key)>>33^(key)^(key)<<11)
+/*! @function
+  @abstract     64-bit integer comparison function
+ */
+#define kh_int64_hash_equal(a, b) ((a) == (b))
+/*! @function
+  @abstract     const char* hash function
+  @param  s     Pointer to a null terminated string
+  @return       The hash value
+ */
+static kh_inline khint_t __ac_X31_hash_string(const char *s)
+{
+	khint_t h = (khint_t)*s;
+	if (h) for (++s ; *s; ++s) h = (h << 5) - h + (khint_t)*s;
+	return h;
+}
+/*! @function
+  @abstract     Another interface to const char* hash function
+  @param  key   Pointer to a null terminated string [const char*]
+  @return       The hash value [khint_t]
+ */
+#define kh_str_hash_func(key) __ac_X31_hash_string(key)
+/*! @function
+  @abstract     Const char* comparison function
+ */
+#define kh_str_hash_equal(a, b) (strcmp(a, b) == 0)
+
+static kh_inline khint_t __ac_Wang_hash(khint_t key)
+{
+    key += ~(key << 15);
+    key ^=  (key >> 10);
+    key +=  (key << 3);
+    key ^=  (key >> 6);
+    key += ~(key << 11);
+    key ^=  (key >> 16);
+    return key;
+}
+#define kh_int_hash_func2(key) __ac_Wang_hash((khint_t)key)
+
+/* --- END OF HASH FUNCTIONS --- */
+
+/* Other convenient macros... */
+
+/*!
+  @abstract Type of the hash table.
+  @param  name  Name of the hash table [symbol]
+ */
+#define khash_t(name) kh_##name##_t
+
+/*! @function
+  @abstract     Initiate a hash table.
+  @param  name  Name of the hash table [symbol]
+  @return       Pointer to the hash table [khash_t(name)*]
+ */
+#define kh_init(name) kh_init_##name()
+
+/*! @function
+  @abstract     Destroy a hash table.
+  @param  name  Name of the hash table [symbol]
+  @param  h     Pointer to the hash table [khash_t(name)*]
+ */
+#define kh_destroy(name, h) kh_destroy_##name(h)
+
+/*! @function
+  @abstract     Reset a hash table without deallocating memory.
+  @param  name  Name of the hash table [symbol]
+  @param  h     Pointer to the hash table [khash_t(name)*]
+ */
+#define kh_clear(name, h) kh_clear_##name(h)
+
+/*! @function
+  @abstract     Resize a hash table.
+  @param  name  Name of the hash table [symbol]
+  @param  h     Pointer to the hash table [khash_t(name)*]
+  @param  s     New size [khint_t]
+ */
+#define kh_resize(name, h, s) kh_resize_##name(h, s)
+
+/*! @function
+  @abstract     Insert a key to the hash table.
+  @param  name  Name of the hash table [symbol]
+  @param  h     Pointer to the hash table [khash_t(name)*]
+  @param  k     Key [type of keys]
+  @param  r     Extra return code: -1 if the operation failed;
+                0 if the key is present in the hash table;
+                1 if the bucket is empty (never used); 2 if the element in
+				the bucket has been deleted [int*]
+  @return       Iterator to the inserted element [khint_t]
+ */
+#define kh_put(name, h, k, r) kh_put_##name(h, k, r)
+
+/*! @function
+  @abstract     Retrieve a key from the hash table.
+  @param  name  Name of the hash table [symbol]
+  @param  h     Pointer to the hash table [khash_t(name)*]
+  @param  k     Key [type of keys]
+  @return       Iterator to the found element, or kh_end(h) if the element is absent [khint_t]
+ */
+#define kh_get(name, h, k) kh_get_##name(h, k)
+
+/*! @function
+  @abstract     Remove a key from the hash table.
+  @param  name  Name of the hash table [symbol]
+  @param  h     Pointer to the hash table [khash_t(name)*]
+  @param  k     Iterator to the element to be deleted [khint_t]
+ */
+#define kh_del(name, h, k) kh_del_##name(h, k)
+
+/*! @function
+  @abstract     Test whether a bucket contains data.
+  @param  h     Pointer to the hash table [khash_t(name)*]
+  @param  x     Iterator to the bucket [khint_t]
+  @return       1 if containing data; 0 otherwise [int]
+ */
+#define kh_exist(h, x) (!__ac_iseither((h)->flags, (x)))
+
+/*! @function
+  @abstract     Get key given an iterator
+  @param  h     Pointer to the hash table [khash_t(name)*]
+  @param  x     Iterator to the bucket [khint_t]
+  @return       Key [type of keys]
+ */
+#define kh_key(h, x) ((h)->keys[x])
+
+/*! @function
+  @abstract     Get value given an iterator
+  @param  h     Pointer to the hash table [khash_t(name)*]
+  @param  x     Iterator to the bucket [khint_t]
+  @return       Value [type of values]
+  @discussion   For hash sets, calling this results in segfault.
+ */
+#define kh_val(h, x) ((h)->vals[x])
+
+/*! @function
+  @abstract     Alias of kh_val()
+ */
+#define kh_value(h, x) ((h)->vals[x])
+
+/*! @function
+  @abstract     Get the start iterator
+  @param  h     Pointer to the hash table [khash_t(name)*]
+  @return       The start iterator [khint_t]
+ */
+#define kh_begin(h) (khint_t)(0)
+
+/*! @function
+  @abstract     Get the end iterator
+  @param  h     Pointer to the hash table [khash_t(name)*]
+  @return       The end iterator [khint_t]
+ */
+#define kh_end(h) ((h)->n_buckets)
+
+/*! @function
+  @abstract     Get the number of elements in the hash table
+  @param  h     Pointer to the hash table [khash_t(name)*]
+  @return       Number of elements in the hash table [khint_t]
+ */
+#define kh_size(h) ((h)->size)
+
+/*! @function
+  @abstract     Get the number of buckets in the hash table
+  @param  h     Pointer to the hash table [khash_t(name)*]
+  @return       Number of buckets in the hash table [khint_t]
+ */
+#define kh_n_buckets(h) ((h)->n_buckets)
+
+/*! @function
+  @abstract     Iterate over the entries in the hash table
+  @param  h     Pointer to the hash table [khash_t(name)*]
+  @param  kvar  Variable to which key will be assigned
+  @param  vvar  Variable to which value will be assigned
+  @param  code  Block of code to execute
+ */
+#define kh_foreach(h, kvar, vvar, code) { khint_t __i;		\
+	for (__i = kh_begin(h); __i != kh_end(h); ++__i) {		\
+		if (!kh_exist(h,__i)) continue;						\
+		(kvar) = kh_key(h,__i);								\
+		(vvar) = kh_val(h,__i);								\
+		code;												\
+	} }
+
+/*! @function
+  @abstract     Iterate over the values in the hash table
+  @param  h     Pointer to the hash table [khash_t(name)*]
+  @param  vvar  Variable to which value will be assigned
+  @param  code  Block of code to execute
+ */
+#define kh_foreach_value(h, vvar, code) { khint_t __i;		\
+	for (__i = kh_begin(h); __i != kh_end(h); ++__i) {		\
+		if (!kh_exist(h,__i)) continue;						\
+		(vvar) = kh_val(h,__i);								\
+		code;												\
+	} }
+
+/* More conenient interfaces */
+
+/*! @function
+  @abstract     Instantiate a hash set containing integer keys
+  @param  name  Name of the hash table [symbol]
+ */
+#define KHASH_SET_INIT_INT(name)										\
+	KHASH_INIT(name, khint32_t, char, 0, kh_int_hash_func, kh_int_hash_equal)
+
+/*! @function
+  @abstract     Instantiate a hash map containing integer keys
+  @param  name  Name of the hash table [symbol]
+  @param  khval_t  Type of values [type]
+ */
+#define KHASH_MAP_INIT_INT(name, khval_t)								\
+	KHASH_INIT(name, khint32_t, khval_t, 1, kh_int_hash_func, kh_int_hash_equal)
+
+/*! @function
+  @abstract     Instantiate a hash map containing 64-bit integer keys
+  @param  name  Name of the hash table [symbol]
+ */
+#define KHASH_SET_INIT_INT64(name)										\
+	KHASH_INIT(name, khint64_t, char, 0, kh_int64_hash_func, kh_int64_hash_equal)
+
+/*! @function
+  @abstract     Instantiate a hash map containing 64-bit integer keys
+  @param  name  Name of the hash table [symbol]
+  @param  khval_t  Type of values [type]
+ */
+#define KHASH_MAP_INIT_INT64(name, khval_t)								\
+	KHASH_INIT(name, khint64_t, khval_t, 1, kh_int64_hash_func, kh_int64_hash_equal)
+
+typedef const char *kh_cstr_t;
+/*! @function
+  @abstract     Instantiate a hash map containing const char* keys
+  @param  name  Name of the hash table [symbol]
+ */
+#define KHASH_SET_INIT_STR(name)										\
+	KHASH_INIT(name, kh_cstr_t, char, 0, kh_str_hash_func, kh_str_hash_equal)
+
+/*! @function
+  @abstract     Instantiate a hash map containing const char* keys
+  @param  name  Name of the hash table [symbol]
+  @param  khval_t  Type of values [type]
+ */
+#define KHASH_MAP_INIT_STR(name, khval_t)								\
+	KHASH_INIT(name, kh_cstr_t, khval_t, 1, kh_str_hash_func, kh_str_hash_equal)
+
+#endif /* __AC_KHASH_H */
diff --git a/pt/logger.c b/pt/logger.c
new file mode 100644
index 000000000..55b7e1433
--- /dev/null
+++ b/pt/logger.c
@@ -0,0 +1,106 @@
+/* 
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+#include <stdio.h>
+#include <stdarg.h>
+#include <stdint.h>
+#include "pt/logger.h"
+
+#define SAMPLE_DECODED_DETAILED
+
+#ifdef SAMPLE_RAW_SINGLE
+#define SAMPLE_RAW_SINGLE_TARGET "/dev/shm/kafl_pt_%d"
+
+
+int sample_raw_single_id = 0;
+FILE* sample_raw_single_file = NULL;
+
+void init_sample_raw_single(uint32_t id){
+	sample_raw_single_id = id;
+	char name[256];
+	snprintf(name, 256, SAMPLE_RAW_SINGLE_TARGET, sample_raw_single_id);
+	if (sample_raw_single_file)
+		fclose(sample_raw_single_file);
+	sample_raw_single_file = fopen(name, "wb"); 
+}
+
+void sample_raw_single(void* buffer, int bytes){
+	if (sample_raw_single_file){
+		fwrite(buffer, sizeof(char), bytes, sample_raw_single_file);
+		fflush(sample_raw_single_file);
+	}
+}
+#endif
+
+#ifdef SAMPLE_RAW
+#define SAMPLE_RAW_TARGET "/tmp/sample_raw_%d"
+
+int sample_raw_id = 0;
+FILE* sample_raw_file = NULL;
+
+void init_sample_raw(void){
+	char name[256];
+	snprintf(name, 256, SAMPLE_RAW_TARGET, sample_raw_id++);
+	if (sample_raw_file)
+		fclose(sample_raw_file);
+	sample_raw_file = fopen(name, "wb"); 
+}
+
+void sample_raw(void* buffer, int bytes){
+	if (sample_raw_file)
+		fwrite(buffer, sizeof(char), bytes, sample_raw_file);
+}
+#endif
+
+#ifdef SAMPLE_DECODED
+#define SAMPLE_DECODED_TARGET "/tmp/traces/sample_decoded_%d"
+
+int sample_decoded_id = 0;
+FILE* sample_decoded_file = NULL;
+
+void init_sample_decoded(void){
+	char name[256];
+	snprintf(name, 256, SAMPLE_DECODED_TARGET, sample_decoded_id++);
+	if (sample_decoded_file)
+		fclose(sample_decoded_file);
+	sample_decoded_file = fopen(name, "w"); 
+}
+
+void sample_decoded(uint64_t addr){
+	if (sample_decoded_file)
+		fprintf(sample_decoded_file, "%lx\n", addr);
+}
+#endif
+
+#ifdef SAMPLE_DECODED_DETAILED
+#define SAMPLE_DETAILED_TARGET "/tmp/traces/sample_detailed_%d"
+
+int sample_detailed_id = 0;
+FILE* sample_detailed_file = NULL;
+
+void init_sample_decoded_detailed(void){
+	char name[256];
+	snprintf(name, 256, SAMPLE_DETAILED_TARGET, sample_detailed_id);
+	if (sample_detailed_file)
+		fclose(sample_detailed_file);
+	sample_detailed_file = fopen(name, "w"); 
+}
+#endif
+
+void sample_decoded_detailed(const char *format, ...){
+	#ifdef SAMPLE_DECODED_DETAILED
+	va_list args;
+
+	va_start(args, format);
+	printf(format, args);
+	if (sample_detailed_file)
+		vfprintf(sample_detailed_file, format, args);
+	va_end(args);
+	#endif
+}
diff --git a/pt/logger.h b/pt/logger.h
new file mode 100644
index 000000000..a61ded82b
--- /dev/null
+++ b/pt/logger.h
@@ -0,0 +1,57 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+#ifndef LOGGER_H
+#define LOGGER_H
+
+	#define CREATE_VM_IMAGE
+	//#define SAMPLE_RAW
+	//#define SAMPLE_DECODED
+	//#define SAMPLE_DECODED_DETAILED
+	//#define SAMPLE_RAW_SINGLE
+	
+	#ifdef CREATE_VM_IMAGE
+		#define DECODER_MEMORY_IMAGE "/tmp/data"
+	#endif
+
+	#ifdef SAMPLE_RAW_SINGLE
+		void init_sample_raw_single(uint32_t id);
+		void sample_raw_single(void* buffer, int bytes);
+	#endif
+	
+	#ifdef SAMPLE_RAW
+		void init_sample_raw(void);
+		void sample_raw(void* buffer, int bytes);
+	#endif
+
+	#ifdef SAMPLE_DECODED
+		void init_sample_decoded(void);
+		void sample_decoded(uint64_t addr);
+	#endif
+
+	#ifdef SAMPLE_DECODED_DETAILED
+		void init_sample_decoded_detailed(void);
+	#endif
+
+	void sample_decoded_detailed(const char *format, ...);
+
+#define UNUSED(x) (void)x;
+
+#ifdef SAMPLE_DECODED
+#define WRITE_SAMPLE_DECODED(addr) (sample_decoded(addr))
+#endif
+
+#ifdef SAMPLE_DECODED_DETAILED
+#define WRITE_SAMPLE_DECODED_DETAILED(format, ...) (sample_decoded_detailed(format, ##__VA_ARGS__))
+#else
+#define WRITE_SAMPLE_DECODED_DETAILED(format, ...)  (void)0
+#endif
+
+
+#endif
diff --git a/pt/memory_access.c b/pt/memory_access.c
new file mode 100644
index 000000000..bfd190309
--- /dev/null
+++ b/pt/memory_access.c
@@ -0,0 +1,289 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+#include "memory_access.h"
+#include "hypercall.h"
+#include "debug.h"
+
+bool read_virtual_memory(uint64_t address, uint8_t* data, uint32_t size, CPUState *cpu){
+	uint8_t tmp_buf[x86_64_PAGE_SIZE];
+	MemTxAttrs attrs;
+	hwaddr phys_addr;
+	int asidx;
+	bool ret = true;
+	uint64_t amount_copied = 0;
+	
+	//cpu_synchronize_state(cpu);
+	kvm_cpu_synchronize_state(cpu);
+
+	/* copy per page */
+	while(amount_copied < size){
+		uint64_t len_to_copy = (size - amount_copied);
+		if(len_to_copy > x86_64_PAGE_SIZE)
+			len_to_copy = x86_64_PAGE_SIZE;
+
+		asidx = cpu_asidx_from_attrs(cpu, MEMTXATTRS_UNSPECIFIED);
+		attrs = MEMTXATTRS_UNSPECIFIED;
+		phys_addr = cpu_get_phys_page_attrs_debug(cpu, (address & x86_64_PAGE_MASK), &attrs);
+
+		if (phys_addr == -1){
+			uint64_t next_page = (address & x86_64_PAGE_MASK) + x86_64_PAGE_SIZE;
+			uint64_t len_skipped =next_page-address;  
+			if(len_skipped > size-amount_copied){
+				len_skipped = size-amount_copied;
+			}
+
+			QEMU_PT_PRINTF(MEM_PREFIX, "Warning, read from unmapped memory:\t%lx, skipping to %lx", address, next_page);
+			memset( data+amount_copied, ' ',  len_skipped);
+			address += len_skipped;
+			amount_copied += len_skipped;
+			ret = false;
+			continue;
+		}
+			
+		phys_addr += (address & ~x86_64_PAGE_MASK);
+		uint64_t remaining_on_page = x86_64_PAGE_SIZE - (address & ~x86_64_PAGE_MASK);
+		if(len_to_copy > remaining_on_page){
+			len_to_copy = remaining_on_page;
+		}
+		MemTxResult txt = address_space_rw(cpu_get_address_space(cpu, asidx), phys_addr, MEMTXATTRS_UNSPECIFIED, tmp_buf, len_to_copy, 0);
+		if(txt){
+			QEMU_PT_PRINTF(MEM_PREFIX, "Warning, read failed:\t%lx", address);
+		}
+			
+		memcpy(data+amount_copied, tmp_buf, len_to_copy);
+			
+		address += len_to_copy;
+		amount_copied += len_to_copy;
+	}
+	
+	return ret;
+}
+
+bool is_addr_mapped(uint64_t address, CPUState *cpu){
+	MemTxAttrs attrs;
+	hwaddr phys_addr;
+	kvm_cpu_synchronize_state(cpu);
+	attrs = MEMTXATTRS_UNSPECIFIED;
+	phys_addr = cpu_get_phys_page_attrs_debug(cpu, (address & x86_64_PAGE_MASK), &attrs);
+	return phys_addr != -1;
+}
+
+bool write_virtual_memory(uint64_t address, uint8_t* data, uint32_t size, CPUState *cpu)
+{
+	int asidx;
+	MemTxAttrs attrs;
+	hwaddr phys_addr;
+	MemTxResult res;
+
+	uint64_t counter, l, i;
+
+	counter = size;
+	while(counter != 0){
+		l = x86_64_PAGE_SIZE;
+		if (l > counter)
+		l = counter;
+
+		kvm_cpu_synchronize_state(cpu);
+		//cpu_synchronize_state(cpu);
+		asidx = cpu_asidx_from_attrs(cpu, MEMTXATTRS_UNSPECIFIED);
+		attrs = MEMTXATTRS_UNSPECIFIED;
+		phys_addr = cpu_get_phys_page_attrs_debug(cpu, (address & x86_64_PAGE_MASK), &attrs);
+
+		if (phys_addr == -1){
+			QEMU_PT_PRINTF(MEM_PREFIX, "phys_addr == -1:\t%lx", address);
+			return false;
+		}
+		
+		phys_addr += (address & ~x86_64_PAGE_MASK);   
+		res = address_space_rw(cpu_get_address_space(cpu, asidx), phys_addr, MEMTXATTRS_UNSPECIFIED, data, l, true);
+		if (res != MEMTX_OK){
+			QEMU_PT_PRINTF(MEM_PREFIX, "!MEMTX_OK:\t%lx", address);
+			return false;
+		}   
+
+		i++;
+		data += l;
+		address += l;
+		counter -= l;
+	}
+
+	return true;
+}
+
+void hexdump_virtual_memory(uint64_t address, uint32_t size, CPUState *cpu){
+	assert(size < 0x100000); /* 1MB max */
+	uint64_t i = 0;
+	uint8_t tmp[17];
+	uint8_t* data = malloc(size);
+	bool success = read_virtual_memory(address, data, size, cpu);
+
+	if(success){
+		for (i = 0; i < size; i++){
+		if(!(i % 16)){
+			if (i != 0){
+			printf ("  %s\n", tmp);
+		}
+			printf ("  %04lx ", i);
+		}
+		printf (" %02x", data[i]);
+
+		if ((data[i] < 0x20) || (data[i] > 0x7e))
+			tmp[i % 16] = '.';
+		else
+			tmp[i % 16] = data[i];
+		tmp[(i % 16) + 1] = '\0';
+		}
+
+		while ((i % 16) != 0) {
+			printf ("   ");
+			i++;
+		}
+		printf ("  %s\n", tmp);
+	}
+
+	free(data);
+}
+
+bool write_virtual_shadow_memory(uint64_t address, uint8_t* data, uint32_t size, CPUState *cpu)
+{
+	/* Todo: later &address_space_memory + phys_addr -> mmap SHARED */
+	int asidx;
+	MemTxAttrs attrs;
+	hwaddr phys_addr;
+	MemTxResult res;
+	
+	uint64_t counter, l, i;
+	
+	void* shadow_memory = NULL;
+	
+	counter = size;
+	while(counter != 0){
+		l = x86_64_PAGE_SIZE;
+		if (l > counter)
+			l = counter;
+
+		kvm_cpu_synchronize_state(cpu);
+		//cpu_synchronize_state(cpu);
+		asidx = cpu_asidx_from_attrs(cpu, MEMTXATTRS_UNSPECIFIED);
+		attrs = MEMTXATTRS_UNSPECIFIED;
+		phys_addr = cpu_get_phys_page_attrs_debug(cpu, (address & x86_64_PAGE_MASK), &attrs);
+	
+		if (phys_addr == -1){
+			QEMU_PT_PRINTF(MEM_PREFIX, "phys_addr == -1:\t%lx", address);
+			return false;
+		}
+		
+		res = address_space_rw(cpu_get_address_space(cpu, asidx), (phys_addr + (address & ~x86_64_PAGE_MASK)), MEMTXATTRS_UNSPECIFIED, data, l, true);
+		if (res != MEMTX_OK){
+			QEMU_PT_PRINTF(MEM_PREFIX, "!MEMTX_OK:\t%lx", address);
+			return false;
+		}   
+	
+		assert(false);
+		shadow_memory = 0;//*get_physmem_shadow_ptr(phys_addr);
+		if (shadow_memory){
+			memcpy(shadow_memory + (address & ~x86_64_PAGE_MASK), data, l);
+		}
+		else{
+			QEMU_PT_PRINTF(MEM_PREFIX, "get_physmem_shadow_ptr(%lx) == NULL", phys_addr);
+			assert(false);
+			return false;
+		}
+	
+		phys_addr += (address & ~x86_64_PAGE_MASK);   
+	
+		i++;
+		data += l;
+		address += l;
+		counter -= l;
+	}
+	
+	return true;
+}
+
+/* Mmap guest virtual address to host address with size of 1 */
+void *mmap_virtual_memory(uint64_t address, CPUState *cpu)
+{
+	hwaddr phys_addr;
+	hwaddr len = 1;
+	phys_addr = cpu_get_phys_page_debug(cpu, (address & x86_64_PAGE_MASK));
+	if (phys_addr == -1) {
+		printf("pu_get_phys_page_debug return -1 with address of %lx\n", address);
+		return NULL;
+	}
+
+	return cpu_physical_memory_map(phys_addr + (address & ~x86_64_PAGE_MASK), &len, false);
+}
+
+/* Mmap guest virtual address to host address with size of 1 */
+void *mmap_physical_memory(uint64_t address, CPUState *cpu)
+{
+	hwaddr phys_addr = (hwaddr)address;
+	hwaddr len = 1;
+	return cpu_physical_memory_map(phys_addr, &len, false);
+}
+
+void munmap_virtual_memory(void *buffer, CPUState *cpu)
+{
+	cpu_physical_memory_unmap(buffer, 1, false, 1);
+}
+
+bool write_virtual_memory_via_kvm(uint64_t address, uint8_t* data, uint32_t size, bool user_mode_address, CPUState *cpu)
+{
+	kvm_payload payload = {0};
+	
+	payload.size = size;
+	payload.host_addr = data;
+	payload.guest_addr = address;
+
+	if (user_mode_address) {
+		payload.access = PFERR_USER_MASK;
+	}
+	else {
+		payload.access = 0;
+	}
+	
+	if (!address) {
+		return true;
+	}
+
+	if (!data) {
+		return true;
+	}
+	kvm_vcpu_ioctl(cpu, KVM_VMX_PT_WRITE_TO_GUEST, &payload);
+
+	return true;
+}
+
+bool read_virtual_memory_via_kvm(uint64_t address, uint8_t* data, uint32_t size, bool user_mode_address, CPUState *cpu)
+{
+	kvm_payload payload = {0};
+	
+	payload.size = size;
+	payload.host_addr = data;
+	payload.guest_addr = address;
+	if (user_mode_address) {
+		payload.access = PFERR_USER_MASK;
+	}
+	else {
+		payload.access = 0;
+	}
+	
+	if (!address) {
+		return true;
+	}
+
+	if (!data) {
+		return true;
+	}
+
+	kvm_vcpu_ioctl(cpu, KVM_VMX_PT_READ_FROM_GUEST, &payload);
+	return true;
+}
diff --git a/pt/memory_access.h b/pt/memory_access.h
new file mode 100644
index 000000000..dc7b7e5d0
--- /dev/null
+++ b/pt/memory_access.h
@@ -0,0 +1,60 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+
+#ifndef MEMORY_ACCESS_H
+#define MEMORY_ACCESS_H
+
+#include "qemu/osdep.h"
+#include <linux/kvm.h>
+#include "qemu-common.h"
+#include "sysemu/kvm_int.h"
+
+#define x86_64_PAGE_SIZE	0x1000
+#define x86_64_PAGE_MASK	~(x86_64_PAGE_SIZE - 1)
+
+#define PFERR_PRESENT_BIT 0
+#define PFERR_WRITE_BIT 1
+#define PFERR_USER_BIT 2
+#define PFERR_RSVD_BIT 3
+#define PFERR_FETCH_BIT 4
+#define PFERR_PK_BIT 5
+#define PFERR_GUEST_FINAL_BIT 32
+#define PFERR_GUEST_PAGE_BIT 33
+
+#define PFERR_PRESENT_MASK (1U << PFERR_PRESENT_BIT)
+#define PFERR_WRITE_MASK (1U << PFERR_WRITE_BIT)
+#define PFERR_USER_MASK (1U << PFERR_USER_BIT)
+#define PFERR_RSVD_MASK (1U << PFERR_RSVD_BIT)
+#define PFERR_FETCH_MASK (1U << PFERR_FETCH_BIT)
+#define PFERR_PK_MASK (1U << PFERR_PK_BIT)
+#define PFERR_GUEST_FINAL_MASK (1ULL << PFERR_GUEST_FINAL_BIT)
+#define PFERR_GUEST_PAGE_MASK (1ULL << PFERR_GUEST_PAGE_BIT)
+
+
+typedef struct {
+    uint32_t size;
+	uint64_t host_addr;
+	uint64_t guest_addr;
+    uint32_t access;
+} kvm_payload;
+
+bool read_virtual_memory(uint64_t address, uint8_t* data, uint32_t size, CPUState *cpu);
+bool write_virtual_memory(uint64_t address, uint8_t* data, uint32_t size, CPUState *cpu);
+void hexdump_virtual_memory(uint64_t address, uint32_t size, CPUState *cpu);
+bool write_virtual_shadow_memory(uint64_t address, uint8_t* data, uint32_t size, CPUState *cpu);
+bool is_addr_mapped(uint64_t address, CPUState *cpu);
+void *mmap_virtual_memory(uint64_t address, CPUState *cpu);
+void munmap_virtual_memory(void *buffer, CPUState *cpu);
+bool write_virtual_memory_via_kvm(uint64_t address, uint8_t* data, uint32_t size, bool user_mode_address, CPUState *cpu);
+bool read_virtual_memory_via_kvm(uint64_t address, uint8_t* data, uint32_t size, bool user_mode_address, CPUState *cpu);
+bool read_root_partition_virtual_memory_via_kvm(uint64_t address, uint8_t* data, uint32_t size, CPUState *cpu);
+bool read_root_partition_virtual_memory_via_kvm_helper(uint64_t address, uint8_t* data, uint32_t size, CPUState *cpu);
+void *mmap_physical_memory(uint64_t address, CPUState *cpu);
+#endif
diff --git a/pt/meson.build b/pt/meson.build
new file mode 100644
index 000000000..e69de29bb
diff --git a/pt/patcher.c b/pt/patcher.c
new file mode 100644
index 000000000..9d15496cb
--- /dev/null
+++ b/pt/patcher.c
@@ -0,0 +1,192 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+#include "patcher.h"
+#include "pt/memory_access.h"
+#include "pt/disassembler.h"
+#include "debug.h"
+
+uint8_t cmp_patch_data[] = { 0x38, 0xC0, [2 ... MAX_INSTRUCTION_SIZE]=0x90 }; // CMP AL,AL; NOP, NOP ...
+const uint8_t *cmp_patch = &cmp_patch_data[0];
+
+///////////////////////////////////////////////////////////////////////////////////
+// Private Helper Functions Declarations
+///////////////////////////////////////////////////////////////////////////////////
+//
+static void _patcher_apply_patch(patcher_t *self, size_t index);
+
+static void _patcher_restore_patch(patcher_t *self, size_t index);
+
+static void _patcher_save_patch(patcher_t *self, size_t index, uint8_t* data, size_t instruction_size, uint64_t addr);
+
+static size_t _patcher_disassemble_size(patcher_t *self, uint8_t* data,  uint64_t addr, x86_insn id);
+
+static void _patcher_alloc_patch_infos(patcher_t *self, size_t num_patches);
+
+static void _patcher_free_patch_infos(patcher_t *self);
+
+static redqueen_t* _redq_ptr(patcher_t *self);
+
+
+///////////////////////////////////////////////////////////////////////////////////
+// Public Functions
+///////////////////////////////////////////////////////////////////////////////////
+
+patcher_t* patcher_new(CPUState *cpu){
+    patcher_t *res = malloc(sizeof(patcher_t));
+    res->cpu = cpu;
+    res->num_patches = 0;
+    res->patches = NULL;
+    res->is_currently_applied = false;
+    return res;
+}
+
+void patcher_free(patcher_t* self){
+    assert(!self->is_currently_applied);
+    _patcher_free_patch_infos(self);
+    free(self);
+}
+
+void patcher_apply_all(patcher_t *self){
+  assert(!self->is_currently_applied);
+  if (_redq_ptr(self)) assert(!_redq_ptr(self)->hooks_applied);
+  //assert(patcher_validate_patches(self));
+  for(size_t i=0; i < self->num_patches; i++){
+      _patcher_apply_patch(self, i);
+  }
+  self->is_currently_applied = true;
+}
+
+void patcher_restore_all(patcher_t *self){
+  assert(self->is_currently_applied);
+  if (_redq_ptr(self)) assert(!_redq_ptr(self)->hooks_applied);
+  //assert(patcher_validate_patches(self));
+  for(size_t i = 0; i < self->num_patches; i++){
+    _patcher_restore_patch(self, i);
+  }
+  self->is_currently_applied = false;
+}
+
+void patcher_set_addrs(patcher_t *self, uint64_t* addrs, size_t num_addrs){
+  _patcher_free_patch_infos(self);
+  _patcher_alloc_patch_infos(self, num_addrs);
+  uint8_t curr_instruction_code[MAX_INSTRUCTION_SIZE];
+  memset(&curr_instruction_code[0], 0, MAX_INSTRUCTION_SIZE);
+
+  for(size_t i=0; i < self->num_patches; i++){
+    //QEMU_PT_PRINTF(REDQUEEN_PREFIX, "patching %lx", addrs[i]);
+    if( read_virtual_memory(addrs[i], &curr_instruction_code[0], MAX_INSTRUCTION_SIZE, self->cpu) ) {
+      size_t size =_patcher_disassemble_size(self, &curr_instruction_code[0], addrs[i], X86_INS_CMP);
+      assert(size != 0); //csopen failed, shouldn't happen
+      _patcher_save_patch(self, i, &curr_instruction_code[0], size, addrs[i]);
+    }
+  }
+}
+
+static void print_hexdump(const uint8_t* addr, size_t size){
+  for(size_t i = 0; i < size; i++){
+	  printf (" %02x", addr[i]);
+  }
+  printf("\n");
+}
+
+bool patcher_validate_patches(patcher_t *self){
+  bool was_rq = _redq_ptr(self)->hooks_applied;
+  if(was_rq)
+    redqueen_remove_hooks(_redq_ptr(self));
+  if(!self->patches){return true;}
+  for(size_t i=0; i<self->num_patches; i++){
+    uint8_t buf[MAX_INSTRUCTION_SIZE];
+    read_virtual_memory(self->patches[i].addr, &buf[0], MAX_INSTRUCTION_SIZE, self->cpu);
+    const uint8_t* should_value = NULL;
+    if(self->is_currently_applied){
+      should_value = cmp_patch;
+    } else {
+      should_value = &self->patches[i].orig_bytes[0];
+    }
+
+    QEMU_PT_PRINTF(REDQUEEN_PREFIX, "Validating, mem:");
+    print_hexdump(&buf[0], self->patches[i].size);
+    QEMU_PT_PRINTF(REDQUEEN_PREFIX, "should_be:");
+    print_hexdump(should_value, self->patches[i].size);
+    if(0 != memcmp(&buf[0], should_value, self->patches[i].size)){
+      QEMU_PT_PRINTF(REDQUEEN_PREFIX, "validating patches failed self->is_currently_applied = %d",  self->is_currently_applied);
+      return false;
+    }
+  }
+  if(was_rq)
+    redqueen_insert_hooks(_redq_ptr(self));
+  return true;
+}
+
+
+///////////////////////////////////////////////////////////////////////////////////
+// Private Helper Functions Definitions
+///////////////////////////////////////////////////////////////////////////////////
+
+
+static void _patcher_apply_patch(patcher_t *self, size_t index) {
+  patch_info_t *info = &self->patches[index];
+	write_virtual_shadow_memory(info->addr, (uint8_t*)cmp_patch, info->size, self->cpu);
+}
+
+static void _patcher_restore_patch(patcher_t *self, size_t index){
+  patch_info_t *info = &self->patches[index];
+	write_virtual_shadow_memory(info->addr, (uint8_t*)&info->orig_bytes[0], info->size, self->cpu);
+}
+
+static void _patcher_save_patch(patcher_t *self, size_t index, uint8_t* data, size_t instruction_size, uint64_t addr) {
+  assert(instruction_size >= 2);
+  assert(instruction_size < MAX_INSTRUCTION_SIZE);
+  patch_info_t *info = &self->patches[index];
+  memset(&info->orig_bytes[0], 0, MAX_INSTRUCTION_SIZE);
+  memcpy(&info->orig_bytes[0], data, instruction_size);
+  info->addr = addr;
+  info->size = instruction_size;
+}
+
+static size_t _patcher_disassemble_size(patcher_t *self, uint8_t* data, uint64_t addr, x86_insn type){
+
+    csh handle;
+    if (cs_open(CS_ARCH_X86, get_capstone_mode(self->cpu), &handle) == CS_ERR_OK){
+      cs_insn *insn = cs_malloc(handle);
+      uint8_t* cur_offset = data;
+      uint64_t cs_address = addr;
+      uint64_t code_size = MAX_INSTRUCTION_SIZE;
+      cs_disasm_iter(handle, (const uint8_t **) &cur_offset, &code_size, &cs_address, insn);
+      size_t size = insn->size;
+      if(type != X86_INS_INVALID){
+        assert(insn->id == type);
+      }
+      cs_free(insn, 1);
+      cs_close(&handle);
+      return size;
+    }
+    return 0;
+}
+
+static void _patcher_alloc_patch_infos(patcher_t *self, size_t num_patches){
+  assert(self->num_patches == 0);
+  assert(self->patches == NULL);
+  assert(num_patches < 10000);
+  self->num_patches = num_patches;
+  self->patches = malloc(sizeof(patch_info_t)*num_patches);
+}
+
+static void _patcher_free_patch_infos(patcher_t *self){
+  assert(!self->is_currently_applied);
+  free(self->patches);
+  self->patches = NULL;
+  self->num_patches = 0;
+}
+
+static redqueen_t* _redq_ptr(patcher_t *self){
+  redqueen_t* res = self->cpu->redqueen_state[0];
+  return res;
+}
diff --git a/pt/patcher.h b/pt/patcher.h
new file mode 100644
index 000000000..c57db7b0f
--- /dev/null
+++ b/pt/patcher.h
@@ -0,0 +1,54 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+#ifndef __GUARD_REDQUEEN_PATCHER_STRUCT__
+#define __GUARD_REDQUEEN_PATCHER_STRUCT__
+
+#include <stdint.h>
+#include <stddef.h>
+
+#include <capstone/capstone.h>
+#include <capstone/x86.h>
+
+#include "qemu/osdep.h"
+
+#define MAX_INSTRUCTION_SIZE 64
+//Patch used to replace cmp instructions. It encodes CMP AL, AL a comparision which always evaluates to true. This can
+//be used to remove hash checks that we suspsect can later on be patched.
+extern const uint8_t* cmp_patch; 
+
+typedef struct patch_info_s{
+  uint64_t addr;
+  size_t size;
+  uint8_t orig_bytes[MAX_INSTRUCTION_SIZE];
+} patch_info_t;
+
+typedef struct patcher_s{
+
+  CPUState *cpu;
+
+  patch_info_t *patches;
+  size_t num_patches;
+  bool is_currently_applied;
+} patcher_t;
+
+patcher_t* patcher_new(CPUState *cpu);
+
+void patcher_free(patcher_t *self);
+
+void patcher_apply_all(patcher_t *self);
+
+void patcher_restore_all(patcher_t *self);
+
+//Doesn't take ownership of addrs
+void patcher_set_addrs(patcher_t *self, uint64_t* addrs, size_t num_addrs);
+
+bool patcher_validate_patches(patcher_t *self);
+
+#endif
diff --git a/pt/printk.c b/pt/printk.c
new file mode 100644
index 000000000..94082ce81
--- /dev/null
+++ b/pt/printk.c
@@ -0,0 +1,113 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+#include "qemu/osdep.h"
+#include <linux/kvm.h>
+#include "qemu-common.h"
+#include "pt/memory_access.h"
+#include "pt/hypercall.h"
+#include "pt/printk.h"
+
+enum reg_types{RAX, RCX, RDX, RBX, RSP, RBP, RSI, RDI, R8, R9, R10, R11, R12, R13, R14, R15, RIP};
+
+uint8_t types[] = {RSI, RDX, RCX, R8, R9} ;
+/* calling convention: RDI, RSI, RDX, RCX, R8, R9 */
+
+/* https://www.kernel.org/doc/Documentation/printk-formats.txt :-( */
+
+bool kafl_linux_printk(CPUState *cpu){
+	X86CPU *x86_cpu = X86_CPU(cpu);
+    CPUX86State *env = &x86_cpu->env;
+
+	char printk_buf[0x1000];
+
+	uint8_t rsp_buf[0x1000];
+	uint8_t rdi_buf[0x1000];
+	uint8_t rsi_buf[0x1000];
+	uint8_t rdx_buf[0x1000];
+	uint8_t rcx_buf[0x1000];
+	uint8_t r8_buf[0x1000];
+	uint8_t r9_buf[0x1000];
+
+	read_virtual_memory((uint64_t)env->regs[RSP], (uint8_t*)rsp_buf, 0x1000, cpu);
+	read_virtual_memory((uint64_t)env->regs[RDI], (uint8_t*)rdi_buf, 0x1000, cpu);
+
+	uint8_t* buf[] = {rsi_buf, rdx_buf, rcx_buf, r8_buf, r9_buf};
+
+	
+
+	for(uint16_t i = 0, type = 0; i < 0x1000 && rdi_buf[i] != '\x00'; i++){
+
+		if(i > 1 && rdi_buf[i-2] == '%' && rdi_buf[i-1] != '%'){
+			
+			if(rdi_buf[i-1] == 's' || rdi_buf[i-1] == 'p' || rdi_buf[i-1] == '.'){
+
+				
+				if(rdi_buf[i] == 'B'){
+					rdi_buf[i-1] = 'l';
+					rdi_buf[i] = 'x';
+					buf[type] = (uint8_t*)env->regs[types[type]];
+				}
+
+				else if(rdi_buf[i-1] == 'p' && rdi_buf[i] == 'V'){
+					rdi_buf[i-1] = 's';
+					rdi_buf[i] = ' ';
+					read_virtual_memory((uint64_t)env->regs[types[type]],  (uint8_t*)buf[type], 0x1000, cpu);
+					uint64_t tmp = *((uint64_t*)buf[type]);
+					read_virtual_memory(tmp,  (uint8_t*)buf[type], 0x1000, cpu);
+
+				}
+				else if(rdi_buf[i-1] == 'p'){
+					rdi_buf[i-1] = 'l';
+					memmove(rdi_buf+i+1, rdi_buf+i, 0x1000-i-1);
+					rdi_buf[i] = 'x';
+					buf[type] = (uint8_t*)env->regs[types[type]];
+					
+				}
+				else {
+					read_virtual_memory((uint64_t)env->regs[types[type]],  (uint8_t*)buf[type], 0x1000, cpu);
+				}
+			}
+			else{
+				buf[type] = (uint8_t*)env->regs[types[type]];
+			}
+
+			type++;
+
+
+			if(type > 4){
+				rdi_buf[i] = '\n';
+				rdi_buf[i+1] = '\x00';
+				break;
+			}
+		}
+
+	}
+
+	snprintf(printk_buf, 0x1000, (char*)rdi_buf, buf[0], buf[1], buf[2], buf[3], buf[4]);
+	
+	if(printk_buf[0] == 0x1){
+		//printf("%s", rdi_buf+2);
+		hprintf(printk_buf+2);
+		//printf("%s", printk_buf+2);
+		if(!strncmp(printk_buf+2, "---[ end Kernel panic", 21)){
+			return true;
+		}
+	}
+	else {
+		//printf("%s", rdi_buf);
+		hprintf(printk_buf);
+		//printf("%s", printk_buf);
+		if(!strncmp(printk_buf, "---[ end Kernel panic", 21)){
+			return true;
+		}
+	}
+	return false;
+	
+}
diff --git a/pt/printk.h b/pt/printk.h
new file mode 100644
index 000000000..24895d186
--- /dev/null
+++ b/pt/printk.h
@@ -0,0 +1,17 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+
+#ifndef PRINTK_H
+#define PRINTK_H
+
+bool kafl_linux_printk(CPUState *cpu);
+
+
+#endif
diff --git a/pt/redqueen.c b/pt/redqueen.c
new file mode 100644
index 000000000..bae1e270d
--- /dev/null
+++ b/pt/redqueen.c
@@ -0,0 +1,905 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+#include <assert.h>
+#include <inttypes.h>
+
+#include "pt/redqueen.h"
+#include "pt/memory_access.h"
+#include "pt/disassembler.h"
+#include "pt/interface.h"
+#include "file_helper.h"
+#include "patcher.h"
+#include "debug.h"
+#include "asm_decoder.h"
+
+#include "exec/user/abitypes.h"
+
+const char* regs64[] = RQ_REG64;
+const char* regs32[] = RQ_REG32;
+const char* regs16[] = RQ_REG16;
+const char* regs8l[] = RQ_REG8L;
+const char* regs8h[] = RQ_REG8H;
+
+redqueen_workdir_t redqueen_workdir = {0};
+
+void setup_redqueen_workdir(char* workdir){
+   assert(asprintf(&redqueen_workdir.redqueen_results,"%s/redqueen_results.txt", workdir)>0);
+   assert(asprintf(&redqueen_workdir.symbolic_results,"%s/symbolic_results.txt", workdir)>0);
+   assert(asprintf(&redqueen_workdir.pt_trace_results,"%s/pt_trace_results.txt", workdir)>0);
+   assert(asprintf(&redqueen_workdir.redqueen_patches,"%s/redqueen_patches.txt", workdir)>0);
+   assert(asprintf(&redqueen_workdir.breakpoint_white,"%s/breakpoint_white.txt", workdir)>0);
+   assert(asprintf(&redqueen_workdir.breakpoint_black,"%s/breakpoint_black.txt", workdir)>0);
+   assert(asprintf(&redqueen_workdir.target_code_dump,"%s/target_code_dump.img", workdir)>0);
+}
+
+redqueen_t* new_rq_state(uint64_t start_range, uint64_t end_range, CPUState *cpu){
+	redqueen_t* res = malloc(sizeof(redqueen_t));
+	res->address_range_start = start_range;
+	res->address_range_end = end_range;
+	res->cpu = cpu;
+	res->intercept_mode = false;
+	res->trace_mode = false;
+	res->singlestep_enabled = false;
+  res->hooks_applied = 0;
+	assert((end_range-start_range) < 0x40000000);
+	res->bitmap_size = end_range-start_range;
+	res->bitmap = malloc(res->bitmap_size);
+	res->counter_bitmap = malloc(res->bitmap_size * sizeof(uint32_t));
+	memset(res->counter_bitmap, 0x00, (res->bitmap_size * sizeof(uint32_t)));
+	res->last_rip = 0x0;
+	memset(res->bitmap, CMP_BITMAP_NOP, end_range-start_range);
+  res->num_breakpoint_whitelist=0;
+  res->breakpoint_whitelist=NULL;
+
+	//FILE* pt_file = fopen("/tmp/redqueen_vm.img", "wb");
+	//delete_redqueen_files();
+  //fwrite(&start_range, sizeof(uint64_t), 1, pt_file);
+	//fwrite(code, sizeof(uint8_t), end_range-start_range, pt_file);
+	//fclose(pt_file);
+	return res;
+}
+
+void redqueen_set_trace_mode(redqueen_t* self){
+  delete_trace_files();
+  self->trace_mode = true;
+}
+
+void destroy_rq_state(redqueen_t* self){
+	free(self->bitmap);
+	free(self);
+}
+
+static void set_rq_trace_enabled_bp(redqueen_t* self, uint64_t addr){
+	if(addr >= self->address_range_start && addr <= self->address_range_end){
+    self->bitmap[addr-self->address_range_start] |= CMP_BITMAP_TRACE_ENABLED;
+  }
+}
+
+void set_rq_instruction(redqueen_t* self, uint64_t addr){
+	if(addr >= self->address_range_start && addr <= self->address_range_end){
+		if( !(self->bitmap[addr-self->address_range_start] & CMP_BITMAP_BLACKLISTED) ){
+			self->bitmap[addr-self->address_range_start] |= CMP_BITMAP_RQ_INSTRUCTION; 
+		}
+	}	
+}
+
+void set_se_instruction(redqueen_t* self, uint64_t addr){
+	if(addr >= self->address_range_start && addr <= self->address_range_end){
+		if( !(self->bitmap[addr-self->address_range_start] & CMP_BITMAP_BLACKLISTED) ){
+			self->bitmap[addr-self->address_range_start] |= CMP_BITMAP_SE_INSTRUCTION; 
+		}
+	}	
+}
+
+void set_rq_blacklist(redqueen_t* self, uint64_t addr){
+	if(addr >= self->address_range_start && addr <= self->address_range_end){
+		self->bitmap[addr-self->address_range_start] |= CMP_BITMAP_BLACKLISTED; 
+	}	
+}
+
+static void insert_hooks_whitelist(redqueen_t* self){
+  for(size_t i = 0; i < self->num_breakpoint_whitelist; i++){
+		kvm_insert_breakpoint(self->cpu, self->breakpoint_whitelist[i], 1, 0);
+  }
+}
+
+static void insert_hooks_bitmap(redqueen_t* self){
+	uint64_t c = 0;
+	//uint8_t data;
+	for(uint64_t i = 0; i < self->bitmap_size; i++){
+    int mode = self->cpu->redqueen_instrumentation_mode;
+    if(self->bitmap[i] & CMP_BITMAP_BLACKLISTED){ continue; }
+    bool should_hook_se = (self->bitmap[i] & CMP_BITMAP_SHOULD_HOOK_SE) && (mode == REDQUEEN_SE_INSTRUMENTATION);
+    bool should_hook_rq = (self->bitmap[i] & CMP_BITMAP_SHOULD_HOOK_RQ) && (mode == REDQUEEN_LIGHT_INSTRUMENTATION || REDQUEEN_SE_INSTRUMENTATION);
+		if( should_hook_se || should_hook_rq ){
+			kvm_insert_breakpoint(self->cpu, (i+self->address_range_start), 1, 0);
+			c++;
+		}
+	}
+}
+
+void redqueen_insert_hooks(redqueen_t* self){
+  QEMU_PT_DEBUG(REDQUEEN_PREFIX, "insert hooks");
+  assert(!self->hooks_applied);
+  switch(self->cpu->redqueen_instrumentation_mode){
+    case(REDQUEEN_SE_INSTRUMENTATION):
+    case(REDQUEEN_LIGHT_INSTRUMENTATION):
+      insert_hooks_bitmap(self);
+      break;
+    case(REDQUEEN_WHITELIST_INSTRUMENTATION):
+      insert_hooks_whitelist(self);
+      break;
+    case(REDQUEEN_NO_INSTRUMENTATION):
+      break;
+    default:
+      assert(false);
+  }
+  self->hooks_applied = 1;
+}
+
+void redqueen_remove_hooks(redqueen_t* self){
+  QEMU_PT_DEBUG(REDQUEEN_PREFIX, "remove hooks");
+  assert(self->hooks_applied);
+	kvm_remove_all_breakpoints(self->cpu);
+	memset(self->counter_bitmap, 0x00, (self->bitmap_size * sizeof(uint32_t)));
+  self->hooks_applied = 0;
+  return;
+}
+static uint64_t get_segment_register(redqueen_t* self, char* segmentor) {
+  X86CPU *cpu = X86_CPU(self->cpu);
+  CPUX86State *env = &cpu->env;
+  assert(strlen(segmentor) == 2);
+  assert(segmentor[1]=='s');
+  switch(segmentor[0]){
+    case('g'): return env->segs[R_GS].base;
+    case('f'): return env->segs[R_FS].base;
+    case('c'): return env->segs[R_CS].base;
+    case('d'): return env->segs[R_DS].base;
+    case('s'): return env->segs[R_SS].base;
+  }
+  assert(false);
+}
+
+static bool parse_reg(char* reg_str, uint8_t* index, uint8_t* type){
+	uint8_t j;
+
+	/* 64bit regs */
+	if (reg_str[0] == 'r'){
+		for(j = 0; j < REG64_NUM+1; j++){
+			if (!strcmp(reg_str, regs64[j])){
+				*type = VALUE64;
+				*index = j; 
+				return true;
+			}
+		}
+	}
+
+	/* 32bit regs */
+	if (reg_str[0] == 'r' || reg_str[0] == 'e'){
+		for(j = 0; j < REG32_NUM+1; j++){
+			if (!strcmp(reg_str, regs32[j])){
+				*type = VALUE32;
+				*index = j; 
+				return true;
+			}
+		}
+	}
+
+	/* 16bit regs */
+	if (reg_str[0] == 'r' || strlen(reg_str) == 2){
+		for(j = 0; j < REG16_NUM+1; j++){
+			if (!strcmp(reg_str, regs16[j])){
+				*type = VALUE16;
+				*index = j; 
+				return true;
+			}
+		}
+	}
+
+	/* 8bit regs high */
+	for(j = 0; j < REG8H_NUM; j++){
+		if (!strcmp(reg_str, regs8h[j])){
+			*type = VALUE8H;
+			*index = j; 
+			return true;
+		}
+	}
+
+	/* 8bit regs low */
+	for(j = 0; j < REG8L_NUM; j++){
+		if (!strcmp(reg_str, regs8l[j])){
+			*type = VALUE8L;
+			*index = j; 
+			return true;
+		}
+	}	
+	return false;
+}
+
+static inline uint64_t load64_qreg(redqueen_t* self, uint8_t index){
+  CPUX86State *env = &(X86_CPU(self->cpu))->env;
+	if (index == REG64_NUM){
+		return env->eip;
+	}
+	if (index > REG64_NUM){
+		return 0;
+	}
+	return env->regs[index];
+}
+
+static inline uint64_t sign_extend_from_size(uint64_t value, uint8_t size){
+  switch(size){
+    case 64: return value;
+    case 32: return ((int32_t)(value)<0) ? 0xffffffff00000000 | value : value;
+    case 16: return ((int16_t)(value)<0) ? 0xffffffffffff0000 | value : value;
+    case 8: return  (( int8_t)(value)<0) ? 0xffffffffffffff00 | value : value;
+  }
+  assert(false);
+}
+
+static inline uint64_t limit_to_type(uint64_t value, uint8_t type){
+	switch(type){
+		case VALUE64:
+			return value;
+		case VALUE32:
+			return value&0xffffffff;
+		case VALUE16:
+			return value &0xffff;
+		case VALUE8H:
+			return (value & 0xff00)>>8;
+		case VALUE8L:
+			return value &0xff;
+	}
+  assert(false);
+}
+
+static inline uint8_t type_to_bitsize(uint8_t type){
+	switch(type){
+		case VALUE64:
+			return 64;
+		case VALUE32:
+			return 32;
+		case VALUE16:
+			return 16;
+		case VALUE8H:
+			return 8;
+		case VALUE8L:
+			return 8;
+	}
+  assert(false);
+}
+
+static inline uint64_t load_qreg(redqueen_t* self, uint8_t index, uint8_t type){
+  return limit_to_type(load64_qreg(self, index), type);
+}
+
+static void parse_op_str2(char* op_str, asm_operand_t* op1, asm_operand_t* op2){
+
+	//QEMU_PT_PRINTF(REDQUEEN_PREFIX, "parsing 2 ops on: %s\n",op_str);
+  op1->was_present = false;
+  op2->was_present = false;
+  char* op_copy = strdup(op_str);
+  char* arg2 = op_copy;
+  char* arg1 = strsep(&arg2,",");
+	//QEMU_PT_PRINTF(REDQUEEN_PREFIX, "parsing arg1 on: %s\n",arg1);
+  asm_decoder_parse_op(arg1, op1);
+  if(arg2){
+	  //QEMU_PT_PRINTF(REDQUEEN_PREFIX,  "parsing arg2 on: %s\n",arg2);
+    while(*arg2 == ' ') arg2++;
+    asm_decoder_parse_op(arg2, op2);
+  } 
+  free(op_copy);
+}
+
+static uint64_t eval_reg(redqueen_t* self, char* regstr, uint8_t *size){
+    uint8_t index;
+    uint8_t type;
+    assert(parse_reg(regstr, &index, &type));
+    if(size){
+      *size = type_to_bitsize(type);
+    }
+    return load_qreg(self, index, type);
+}
+
+static uint64_t eval_addr(redqueen_t* self, asm_operand_t* op){
+
+  uint8_t size=0;
+  uint64_t base = 0; 
+  uint64_t index = 0;
+  uint64_t segment = 0;
+  if(op->base){
+    base = eval_reg(self, op->base, &size);
+  }
+  if(op->index){
+    index = eval_reg(self, op->index, &size);
+  }
+
+  if(op->segment){
+    segment = get_segment_register(self, op->segment);
+  }
+
+  uint64_t addr = segment + base + index*op->scale + op->offset;
+  return addr;
+}
+
+static uint64_t eval_mem(redqueen_t* self, asm_operand_t* op){
+  uint64_t val = 0;
+  QEMU_PT_DEBUG(REDQUEEN_PREFIX, "EVAL MEM FOR OP:");
+ //asm_decoder_print_op(op);
+  assert(op->ptr_size == 1 || op->ptr_size == 2 || op->ptr_size == 4 || op->ptr_size == 8);
+  read_virtual_memory(eval_addr(self, op), (uint8_t*) &val, op->ptr_size, self->cpu);
+  return val;
+}
+
+static uint64_t eval(redqueen_t* self, asm_operand_t *op, uint8_t* size){
+  switch(op->ptr_size){
+    case 0: break;
+    case 1: *size =8;  return eval_mem(self, op) &0xff;
+    case 2: *size =16; return eval_mem(self, op)&0xffff;
+    case 4: *size =32; return eval_mem(self, op)&0xffffffff;
+    case 8: *size =64; return eval_mem(self, op);
+    default: assert(false);
+  }
+  if(op->base){
+    return eval_reg(self, op->base, size);
+  }
+  *size=0;
+  return op->offset;
+}
+
+static void print_comp_result(uint64_t addr, const char* type, uint64_t val1, uint64_t val2, uint8_t size, bool is_imm){
+
+	char result_buf[256]; 
+  const char *format = NULL;
+	uint8_t pos = 0;
+			pos += snprintf(result_buf+pos, 256-pos, "%lx\t\t %s", addr, type);
+	    //QEMU_PT_PRINTF(REDQUEEN_PREFIX, "got size: %ld", size);
+      uint64_t mask = 0;
+			switch(size){
+				case 64: format = " 64\t%016lX-%016lX"; mask = 0xffffffffffffffff;  break;
+				case 32: format = " 32\t%08X-%08X";     mask = 0xffffffff;          break;
+				case 16: format = " 16\t%04X-%04X";     mask = 0xffff;              break;
+				case 8:  format = " 8\t%02X-%02X";      mask = 0xff;                break;
+        default:
+          assert(false);
+			}
+			pos += snprintf(result_buf+pos, 256-pos, format, val1 & mask, val2 & mask);
+			if(is_imm){
+				pos += snprintf(result_buf+pos, 256-pos, " IMM");
+			}
+			pos += snprintf(result_buf+pos, 256-pos, "\n");
+			write_re_result(result_buf);
+}
+
+bool redqueen_get_operands_at(redqueen_t* self, uint64_t addr, asm_operand_t *op1, asm_operand_t *op2){
+  asm_decoder_clear(op1);
+  asm_decoder_clear(op2);
+	csh handle;
+	cs_insn *insn;
+        size_t code_size = 15;
+        uint8_t code[15], *pcode = code;
+        if (!read_virtual_memory(addr, code, code_size, self->cpu))
+    	    return false;
+	uint64_t cs_address = addr;
+
+	//assert(self->disassembler_word_width == 32 || self->disassembler_word_width == 64);
+	if (cs_open(CS_ARCH_X86, get_capstone_mode(self->cpu), &handle) == CS_ERR_OK){
+		cs_option(handle, CS_OPT_DETAIL, CS_OPT_ON);
+		insn = cs_malloc(handle);
+		assert(cs_disasm_iter(handle, (const uint8_t **) &pcode, &code_size, &cs_address, insn)==1);
+
+    parse_op_str2(insn->op_str, op1, op2);
+
+    //asm_decoder_print_op(op1);
+    //asm_decoder_print_op(op2);
+
+		cs_free(insn, 1);
+		cs_close(&handle);
+    return true;
+	}
+  return false;
+}
+
+static void get_cmp_value(redqueen_t* self, uint64_t addr, const char* type){
+  asm_operand_t op1 = {0};
+  asm_operand_t op2 = {0};
+  uint8_t size_1=0;
+  uint8_t size_2=0;
+
+  if( redqueen_get_operands_at(self, addr, &op1, &op2) ) {
+    assert(op1.was_present && op2.was_present);
+
+    uint64_t v1 = eval(self, &op1, &size_1);
+    uint64_t v2 = eval(self, &op2, &size_2);
+
+    if(self->cpu->redqueen_instrumentation_mode == REDQUEEN_WHITELIST_INSTRUMENTATION  ||  v1 != v2){
+      print_comp_result(addr, type, v1, v2, (size_1 ? size_1 : size_2), asm_decoder_is_imm(&op2));
+    }
+    asm_decoder_clear(&op1);
+    asm_decoder_clear(&op2);
+  }
+}
+
+static void get_cmp_value_add(redqueen_t* self, uint64_t addr){
+  asm_operand_t op1 = {0};
+  asm_operand_t op2 = {0};
+  uint8_t size_1=0;
+  uint8_t size_2=0;
+
+  if( redqueen_get_operands_at(self, addr, &op1, &op2) ) {
+    assert(op1.was_present && op2.was_present);
+    if(!asm_decoder_is_imm(&op2)){return;}
+
+    uint64_t v1 = eval(self, &op1, &size_1);
+    uint64_t v2 = -sign_extend_from_size(eval(self, &op2, &size_2), size_1);
+
+    if(self->cpu->redqueen_instrumentation_mode == REDQUEEN_WHITELIST_INSTRUMENTATION  ||  v1 != v2){
+      print_comp_result(addr, "SUB", v1, v2, size_1, asm_decoder_is_imm(&op2));
+    }
+    asm_decoder_clear(&op1);
+    asm_decoder_clear(&op2);
+  }
+}
+
+static void get_cmp_value_lea(redqueen_t* self, uint64_t addr){
+  asm_operand_t op1 = {0};
+  asm_operand_t op2 = {0};
+
+  if( redqueen_get_operands_at(self, addr, &op1, &op2) ) {
+    assert(op1.was_present && op2.was_present);
+    assert(op2.ptr_size);
+      uint8_t size=0;
+      uint64_t index_val = eval_reg(self, op2.index, &size);
+      if(self->cpu->redqueen_instrumentation_mode == REDQUEEN_WHITELIST_INSTRUMENTATION  ||  index_val != -op2.offset){
+        print_comp_result(addr, "LEA", index_val, -op2.offset, op2.ptr_size*8, asm_decoder_is_imm(&op2));
+      }
+    asm_decoder_clear(&op1);
+    asm_decoder_clear(&op2);
+  }
+}
+
+
+static uint64_t limit_to_word_width(redqueen_t* self, uint64_t val){
+	switch(self->cpu->disassembler_word_width){
+	case 64:
+		return val;
+	case 32: 
+		return val & 0xffffffff;
+	default:
+		assert(false);
+	}
+}
+
+static uint64_t word_width_to_bytes(redqueen_t* self){
+	switch(self->cpu->disassembler_word_width){
+	case 64:
+		return 8;
+	case 32: 
+		return 4;
+	default:
+		assert(false);
+	}
+}
+
+static uint64_t read_stack(redqueen_t* self, uint64_t word_index){
+	CPUX86State *env = &(X86_CPU(self->cpu))->env;
+	uint64_t rsp = env->regs[4];
+	rsp = limit_to_word_width(self, rsp);
+	uint64_t res = 0;
+	uint64_t stack_ptr = rsp + word_index * word_width_to_bytes(self);
+	assert(read_virtual_memory(stack_ptr, (uint8_t*)(&res), 8, self->cpu));
+	return limit_to_word_width(self, res);
+}
+
+static void format_strcmp(redqueen_t* self, uint8_t* buf1, uint8_t* buf2){
+	char out_buf[REDQUEEN_MAX_STRCMP_LEN*4 + 2];
+	char* tmp_hex_buf = &out_buf[0];
+	for(int i = 0; i < REDQUEEN_MAX_STRCMP_LEN; i++){
+		tmp_hex_buf += sprintf(tmp_hex_buf, "%02X", (uint8_t)buf1[i]);
+	}
+	*tmp_hex_buf++ = '-';
+	for(int i = 0; i < REDQUEEN_MAX_STRCMP_LEN; i++){
+		tmp_hex_buf += sprintf(tmp_hex_buf, "%02X", (uint8_t)buf2[i]);
+	}
+	char *res=0;
+	CPUX86State *env = &(X86_CPU(self->cpu))->env;
+	uint64_t rip = env->eip;
+	assert(asprintf( &res, "%lx\t\tSTR %d\t%s\n", rip, REDQUEEN_MAX_STRCMP_LEN*8, out_buf ) != -1);
+	write_re_result(res);
+	free(res);
+}
+
+static bool test_strchr(redqueen_t* self, uint64_t arg1, uint64_t arg2){
+	if(!is_addr_mapped(arg1, self->cpu) || arg2 & (~0xff)){
+    return false;
+  }
+	uint8_t buf1[REDQUEEN_MAX_STRCMP_LEN];
+	uint8_t buf2[REDQUEEN_MAX_STRCMP_LEN];
+	assert(read_virtual_memory(arg1, &buf1[0], REDQUEEN_MAX_STRCMP_LEN, self->cpu));
+  if(!memchr(buf1,'\0',REDQUEEN_MAX_STRCMP_LEN) ){return false;}
+  memset(buf2,'\0',REDQUEEN_MAX_STRCMP_LEN);
+  buf2[0]=  (uint8_t)(arg2);
+  format_strcmp(self, buf1, buf2);
+  return true;
+}
+
+static bool test_strcmp(redqueen_t* self, uint64_t arg1, uint64_t arg2){
+	if(!is_addr_mapped(arg1, self->cpu) || ! is_addr_mapped(arg2, self->cpu)){
+		return false;
+	}
+	//QEMU_PT_PRINTF(REDQUEEN_PREFIX,"valid ptrs");
+	uint8_t buf1[REDQUEEN_MAX_STRCMP_LEN];
+	uint8_t buf2[REDQUEEN_MAX_STRCMP_LEN];
+	assert(read_virtual_memory(arg1, &buf1[0], REDQUEEN_MAX_STRCMP_LEN, self->cpu));
+	assert(read_virtual_memory(arg2, &buf2[0], REDQUEEN_MAX_STRCMP_LEN, self->cpu));
+  format_strcmp(self, buf1,buf2);
+	return true;
+}
+
+static bool test_strcmp_cdecl(redqueen_t* self){
+	uint64_t arg1 = read_stack(self, 0);
+	uint64_t arg2 = read_stack(self, 1);
+	//QEMU_PT_PRINTF(REDQUEEN_PREFIX, "extract call params cdecl %lx %lx", arg1, arg2);
+  test_strchr(self, arg1, arg2);
+	return test_strcmp(self, arg1, arg2) ;
+
+}
+
+static bool test_strcmp_fastcall(redqueen_t* self){
+	CPUX86State *env = &(X86_CPU(self->cpu))->env;
+	uint64_t arg1 = env->regs[1]; //rcx
+	uint64_t arg2 = env->regs[2]; //rdx
+	//QEMU_PT_PRINTF(REDQUEEN_PREFIX, "extract call params fastcall %lx %lx", arg1, arg2);
+  test_strchr(self, arg1, arg2);
+	return test_strcmp(self, arg1, arg2);
+}
+
+static bool test_strcmp_sys_v(redqueen_t* self){
+	if(self->cpu->disassembler_word_width != 64 ){return false;}
+	CPUX86State *env = &(X86_CPU(self->cpu))->env;
+	uint64_t arg1 = env->regs[7]; //rdx
+	uint64_t arg2 = env->regs[6]; //rsi
+	//QEMU_PT_PRINTF(REDQUEEN_PREFIX, "extract call params sysv %lx %lx", arg1, arg2);
+  test_strchr(self, arg1, arg2);
+	return test_strcmp(self, arg1, arg2);
+}
+
+static void extract_call_params(redqueen_t* self, uint64_t ip){
+	//QEMU_PT_PRINTF(REDQUEEN_PREFIX, "extract call at %lx", ip);
+	test_strcmp_cdecl(self);
+	test_strcmp_fastcall(self);
+	test_strcmp_sys_v(self);
+}
+
+static bool is_memory_access(redqueen_t* self, cs_insn* insn){
+  return insn->id != X86_INS_LEA && strstr(insn->op_str,"[");
+}
+
+static bool is_trace_entry_point(redqueen_t* self, uint64_t addr){
+	if(addr >= self->address_range_start && addr <= self->address_range_end){
+    return self->bitmap[addr-self->address_range_start] & CMP_BITMAP_TRACE_ENABLED;
+  }
+  return false;
+}
+
+static void handle_hook_redqueen_light(redqueen_t* self, uint64_t ip, cs_insn *insn){
+	if(insn->id == X86_INS_CMP || insn->id == X86_INS_XOR){ //handle original redqueen case
+		get_cmp_value(self, ip, "CMP");
+  } else if(insn->id == X86_INS_SUB){ //handle original redqueen case
+		get_cmp_value(self, ip, "SUB");
+  } else if(insn->id == X86_INS_LEA){ //handle original redqueen case
+		get_cmp_value_lea(self, ip);
+  } else if(insn->id == X86_INS_ADD){ //handle original redqueen case
+		get_cmp_value_add(self, ip);
+	} else if (insn->id == X86_INS_CALL || insn->id == X86_INS_LCALL){
+		extract_call_params(self, ip);
+	}
+}
+
+static void handle_hook_redqueen_se( redqueen_t* self, uint64_t ip, cs_insn *insn){
+	int unused __attribute__((unused));
+	CPUX86State *env = &(X86_CPU(self->cpu))->env;
+    if( is_trace_entry_point(self, ip) ){
+      char* res = NULL;
+      unused = asprintf(&res, "{\"ep\": %"PRIu64", ", ip);
+      write_se_result(res);
+      dump_se_registers(self);
+      write_se_result((char*)" }\n");
+      write_se_result((char*)"{ ");
+      dump_se_memory_access_at(self, env->eip, env->regs[RSP]+64);
+      write_se_result((char*)" }\n");
+      free(res);
+    }
+    if( is_memory_access(self, insn) ){
+      write_se_result((char*)"{ ");
+      dump_se_memory_access(self, insn);
+      write_se_result((char*)" }\n");
+    }
+    if(insn->id == X86_INS_RET || insn->id == X86_INS_POP){
+      write_se_result((char*)"{ ");
+      dump_se_return_access(self, insn);
+      write_se_result((char*)" }\n");
+    }
+}
+
+static void handle_hook_breakpoint(redqueen_t* self){
+    X86CPU *cpu = X86_CPU(self->cpu);
+    CPUX86State *env = &cpu->env;
+    csh handle;
+    cs_insn *insn;
+    uint64_t ip = env->eip;
+    //uint8_t* code = (self->code+(ip-self->address_range_start));
+    size_t code_size = 15;
+    uint8_t code[15];
+    if (!read_virtual_memory(ip, code, code_size, self->cpu))
+	    return;
+    //uint64_t cs_address = ip;
+    if (cs_open(CS_ARCH_X86, get_capstone_mode(self->cpu), &handle) == CS_ERR_OK){
+      cs_option(handle, CS_OPT_DETAIL, CS_OPT_ON);
+      size_t count = cs_disasm(handle, code, code_size, ip, 1, &insn);
+	  QEMU_PT_DEBUG(REDQUEEN_PREFIX, " === HANDLE REDQUEEN HOOK %s %s ===", insn->mnemonic, insn->op_str);
+      if(count > 0){
+        int mode = self->cpu->redqueen_instrumentation_mode;
+        if(mode == REDQUEEN_LIGHT_INSTRUMENTATION || mode == REDQUEEN_WHITELIST_INSTRUMENTATION || mode == REDQUEEN_SE_INSTRUMENTATION){
+          handle_hook_redqueen_light(self, ip, insn);
+        }
+        if(mode == REDQUEEN_SE_INSTRUMENTATION){
+          handle_hook_redqueen_se(self, ip, insn);
+        }
+      }
+      cs_close(&handle);
+      cs_free(insn, count);
+    } else{
+      printf("Oops!\n");
+    }
+}
+
+/*
+static void debug_print_disasm(char* desc, uint64_t ip, CPUState* cpu_state){
+  //uint64_t cs_address = ip;
+  uint8_t code[64];
+  csh handle;
+  cs_insn *insn;
+  read_virtual_memory(ip, &code[0], 64, cpu_state);
+  if (cs_open(CS_ARCH_X86, get_capstone_mode(cpu_state->disassembler_word_width), &handle) == CS_ERR_OK){
+    cs_option(handle, CS_OPT_DETAIL, CS_OPT_ON);
+    size_t count = cs_disasm(handle, &code[0], 64, ip, 1, &insn);
+    if(count > 0){
+      QEMU_PT_PRINTF(REDQUEEN_PREFIX,"%s\t %lx: %s %s",desc, ip,  insn->mnemonic, insn->op_str);
+    } else {
+      QEMU_PT_PRINTF(REDQUEEN_PREFIX,"%s\t Failed to disassemble at: %lx",desc, ip);
+    }
+    cs_close(&handle);
+    cs_free(insn, count);
+  } else {
+      QEMU_PT_PRINTF(REDQUEEN_PREFIX,"%s\t Failed to create capstone instance at: %lx",desc, ip);
+  }
+}
+*/
+
+/*
+static void debug_print_state(char* desc, CPUState* cpu_state){
+  X86CPU *cpu = X86_CPU(cpu_state);
+  CPUX86State *env = &cpu->env;
+  debug_print_disasm(desc, env->eip, cpu_state);
+  QEMU_PT_PRINTF(REDQUEEN_PREFIX,"ECX: %lx", get_reg_cpu(cpu_state, (char*)"rcx"));
+}
+*/
+
+int trace_debug = false;
+
+void handle_hook(redqueen_t* self){
+  X86CPU *cpu = X86_CPU(self->cpu);
+  CPUX86State *env = &cpu->env;
+  if(!self->cpu->singlestep_enabled){
+    self->last_rip = env->eip;
+    kvm_remove_breakpoint(self->cpu, env->eip, 1, 0);
+    self->cpu->singlestep_enabled = true;
+    self->singlestep_enabled = true;
+    kvm_update_guest_debug(self->cpu, 0);
+    if(self->cpu->pt_enabled && self->cpu->pt_c3_filter == env->cr[3]){
+      handle_hook_breakpoint(self);
+    }
+  } else{
+    self->cpu->singlestep_enabled = false;
+    self->singlestep_enabled = false;
+    kvm_update_guest_debug(self->cpu, 0);
+    if(self->counter_bitmap[self->last_rip-self->address_range_start]++ < REDQUEEN_TRAP_LIMIT){
+	  kvm_insert_breakpoint(self->cpu, self->last_rip, 1, 0);
+    }
+  }
+}
+
+void dump_se_return_access(redqueen_t* self, cs_insn* insn){
+  int unused __attribute__((unused));
+  X86CPU *cpu = X86_CPU(self->cpu);
+  CPUX86State *env = &cpu->env;
+  char* res = NULL;
+  uint8_t buf[8];
+  char hex_buf[16+1];
+  abi_ulong begin = env->regs[RSP];
+  read_virtual_memory(begin, (uint8_t*)&buf, 8, self->cpu);
+  char* tmp_hex_buf = hex_buf;
+  for(int i = 0; i < 8; i++){
+    tmp_hex_buf += sprintf(tmp_hex_buf, "%02X", (uint8_t)buf[i]);
+  }
+  unused = asprintf(&res,
+                    "\"access\":" TARGET_FMT_lu
+                    ", \"mem\":["TARGET_FMT_lu
+                    ",\"%s\"]",
+                    env->eip, begin, hex_buf ) ;
+  write_se_result(res);
+  free(res);
+}
+
+#define REDQUEEN_SE_MEMORY_DUMP_SIZE 256
+#define REDQUEEN_SE_MEMORY_DUMP_OFFSET 64
+
+void dump_se_memory_access_at(redqueen_t* self, uint64_t instr_addr, uint64_t mem_addr){
+      int unused __attribute__((unused));
+      char* res = NULL;
+      uint8_t buf[REDQUEEN_SE_MEMORY_DUMP_SIZE];
+      char hex_buf[REDQUEEN_SE_MEMORY_DUMP_SIZE*2+1];
+      memset(buf,'X',REDQUEEN_SE_MEMORY_DUMP_SIZE);
+      if(mem_addr > 24+REDQUEEN_SE_MEMORY_DUMP_OFFSET){
+        uint64_t begin = mem_addr - REDQUEEN_SE_MEMORY_DUMP_OFFSET;
+        read_virtual_memory(begin, (uint8_t*)&buf, REDQUEEN_SE_MEMORY_DUMP_SIZE, self->cpu);
+        char* tmp_hex_buf = hex_buf;
+        for(int i = 0; i < REDQUEEN_SE_MEMORY_DUMP_SIZE; i++){
+          tmp_hex_buf += sprintf(tmp_hex_buf, "%02X", (uint8_t)buf[i]);
+        }
+        unused = asprintf( &res, "\"access\":%"PRIu64", \"mem\":[%"PRIu64",\"%s\"]", instr_addr, begin, hex_buf ) ;
+        write_se_result(res);
+        free(res);
+      }
+}
+
+static void dump_se_memory_for_op(redqueen_t* self, asm_operand_t *op){
+    X86CPU *cpu = X86_CPU(self->cpu);
+    CPUX86State *env = &cpu->env;
+    if(op->was_present && op->ptr_size){
+      uint64_t addr = eval_addr(self, op);
+      dump_se_memory_access_at(self, env->eip, addr);
+    }
+}
+
+void dump_se_memory_access(redqueen_t* self, cs_insn* insn){
+  asm_operand_t op1 = {0};
+  asm_operand_t op2 = {0};
+  parse_op_str2(insn->op_str, &op1, &op2);
+  dump_se_memory_for_op(self, &op1);
+  dump_se_memory_for_op(self, &op2);
+  asm_decoder_clear(&op1);
+  asm_decoder_clear(&op2);
+}
+
+
+void dump_se_registers(redqueen_t* self){
+  int unused __attribute__((unused));
+  char* res = NULL;
+  X86CPU *cpu = X86_CPU(self->cpu);
+  CPUX86State *env = &cpu->env;
+  abi_ulong rip = env->eip;
+  abi_ulong rax = env->regs[RAX];
+  abi_ulong rbx = env->regs[RBX];
+  abi_ulong rcx = env->regs[RCX];
+  abi_ulong rdx = env->regs[RDX];
+  abi_ulong rsp = env->regs[RSP];
+  abi_ulong rbp = env->regs[RBP];
+  abi_ulong rsi = env->regs[RSI];
+  abi_ulong rdi = env->regs[RDI];
+  abi_ulong r8 =  env->regs[R8];
+#if defined(TARGET_X86_64)
+  abi_ulong r9 =  env->regs[R9];
+  abi_ulong r10 = env->regs[R10];
+  abi_ulong r11 = env->regs[R11];
+  abi_ulong r12 = env->regs[R12];
+  abi_ulong r13 = env->regs[R13];
+  abi_ulong r14 = env->regs[R14];
+  abi_ulong r15 = env->regs[R15];
+#endif
+  abi_ulong eflags = env->eflags;
+  abi_ulong gs = env->segs[R_GS].base;
+  abi_ulong fs = env->segs[R_FS].base;
+  //printf(
+  //    "\"regs\":[" "%"PRIx64 ",%"PRIx64 ",%"PRIx64 ",%"PRIx64 ",%"PRIx64 ",%"PRIx64 ",%"PRIx64 ",%"PRIx64 ",%"PRIx64 ",%"PRIx64 ",%"PRIx64 ",%"PRIx64 ",%"PRIx64 ",%"PRIx64 ",%"PRIx64 ",%"PRIx64 ",%"PRIx64 ",%"PRIx64 ",%"PRIx64 "]\n",
+  //              rip,   rax,   rbx,   rcx,   rdx,    r8,    r9,   r10,   r11,   r12,   r13,   r14,   r15,   rsp,   rbp,   rsi,   rdi,eflags,    gs) ;
+  unused = asprintf(&res,
+      "\"regs\":[" TARGET_FMT_lu "," TARGET_FMT_lu "," TARGET_FMT_lu "," TARGET_FMT_lu ","
+                   TARGET_FMT_lu "," TARGET_FMT_lu "," TARGET_FMT_lu "," TARGET_FMT_lu ","
+#if defined(TARGET_X86_64)
+                   TARGET_FMT_lu "," TARGET_FMT_lu "," TARGET_FMT_lu "," TARGET_FMT_lu ","
+                   TARGET_FMT_lu "," TARGET_FMT_lu "," TARGET_FMT_lu ","
+#endif
+                   TARGET_FMT_lu "," TARGET_FMT_lu "," TARGET_FMT_lu "," TARGET_FMT_lu "," TARGET_FMT_lu "]",
+                   rip, rax, rbx, rcx, rdx, r8,
+#if defined(TARGET_X86_64)
+                   r9, r10, r11, r12, r13, r14, r15,
+#endif
+                   rsp, rbp, rsi, rdi, eflags, gs, fs) ;
+  write_se_result(res);
+  free(res);
+}
+
+void redqueen_register_transition(redqueen_t* self, uint64_t src, uint64_t target){
+	int unused __attribute__((unused));
+	if(self->trace_mode){
+#ifdef RQ_DEBUG
+		printf("{\"edge\": [%"PRIu64",%"PRIu64"] }\n", src, target);
+#endif
+		char* res = NULL;
+		unused = asprintf(&res, "{\"edge\": [%"PRIu64",%"PRIu64"] }\n", src, target);
+		write_trace_result(res);
+		free(res);
+	}
+}
+
+void redqueen_trace_enabled(redqueen_t* self, uint64_t ip){
+	int unused __attribute__((unused));
+  if(self->trace_mode){
+    char* res = NULL;
+    unused = asprintf(&res, "{\"trace_enable\": %"PRIu64" }\n", ip);
+    write_trace_result(res);
+    free(res);
+    set_rq_trace_enabled_bp(self, ip);
+  } 
+}
+
+void redqueen_trace_disabled(redqueen_t* self, uint64_t ip){
+  //if(!self->intercept_mode){
+  //  char* res = NULL;
+  //  asprintf(&res, "{\"trace_disable\": %"PRIu64" }\n", ip);
+  //  write_trace_result(res);
+  //  free(res);
+  //}
+}
+
+static void _redqueen_update_whitelist(redqueen_t* self){
+  if(self->cpu->redqueen_instrumentation_mode == REDQUEEN_WHITELIST_INSTRUMENTATION){
+    //size_t num_addrs = 0;
+    //uint64_t *addrs;
+    free(self->breakpoint_whitelist);
+    parse_address_file(redqueen_workdir.breakpoint_white, &self->num_breakpoint_whitelist, &self->breakpoint_whitelist);
+  }
+}
+
+static void _redqueen_update_blacklist(redqueen_t* self){
+  if(self->cpu->redqueen_update_blacklist){
+    size_t num_addrs = 0;
+    uint64_t *addrs;
+    parse_address_file(redqueen_workdir.breakpoint_black, &num_addrs, &addrs);
+    for(size_t i = 0; i< num_addrs; i++){
+      set_rq_blacklist(self, addrs[i]);
+    }
+    free(addrs);
+  }
+}
+
+extern void* payload_buffer;
+
+void enable_rq_intercept_mode(redqueen_t* self){
+	if(!self->intercept_mode){
+		delete_redqueen_files();
+		//unlink("/tmp/redqueen_result.txt");
+    _redqueen_update_whitelist(self);
+    _redqueen_update_blacklist(self);
+		redqueen_insert_hooks(self);
+		self->intercept_mode = true;
+		//((uint8_t*) payload_buffer)[PAYLOAD_SIZE-1] = 1;
+	}
+}
+
+void disable_rq_intercept_mode(redqueen_t* self){
+	if(self->intercept_mode){
+		redqueen_remove_hooks(self);
+		self->intercept_mode = false;
+		//((uint8_t*) payload_buffer)[PAYLOAD_SIZE-1] = 0;
+	}
+}
diff --git a/pt/redqueen.h b/pt/redqueen.h
new file mode 100644
index 000000000..24734144e
--- /dev/null
+++ b/pt/redqueen.h
@@ -0,0 +1,122 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+#ifndef REDQUEEN_H
+#define REDQUEEN_H
+
+#include <stddef.h>
+#include <stdlib.h>
+#include <string.h>
+#include <stdint.h>
+#include <stdbool.h>
+#include "qemu/osdep.h"
+#include <linux/kvm.h>
+#include <capstone/capstone.h>
+#include <capstone/x86.h>
+#include "asm_decoder.h"
+
+//#define RQ_DEBUG
+
+#define REDQUEEN_MAX_STRCMP_LEN 64
+#define REDQUEEN_TRAP_LIMIT	16
+
+#define REG64_NUM 16
+#define REG32_NUM 16
+//seems we don't want to include rip, since this index is used to acces the qemu cpu structure or something?
+#define REG16_NUM 16
+#define REG8L_NUM 16
+#define REG8H_NUM  8
+
+#define EXTRA_REG_RIP 16
+#define EXTRA_REG_NOP 17
+
+#define REDQUEEN_NO_INSTRUMENTATION 0
+#define REDQUEEN_LIGHT_INSTRUMENTATION 1
+#define REDQUEEN_SE_INSTRUMENTATION 2
+#define REDQUEEN_WHITELIST_INSTRUMENTATION 3
+
+enum reg_types{RAX, RCX, RDX, RBX, RSP, RBP, RSI, RDI, R8, R9, R10, R11, R12, R13, R14, R15};
+
+#define RQ_REG64 {"rax", "rcx", "rdx", "rbx", "rsp", "rbp", "rsi", "rdi", "r8",  "r9",  "r10",  "r11",  "r12",  "r13",  "r14", "r15",   "rip"}
+#define RQ_REG32 {"eax", "ecx", "edx", "ebx", "esp", "ebp", "esi", "edi", "r8d", "r9d", "r10d", "r11d", "r12d", "r13d", "r14d", "r15d", "eip"}
+#define RQ_REG16 {"ax",  "cx",  "dx",  "bx",  "sp",  "bp",  "si",  "di",  "r8w", "r9w", "r10w", "r11w", "r12w", "r13w", "r14w", "r15w", "ip" }
+#define RQ_REG8L {"al",  "cl",  "dl",  "bl",  "spl", "bpl", "sil", "dil", "r8b", "r9b", "r10b", "r11b", "r12b", "r13b", "r14b", "r15b"}
+#define RQ_REG8H {"ah",  "ch",  "dh",  "bh",  "sph", "bph", "sih", "dih" } 
+
+enum operand_types{VALUE64, VALUE32, VALUE16, VALUE8, VALUE8H, VALUE8L};
+
+#define CMP_BITMAP_NOP			0
+#define CMP_BITMAP_RQ_INSTRUCTION	1
+#define CMP_BITMAP_SE_INSTRUCTION	2
+#define CMP_BITMAP_BLACKLISTED	  4
+#define CMP_BITMAP_TRACE_ENABLED  8
+#define CMP_BITMAP_SHOULD_HOOK_SE (CMP_BITMAP_SE_INSTRUCTION|CMP_BITMAP_TRACE_ENABLED)
+#define CMP_BITMAP_SHOULD_HOOK_RQ (CMP_BITMAP_RQ_INSTRUCTION)
+
+typedef struct redqueen_s{
+	uint64_t bitmap_size;
+	uint8_t* bitmap;
+	uint32_t* counter_bitmap;
+	uint64_t address_range_start;
+	uint64_t address_range_end;
+	bool intercept_mode;
+	bool trace_mode;
+	bool singlestep_enabled;
+	int hooks_applied;
+	CPUState *cpu;
+	uint64_t last_rip;
+  uint64_t *breakpoint_whitelist;
+  uint64_t num_breakpoint_whitelist;
+} redqueen_t;
+
+typedef struct redqueen_workdir_s{
+  char* redqueen_results;
+  char* symbolic_results;
+  char* pt_trace_results;
+  char* redqueen_patches;
+  char* breakpoint_white;
+  char* breakpoint_black;
+  char* target_code_dump;
+} redqueen_workdir_t;
+
+extern redqueen_workdir_t redqueen_workdir;
+
+void setup_redqueen_workdir(char* workdir);
+
+redqueen_t* new_rq_state(uint64_t start_range, uint64_t end_range, CPUState *cpu);
+void destroy_rq_state(redqueen_t* self);
+
+void set_rq_instruction(redqueen_t* self, uint64_t addr);
+void set_rq_blacklist(redqueen_t* self, uint64_t addr);
+
+void handle_hook(redqueen_t* self);
+void handel_se_hook(redqueen_t* self);
+
+void enable_rq_intercept_mode(redqueen_t* self);
+void disable_rq_intercept_mode(redqueen_t* self);
+
+
+bool redqueen_get_operands_at(redqueen_t* self, uint64_t addr, asm_operand_t *op1, asm_operand_t *op2);
+
+void redqueen_register_transition(redqueen_t* self, uint64_t ip, uint64_t transition_val);
+void redqueen_trace_enabled(redqueen_t* self, uint64_t ip);
+void redqueen_trace_disabled(redqueen_t* self, uint64_t ip);
+void redqueen_set_trace_mode(redqueen_t* self);
+
+void set_se_instruction(redqueen_t* self, uint64_t addr);
+
+void dump_se_registers(redqueen_t* self);
+void dump_se_memory_access(redqueen_t* self, cs_insn* insn);
+void dump_se_return_access(redqueen_t* self, cs_insn* insn);
+void dump_se_memory_access_at(redqueen_t* self, uint64_t instr_addr, uint64_t mem_addr);
+
+void redqueen_insert_hooks(redqueen_t* self);
+void redqueen_remove_hooks(redqueen_t* self);
+
+#endif
diff --git a/pt/redqueen_patch.c b/pt/redqueen_patch.c
new file mode 100644
index 000000000..cf796742a
--- /dev/null
+++ b/pt/redqueen_patch.c
@@ -0,0 +1,49 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+#include "redqueen_patch.h"
+#include "redqueen.h"
+#include "patcher.h"
+#include "file_helper.h"
+#include "debug.h"
+
+///////////////////////////////////////////////////////////////////////////////////
+// Private Helper Functions Declarations
+///////////////////////////////////////////////////////////////////////////////////
+
+void _load_and_set_patches(patcher_t* self);
+
+///////////////////////////////////////////////////////////////////////////////////
+// Public Functions
+///////////////////////////////////////////////////////////////////////////////////
+
+void pt_enable_patches(patcher_t *self){
+  _load_and_set_patches(self);
+  patcher_apply_all(self);
+}
+
+void pt_disable_patches(patcher_t *self){
+  patcher_restore_all(self);
+}
+
+
+///////////////////////////////////////////////////////////////////////////////////
+// Private Helper Functions Definitions
+///////////////////////////////////////////////////////////////////////////////////
+
+
+void _load_and_set_patches(patcher_t* self){
+  size_t num_addrs = 0;
+  uint64_t *addrs = NULL;
+  parse_address_file(redqueen_workdir.redqueen_patches, &num_addrs, &addrs);
+  if(num_addrs){
+    patcher_set_addrs(self, addrs, num_addrs);
+    free(addrs);
+  }
+}
diff --git a/pt/redqueen_patch.h b/pt/redqueen_patch.h
new file mode 100644
index 000000000..cbd3b4c3d
--- /dev/null
+++ b/pt/redqueen_patch.h
@@ -0,0 +1,20 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+#ifndef __GUARD_REDQUEEN_PATCH__
+#define __GUARD_REDQUEEN_PATCH__
+
+#include "qemu/osdep.h"
+#include <linux/kvm.h>
+#include "pt/patcher.h"
+
+void pt_enable_patches(patcher_t *self);
+
+void pt_disable_patches(patcher_t *self);
+#endif
diff --git a/pt/synchronization.c b/pt/synchronization.c
new file mode 100644
index 000000000..192b735b3
--- /dev/null
+++ b/pt/synchronization.c
@@ -0,0 +1,110 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+#include "pt/synchronization.h"
+#include "pt/hypercall.h"
+#include "pt/interface.h"
+#include "qemu-common.h"
+#include "qemu/osdep.h"
+#include "cpu.h"
+#include "sysemu/sysemu.h"
+#include "sysemu/runstate.h"
+#include "sysemu/kvm.h"
+#include "pt.h"
+
+pthread_mutex_t synchronization_lock_mutex = PTHREAD_MUTEX_INITIALIZER;
+pthread_cond_t synchronization_lock_condition = PTHREAD_COND_INITIALIZER;
+pthread_mutex_t synchronization_disable_pt_mutex = PTHREAD_MUTEX_INITIALIZER;
+
+volatile bool synchronization_reload_pending = false;
+volatile bool synchronization_kvm_loop_waiting = false;
+
+void synchronization_check_reload_pending(CPUState *cpu){
+	bool value;
+	pthread_mutex_lock(&synchronization_lock_mutex);
+	value = synchronization_reload_pending;
+	if(value){
+		qatomic_set(&cpu->kvm_run->immediate_exit, 1);
+	}
+	pthread_mutex_unlock(&synchronization_lock_mutex);
+}
+
+void synchronization_unlock(void){
+	pthread_mutex_lock(&synchronization_lock_mutex);
+	pthread_cond_signal(&synchronization_lock_condition);
+	hypercall_reset_hprintf_counter();
+	pthread_mutex_unlock(&synchronization_lock_mutex);
+}	
+
+void synchronization_lock(CPUState *cpu){
+
+	pthread_mutex_lock(&synchronization_lock_mutex);
+	if(!synchronization_reload_pending){
+		synchronization_kvm_loop_waiting = true;
+
+		if(cpu->intel_pt_run_trashed){
+			//fprintf(stderr, "KAFL_PROTO_PT_TRASHED\n");
+			hypercall_snd_char(KAFL_PROTO_PT_TRASHED);
+			cpu->intel_pt_run_trashed = false;
+		} 
+		else {
+			hypercall_snd_char(KAFL_PROTO_ACQUIRE);
+		}
+	}
+	else{
+		qatomic_set(&cpu->kvm_run->immediate_exit, 1);
+		pthread_mutex_unlock(&synchronization_lock_mutex);
+		return;
+	}
+	printf("Waiting...\n");
+	pthread_cond_wait(&synchronization_lock_condition, &synchronization_lock_mutex);
+	printf("After waiting\n");
+	synchronization_kvm_loop_waiting = false;
+	pthread_mutex_unlock(&synchronization_lock_mutex);
+}	
+
+void synchronization_reload_vm(void){
+	CPUState *cpu = qemu_get_cpu(0);
+	assert(false);
+
+	pthread_mutex_lock(&synchronization_lock_mutex);
+	synchronization_reload_pending = true;
+	if(synchronization_kvm_loop_waiting){
+		pthread_cond_signal(&synchronization_lock_condition);
+	}
+	hypercall_reset_hprintf_counter();
+	synchronization_disable_pt(cpu);
+	pthread_mutex_unlock(&synchronization_lock_mutex);
+
+	//kvm_cpu_synchronize_state(cpu);
+	vm_stop(RUN_STATE_RESTORE_VM);
+
+
+	pthread_mutex_lock(&synchronization_lock_mutex);
+
+	//fast_loadvm();
+
+	synchronization_reload_pending = false;
+	synchronization_kvm_loop_waiting = false;
+	qatomic_set(&cpu->kvm_run->immediate_exit, 0);
+
+	hypercall_snd_char(KAFL_PROTO_RELOAD);
+	pthread_mutex_unlock(&synchronization_lock_mutex);
+
+	vm_start();
+	//kvm_cpu_synchronize_state(cpu);
+}
+
+void synchronization_disable_pt(CPUState *cpu){
+	pthread_mutex_lock(&synchronization_disable_pt_mutex);
+	pt_disable(cpu, false);
+	pt_sync();
+	//kvm_cpu_synchronize_state(cpu);
+	pthread_mutex_unlock(&synchronization_disable_pt_mutex);
+}
diff --git a/pt/synchronization.h b/pt/synchronization.h
new file mode 100644
index 000000000..48722cf10
--- /dev/null
+++ b/pt/synchronization.h
@@ -0,0 +1,19 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+#pragma once
+
+#include "qemu/osdep.h"
+#include <linux/kvm.h>
+
+void synchronization_check_reload_pending(CPUState *cpu);
+void synchronization_unlock(void);
+void synchronization_lock(CPUState *cpu);
+void synchronization_reload_vm(void);
+void synchronization_disable_pt(CPUState *cpu);
diff --git a/pt/tmp.objs b/pt/tmp.objs
new file mode 100644
index 000000000..419b2f8d9
--- /dev/null
+++ b/pt/tmp.objs
@@ -0,0 +1,2 @@
+obj-y += decoder.o disassembler.o tnt_cache.o logger.o pt.o memory_access.o kafl_guest.o
+
diff --git a/pt/tnt_cache.c b/pt/tnt_cache.c
new file mode 100644
index 000000000..a27851675
--- /dev/null
+++ b/pt/tnt_cache.c
@@ -0,0 +1,82 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+#include "tnt_cache.h"
+#include <assert.h>
+#include <sys/mman.h>
+#include <string.h>
+
+#define BIT(x)				(1ULL << (x))
+
+static inline uint8_t asm_bsr(uint64_t x){
+	asm ("bsrq %0, %0" : "=r" (x) : "0" (x));
+	return x;
+}
+
+uint8_t process_tnt_cache(tnt_cache_t* self){
+	uint8_t result;
+	if (self->tnt){
+		result = self->tnt_memory[self->pos];
+		self->tnt--;
+		self->pos = (self->pos + 1) % BUF_SIZE;
+		return result;
+	}
+	return TNT_EMPTY;
+}
+
+void append_tnt_cache(tnt_cache_t* self, uint8_t data){
+	uint8_t bits = asm_bsr(data)-SHORT_TNT_OFFSET;
+	for(uint8_t i = SHORT_TNT_OFFSET; i < bits+SHORT_TNT_OFFSET; i++){
+		self->tnt_memory[((self->max+bits-i)%BUF_SIZE)] = ((data) & BIT(i)) >> i;
+	}
+
+	self->tnt += bits;
+	self->max = (self->max + bits) % BUF_SIZE;
+}	
+
+void append_tnt_cache_ltnt(tnt_cache_t* self, uint64_t data){
+	uint8_t bits = asm_bsr(data)-LONG_TNT_MAX_BITS;
+	for(uint8_t i = LONG_TNT_MAX_BITS; i < bits+LONG_TNT_MAX_BITS; i++){
+		self->tnt_memory[((self->max+bits-i)%BUF_SIZE)] = ((data) & BIT(i)) >> i;
+	}
+
+	self->tnt += bits;
+	self->max = (self->max + bits) % BUF_SIZE;
+}	
+
+bool is_empty_tnt_cache(tnt_cache_t* self){
+	return (bool)!!(self->tnt);
+}
+
+int count_tnt(tnt_cache_t* self){
+	return self->tnt;
+}
+
+tnt_cache_t* tnt_cache_init(void){
+	tnt_cache_t* self = malloc(sizeof(tnt_cache_t));
+	self->tnt_memory = (uint8_t*)mmap(NULL, BUF_SIZE, PROT_READ | PROT_WRITE, MAP_ANONYMOUS | MAP_PRIVATE, 0, 0);
+	self->max = 0;
+	self->pos = 0;
+	self->tnt = 0;
+	return self;
+}
+
+void tnt_cache_flush(tnt_cache_t* self){
+	self->max = 0;
+	self->pos = 0;
+	self->tnt = 0;
+}
+
+void tnt_cache_destroy(tnt_cache_t* self){
+	munmap(self->tnt_memory, BUF_SIZE);
+	self->max = 0;
+	self->pos = 0;
+	self->tnt = 0;
+}
+
diff --git a/pt/tnt_cache.h b/pt/tnt_cache.h
new file mode 100644
index 000000000..38214c811
--- /dev/null
+++ b/pt/tnt_cache.h
@@ -0,0 +1,49 @@
+/*
+ * This file is part of Redqueen.
+ *
+ * Sergej Schumilo, 2019 <sergej@schumilo.de>
+ * Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+ *
+ * SPDX-License-Identifier: GPL-2.0-or-later
+ */
+
+#ifndef TNT_CACHE_H
+#define TNT_CACHE_H
+
+#include <stdio.h>
+#include <stdint.h>
+#include <stdlib.h>
+#include <stdbool.h>
+
+#define NOT_TAKEN			0
+#define TAKEN				1
+#define TNT_EMPTY			2
+
+#define SHORT_TNT_OFFSET	1
+#define SHORT_TNT_MAX_BITS	8-1-SHORT_TNT_OFFSET
+
+#define LONG_TNT_OFFSET		16
+#define LONG_TNT_MAX_BITS	64-1-LONG_TNT_OFFSET
+
+#define BUF_SIZE 0x1000000      /* 16777216 slots */
+
+typedef struct tnt_cache_s{
+	uint8_t* tnt_memory;
+	uint64_t pos;
+	uint64_t max;
+	uint64_t tnt;
+} tnt_cache_t;
+
+tnt_cache_t* tnt_cache_init(void);
+void tnt_cache_destroy(tnt_cache_t* self);
+void tnt_cache_flush(tnt_cache_t* self);
+
+
+bool is_empty_tnt_cache(tnt_cache_t* self);
+int count_tnt(tnt_cache_t* self);
+uint8_t process_tnt_cache(tnt_cache_t* self);
+
+void append_tnt_cache(tnt_cache_t* self, uint8_t data);
+void append_tnt_cache_ltnt(tnt_cache_t* self, uint64_t data);
+
+#endif
diff --git a/scripts/qemu-version.sh b/scripts/qemu-version.sh
index 3f6e7e6d4..20a375c7a 100755
--- a/scripts/qemu-version.sh
+++ b/scripts/qemu-version.sh
@@ -9,7 +9,7 @@ version="$3"
 if [ -z "$pkgversion" ]; then
     cd "$dir"
     if [ -e .git ]; then
-        pkgversion=$(git describe --match 'v*' --dirty) || :
+        pkgversion=6.0.0 || :
     fi
 fi
 
diff --git a/softmmu/hmp-commands-pt.h b/softmmu/hmp-commands-pt.h
new file mode 100644
index 000000000..9e91013f3
--- /dev/null
+++ b/softmmu/hmp-commands-pt.h
@@ -0,0 +1,70 @@
+/*
+* This file is part of Redqueen.
+*
+* Sergej Schumilo, 2019 <sergej@schumilo.de>
+* Cornelius Aschermann, 2019 <cornelius.aschermann@rub.de>
+*
+* SPDX-License-Identifier: GPL-2.0-or-later
+*/
+
+
+#if defined(CONFIG_PROCESSOR_TRACE)
+
+{
+.name       = "enable",
+.args_type  = "id:i",
+.params     = "id",
+.help       = "enable processor tracing for specified vcpu",
+.cmd  = hmp_pt_enable,
+},
+{
+.name       = "enable_all",
+.args_type  = "",
+.params     = "",
+.help       = "enable processor tracing for all presented vcpus",
+.cmd  = hmp_pt_enable_all,
+},
+{
+.name       = "disable",
+.args_type  = "id:i",
+.params     = "id",
+.help       = "disable processor tracing for specified vcpu",
+.cmd  = hmp_pt_disable,
+},
+{
+.name       = "disable_all",
+.args_type  = "",
+.params     = "",
+.help       = "disable processor tracing for all presented vcpus",
+.cmd  = hmp_pt_disable_all,
+},
+{
+.name       = "status",
+.args_type  = "id:i",
+.params     = "id",
+.help       = "print processor tracing status of specified vcpu",
+.cmd  = hmp_pt_status,
+},
+{
+.name       = "status_all",
+.args_type  = "",
+.params     = "",
+.help       = "print processor tracing status of all presented vcpus",
+.cmd  = hmp_pt_status_all,
+},
+{
+.name       = "ip_filtering",
+.args_type  = "id:i,addrn:i,addr_a:l,addr_b:l",
+.params     = "id addrn (0-4) addr_a addr_b",
+.help       = "enables ip-filtering for specified vcpu",
+.cmd  = hmp_pt_ip_filtering,
+},
+{
+.name       = "set_file",
+.args_type  = "file:s",
+.params     = "file",
+.help       = "set output file for all specified vcpu (postfix: _cpuid)",
+.cmd  = hmp_pt_set_file,
+},
+
+#endif
diff --git a/softmmu/runstate.c b/softmmu/runstate.c
index ce8977c6a..121a18be5 100644
--- a/softmmu/runstate.c
+++ b/softmmu/runstate.c
@@ -60,6 +60,20 @@
 #include "sysemu/tpm.h"
 #include "trace.h"
 
+#ifdef CONFIG_PROCESSOR_TRACE
+#include "migration/snapshot.h"
+#include "sysemu/kvm.h"
+#include "pt.h"
+#include "pt/hypercall.h"
+#include "pt/synchronization.h"
+extern void qemu_system_reload_request(void);
+#endif
+
+#ifdef CONFIG_PROCESSOR_TRACE
+static int reload_requested;
+char *loadvm_global = NULL;
+#endif
+
 static NotifierList exit_notifiers =
     NOTIFIER_LIST_INITIALIZER(exit_notifiers);
 
@@ -427,6 +441,16 @@ static int qemu_debug_requested(void)
     return r;
 }
 
+
+#ifdef CONFIG_PROCESSOR_TRACE
+static int qemu_reload_requested(void)
+{
+    int r = reload_requested;
+    reload_requested = 0;
+    return r;
+}
+#endif
+
 /*
  * Reset the VM. Issue an event unless @reason is SHUTDOWN_CAUSE_NONE.
  */
@@ -525,6 +549,12 @@ void qemu_system_guest_crashloaded(GuestPanicInformation *info)
 
 void qemu_system_reset_request(ShutdownCause reason)
 {
+#ifdef CONFIG_PROCESSOR_TRACE
+	if (kvm_enabled()) {
+		synchronization_unlock();
+		pt_disable(qemu_get_cpu(0), false);
+	}
+#endif
     if (reboot_action == REBOOT_ACTION_SHUTDOWN &&
         reason != SHUTDOWN_CAUSE_SUBSYSTEM_RESET) {
         shutdown_requested = reason;
@@ -538,6 +568,19 @@ void qemu_system_reset_request(ShutdownCause reason)
     qemu_notify_event();
 }
 
+#ifdef CONFIG_PROCESSOR_TRACE
+void qemu_system_reload_request(void)
+{
+    if (kvm_enabled()) {
+        synchronization_unlock();
+        pt_disable(qemu_get_cpu(0), false);
+    }
+    reload_requested = 1;
+    cpu_stop_current();
+    qemu_notify_event();
+}
+#endif
+
 static void qemu_system_suspend(void)
 {
     pause_all_vcpus();
@@ -548,6 +591,13 @@ static void qemu_system_suspend(void)
 
 void qemu_system_suspend_request(void)
 {
+#ifdef CONFIG_PROCESSOR_TRACE
+    if (kvm_enabled()) {
+        synchronization_unlock();
+        pt_disable(qemu_get_cpu(0), false);
+    }
+#endif
+
     if (runstate_check(RUN_STATE_SUSPENDED)) {
         return;
     }
@@ -619,6 +669,12 @@ void qemu_system_killed(int signal, pid_t pid)
 
 void qemu_system_shutdown_request(ShutdownCause reason)
 {
+#ifdef CONFIG_PROCESSOR_TRACE
+	if (kvm_enabled()) {
+		synchronization_unlock();
+		pt_disable(qemu_get_cpu(0), false);
+	}
+#endif
     trace_qemu_system_shutdown_request(reason);
     replay_shutdown_request(reason);
     shutdown_requested = reason;
@@ -668,6 +724,21 @@ static bool main_loop_should_exit(void)
     if (qemu_debug_requested()) {
         vm_stop(RUN_STATE_DEBUG);
     }
+#ifdef CONFIG_PROCESSOR_TRACE
+    if (qemu_reload_requested()){
+        if(loadvm_global){ 
+            vm_stop(RUN_STATE_RESTORE_VM);
+            Error *local_err = NULL;
+            if (load_snapshot(loadvm_global, NULL, false, NULL, &local_err) == 0){
+                vm_start();
+            } else {
+                error_reportf_err(local_err, "Error: ");
+            }
+            return false;
+        }
+    }
+#endif
+
     if (qemu_suspend_requested()) {
         qemu_system_suspend();
     }
diff --git a/softmmu/vl.c b/softmmu/vl.c
index aadb52613..74313a68b 100644
--- a/softmmu/vl.c
+++ b/softmmu/vl.c
@@ -128,6 +128,10 @@
 
 #define MAX_VIRTIO_CONSOLES 1
 
+#ifdef CONFIG_PROCESSOR_TRACE
+extern char* loadvm_global;
+#endif
+
 typedef struct BlockdevOptionsQueueEntry {
     BlockdevOptions *bdo;
     Location loc;
@@ -3130,6 +3134,9 @@ void qemu_init(int argc, char **argv, char **envp)
                 break;
             case QEMU_OPTION_loadvm:
                 loadvm = optarg;
+#ifdef CONFIG_PROCESSOR_TRACE
+                loadvm_global = (char*)optarg;
+#endif
                 break;
             case QEMU_OPTION_full_screen:
                 dpy.has_full_screen = true;
diff --git a/util/log.c b/util/log.c
index 2ee1500be..7248beb5c 100644
--- a/util/log.c
+++ b/util/log.c
@@ -329,6 +329,8 @@ const QEMULogItem qemu_log_items[] = {
     { CPU_LOG_TB_NOCHAIN, "nochain",
       "do not chain compiled TBs so that \"exec\" and \"cpu\" show\n"
       "complete traces" },
+     { LOG_KAFL, "kafl",
+      "trace kAFL/Redqueen execution" },
 #ifdef CONFIG_PLUGIN
     { CPU_LOG_PLUGIN, "plugin", "output from TCG plugins\n"},
 #endif
-- 
2.25.1

